{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFLLl1Agum8O"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/docs/gpt-4-langchain-docs.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/docs/gpt-4-langchain-docs.ipynb)\n",
        "\n",
        "# GPT4 with Retrieval Augmentation over LangChain Docs\n",
        "\n",
        "In this notebook we'll work through an example of using GPT-4 with retrieval augmentation to answer questions about the LangChain Python library.\n",
        "\n",
        "[![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/full-link.svg)](https://github.com/pinecone-io/examples/blob/master/learn/generation/openai/gpt-4-langchain-docs.ipynb)\n",
        "\n",
        "To begin we must install the prerequisite libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HDKlQO5svqI",
        "outputId": "1baa3186-e316-4111-931f-3517e1023632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.4/567.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU \\\n",
        "    openai==1.66.3 \\\n",
        "    pinecone==5.4.2 \\\n",
        "    pinecone-datasets==1.0.2 \\\n",
        "    pinecone-notebooks==0.1.1 \\\n",
        "    tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from pinecone_datasets import load_dataset\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from pinecone import Pinecone"
      ],
      "metadata": {
        "id": "KsxutYJHOx9R"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "# Instantiate the OpenAI client\n",
        "\n",
        "index_name = 'gpt-4-langchain-docs-fast'\n",
        "dimensions = 3072\n",
        "# Configure client\n",
        "pc = Pinecone(api_key=api_key)"
      ],
      "metadata": {
        "id": "6rwMRuoNInbH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZdWl7kR9KWJ"
      },
      "source": [
        "---\n",
        "\n",
        "🚨 _Note: the above `pip install` is formatted for Jupyter notebooks. If running elsewhere you may need to drop the `!`._\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgUEJ6vDum8q"
      },
      "source": [
        "In this example, we will use a pre-embedding dataset of the LangChain docs from [python.langchain.readthedocs.com/](https://python.langchain.com/en/latest/). If you'd like to see how we perform the data preparation refer to [this notebook]().\n",
        "\n",
        "The embeddings were produced with OpenAI's `text-embedding-ada-002` model which outputs embeddings with dimension `1536`.\n",
        "\n",
        "Let's go ahead and download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "phk1tQ0U92DM"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset('langchain-python-docs-text-embedding-ada-002')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset.documents.copy()[0:200]\n",
        "model=\"text-embedding-ada-002\"\n",
        "model=\"text-embedding-3-large\"\n"
      ],
      "metadata": {
        "id": "G79xD4msNpar"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "Yv53PFcMfMa_",
        "outputId": "9000bbd1-b8a4-42c5-8f9c-85586849a541"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['sparse_values'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-50ec19ba4207>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We drop the sparse_values column since it is not needed in this demo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sparse_values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# We rename the blob column to metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'blob'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'metadata'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['sparse_values'] not found in axis\""
          ]
        }
      ],
      "source": [
        "# We drop the sparse_values column since it is not needed in this demo\n",
        "df.drop(['sparse_values'], axis=1, inplace=True)\n",
        "# We rename the blob column to metadata\n",
        "df.drop(['metadata'], axis=1, inplace=True)\n",
        "df.rename(columns={'blob': 'metadata'}, inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(7)"
      ],
      "metadata": {
        "id": "UCzw_TIRNGYt",
        "outputId": "a0aa877d-e77b-4016-8f23-cd6777cb3631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     id  \\\n",
              "0  417ede5d-39be-498f-b518-f47ed4e53b90   \n",
              "1  110f550d-110b-4378-b95e-141397fa21bc   \n",
              "2  d5f00f02-3295-4567-b297-5e3262dc2728   \n",
              "3  0b6fe3c6-1f0e-4608-a950-43231e46b08a   \n",
              "4  39d5f15f-b973-42c0-8c9b-a2df49b627dc   \n",
              "5  00e7c34b-555e-4d47-b400-56aba20ce77e   \n",
              "6  74d53a65-3e99-4105-a5b1-e571fc1036f2   \n",
              "\n",
              "                                              values  \\\n",
              "0  [0.005949743557721376, 0.01983247883617878, -0...   \n",
              "1  [0.009401749819517136, 0.02443608082830906, 0....   \n",
              "2  [-0.005517194513231516, 0.0208403542637825, 0....   \n",
              "3  [-0.006499645300209522, 0.0011573900701478124,...   \n",
              "4  [-0.005658374633640051, 0.00817849114537239, 0...   \n",
              "5  [0.0006713771726936102, -0.00321398233063519, ...   \n",
              "6  [-0.005567097570747137, -0.006656466517597437,...   \n",
              "\n",
              "                                            metadata  \n",
              "0  {'chunk': 0, 'text': '.rst\n",
              ".pdf\n",
              "Welcome to Lan...  \n",
              "1  {'chunk': 1, 'text': 'Use Cases#\n",
              "Best practice...  \n",
              "2  {'chunk': 2, 'text': 'Gallery: A collection of...  \n",
              "3  {'chunk': 0, 'text': 'Search\n",
              "Error\n",
              "Please acti...  \n",
              "4  {'chunk': 0, 'text': '.md\n",
              ".pdf\n",
              "Dependents\n",
              "Depe...  \n",
              "5  {'chunk': 1, 'text': '1571\n",
              "IntelligenzaArtific...  \n",
              "6  {'chunk': 2, 'text': '437\n",
              "alexanderatallah/win...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07af380b-61f2-404c-a8d2-641f09cb8afe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>values</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>417ede5d-39be-498f-b518-f47ed4e53b90</td>\n",
              "      <td>[0.005949743557721376, 0.01983247883617878, -0...</td>\n",
              "      <td>{'chunk': 0, 'text': '.rst\n",
              ".pdf\n",
              "Welcome to Lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110f550d-110b-4378-b95e-141397fa21bc</td>\n",
              "      <td>[0.009401749819517136, 0.02443608082830906, 0....</td>\n",
              "      <td>{'chunk': 1, 'text': 'Use Cases#\n",
              "Best practice...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d5f00f02-3295-4567-b297-5e3262dc2728</td>\n",
              "      <td>[-0.005517194513231516, 0.0208403542637825, 0....</td>\n",
              "      <td>{'chunk': 2, 'text': 'Gallery: A collection of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0b6fe3c6-1f0e-4608-a950-43231e46b08a</td>\n",
              "      <td>[-0.006499645300209522, 0.0011573900701478124,...</td>\n",
              "      <td>{'chunk': 0, 'text': 'Search\n",
              "Error\n",
              "Please acti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39d5f15f-b973-42c0-8c9b-a2df49b627dc</td>\n",
              "      <td>[-0.005658374633640051, 0.00817849114537239, 0...</td>\n",
              "      <td>{'chunk': 0, 'text': '.md\n",
              ".pdf\n",
              "Dependents\n",
              "Depe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00e7c34b-555e-4d47-b400-56aba20ce77e</td>\n",
              "      <td>[0.0006713771726936102, -0.00321398233063519, ...</td>\n",
              "      <td>{'chunk': 1, 'text': '1571\n",
              "IntelligenzaArtific...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>74d53a65-3e99-4105-a5b1-e571fc1036f2</td>\n",
              "      <td>[-0.005567097570747137, -0.006656466517597437,...</td>\n",
              "      <td>{'chunk': 2, 'text': '437\n",
              "alexanderatallah/win...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07af380b-61f2-404c-a8d2-641f09cb8afe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-07af380b-61f2-404c-a8d2-641f09cb8afe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-07af380b-61f2-404c-a8d2-641f09cb8afe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6e8ae805-9ec6-4e75-b49a-b20c8731ca15\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6e8ae805-9ec6-4e75-b49a-b20c8731ca15')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6e8ae805-9ec6-4e75-b49a-b20c8731ca15 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 200,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"c4153717-4304-41a7-bdea-b526bb4e379a\",\n          \"74ab93a8-efb1-4115-9a1c-186a4cb52ec4\",\n          \"f3d94aec-5a75-4ff8-bfa8-dd2c54edcca2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"values\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate embeddings\n",
        "def generate_embeddings(text):\n",
        "\n",
        "# Assuming you have your OpenAI API key set as an environment variable\n",
        "  client = OpenAI(api_key=openai_api_key)\n",
        "  #openai.api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "  # response = openai.Embedding.create(\n",
        "  #   input=text,\n",
        "  #     model=model\n",
        "  # )\n",
        "  response = client.embeddings.create(\n",
        "      input=text,\n",
        "      model=model\n",
        "  )\n",
        "\n",
        "  #return response['data'][0]['embedding']\n",
        "  return response\n"
      ],
      "metadata": {
        "id": "45Am_GrbOdEL"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=generate_embeddings(\"how do i make chimichangas?\")\n",
        "#print(x['data'][0]['Embedding'])\n",
        "x.data[0].embedding"
      ],
      "metadata": {
        "id": "vug8uEE9PoUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(x)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "c8hyRQTPPb03",
        "outputId": "24e03d44-e3e5-4ea6-9ddc-c6ae02609ce9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CreateEmbeddingResponse(data=[Embedding(embedding=[-0.023769378662109375, -0.03218448907136917, -0.012402372434735298, -0.009780911728739738, -0.02131313644349575, 0.006608724594116211, 0.010441784746944904, 0.005843213759362698, -0.03249289467930794, 0.05414748191833496, -0.023879524320364, -0.008459167554974556, -0.0618136040866375, -0.024143872782588005, -0.0054797339253127575, -0.013239477761089802, -0.020409943535923958, 0.022734012454748154, 0.011906718835234642, 0.005055674351751804, 0.016554854810237885, 0.043771784752607346, 0.014550208114087582, 0.03844074904918671, 0.049345143139362335, 0.04833180457353592, -0.03427724912762642, -0.023637205362319946, -0.008938299492001534, 0.0241218451410532, -0.008304963819682598, 0.03319782763719559, -0.01025453768670559, 0.022822128608822823, -0.015156008303165436, 0.013030202127993107, 0.01705050840973854, -0.03174390643835068, 0.009995696134865284, 0.011785558424890041, -0.02116994746029377, 0.004403062630444765, 0.010320624336600304, -0.007699164096266031, -0.031171150505542755, 0.019055156037211418, 0.03579725697636604, 0.004493932705372572, -0.0031171150039881468, 0.0017609497299417853, 0.017645293846726418, 0.011367006227374077, 0.00822235457599163, -0.0045104543678462505, -0.009263228625059128, 0.06176954507827759, 0.029386794194579124, -0.07009653747081757, -0.014252815395593643, -0.042604245245456696, -0.020817482843995094, 0.010381205007433891, 0.004744513425976038, 0.020035449415445328, 0.023483000695705414, 0.0003251010493841022, -0.0245844554156065, 0.01245744526386261, -0.030047666281461716, 0.03414507582783699, 0.00015755956701468676, 0.004887702409178019, 0.002699939301237464, 0.01231425628066063, -0.007335684262216091, 0.04000481218099594, -0.002391532063484192, -0.016334563493728638, 0.011752515099942684, -0.014407019130885601, 0.019033126533031464, -0.024011699482798576, 0.0006870320066809654, 0.0041965399868786335, 0.0035191457718610764, 0.026677217334508896, 0.007913947105407715, -0.03247086703777313, 0.0008790980209596455, -0.01663195714354515, 0.03222854435443878, -0.006443506106734276, 0.04176713898777962, 0.013867306523025036, 0.04537990689277649, 0.020960671827197075, 0.005394371226429939, 0.009351344779133797, -0.021247049793601036, -0.010959467850625515, -0.0473184660077095, 0.021423282101750374, -0.023879524320364, 0.018416311591863632, -0.06502985209226608, 0.024298077449202538, 0.012644692324101925, 0.008095687255263329, -0.018240079283714294, -0.08322586864233017, -0.07115393131971359, 0.0003125375951640308, 0.04982978105545044, 0.04696600139141083, -0.018801821395754814, -0.022216329351067543, -0.017292829230427742, 0.023174593225121498, -0.0011152222286909819, -0.04245004057884216, 0.007264089770615101, 0.04242800921201706, 0.03236072137951851, 0.03031201660633087, 0.005264950450509787, 0.02070733718574047, 0.008409601636230946, -0.03310970962047577, 0.004615092650055885, -0.004783064126968384, 0.029585056006908417, -0.025421559810638428, -0.0010925047099590302, 0.0393439382314682, 0.009444968774914742, -0.012688751332461834, 0.00698872609063983, -0.01098700426518917, -0.01939660683274269, 0.026545044034719467, -0.03172187879681587, 0.006096548400819302, 0.025025036185979843, -0.00010188449959969148, -0.025311414152383804, -0.009450475685298443, 0.009208155795931816, -0.010898888111114502, 0.04333120211958885, 0.005991910118609667, -0.03161173313856125, -0.005898286588490009, 0.0107722207903862, 0.008332500234246254, -0.004014800302684307, -0.006013939157128334, -0.02248067781329155, -0.003488855669274926, 0.053839076310396194, -0.026589101180434227, 0.02561982162296772, -0.026016345247626305, -0.021147917956113815, 0.010221493430435658, -0.013613972812891006, -0.014682382345199585, 0.03460768610239029, -0.027007654309272766, -0.04037930816411972, 0.024187931790947914, 0.009428447112441063, -0.017678337171673775, -0.029629115015268326, -0.0018476891564205289, -0.00027295408654026687, -0.026853449642658234, -0.021577484905719757, 0.001360295806080103, 0.031259264796972275, 0.01484760083258152, -0.008211339823901653, -0.009296271950006485, 0.021037772297859192, 0.0042598736472427845, -0.00910902488976717, 0.044895268976688385, -0.009433954022824764, 0.018526457250118256, 0.014164699241518974, -0.016554854810237885, 0.003921176306903362, -0.021522412076592445, 0.0006653470918536186, -0.03764770179986954, 0.018162976950407028, -0.014671368524432182, -0.003367695724591613, -0.035246528685092926, -0.04022510349750519, -0.007853367365896702, -0.02332879789173603, -0.022425604984164238, -0.02969520166516304, 0.03826451301574707, -0.03429928049445152, -0.01245744526386261, -0.02135719358921051, 0.00033181303297169507, 0.010287581011652946, -0.03152361512184143, 0.032206516712903976, -0.02603837475180626, -0.014054553583264351, 0.03253695368766785, -0.029849406331777573, -0.0036320448853075504, -0.009444968774914742, 0.018140949308872223, -0.06480956077575684, -0.027007654309272766, 0.0060304612852633, -0.034409426152706146, -0.004576541483402252, 0.013074260205030441, -0.0015654416056349874, 0.01658789813518524, -0.013702088966965675, -0.012622663751244545, -0.021621543914079666, -0.010017724707722664, 0.011256860569119453, -0.012655707076191902, 0.020013419911265373, -0.00319697055965662, 0.007291626185178757, -0.040819887071847916, -0.024650542065501213, -0.01929747499525547, -0.06331157684326172, 0.02749229408800602, -0.007357713300734758, 0.06820203363895416, -0.05872952938079834, -0.02346097119152546, 0.025641851127147675, 0.03169984742999077, 0.010425263084471226, 0.0030097232665866613, -0.04031321778893471, -0.021654587239027023, 0.004240598063915968, 0.03216245770454407, 0.017491091042757034, 0.002398416167125106, -0.008426123298704624, 0.03844074904918671, -0.011532223783433437, -0.005592633038759232, 0.020299797877669334, 0.021863862872123718, 0.0059974174946546555, 0.011036570183932781, 0.019264431670308113, -0.007148436736315489, 0.02248067781329155, -0.014649339020252228, -0.012975129298865795, 0.007996556349098682, 0.0004791325191035867, -0.032206516712903976, -0.044146280735731125, 0.02266792394220829, 0.0032685650512576103, -0.00639394111931324, 0.008569312281906605, -0.013933394104242325, 0.0332639142870903, 0.02191893570125103, 0.037823934108018875, -0.027932874858379364, -0.00537509610876441, 0.014594266191124916, 0.0063719116151332855, -0.02561982162296772, -0.019286461174488068, 0.002025298774242401, -0.06106461212038994, 0.000907322799321264, -0.016653984785079956, -0.059830985963344574, -0.021147917956113815, -0.049433257430791855, 0.02403372712433338, 0.0021850094199180603, 0.01482557225972414, 0.02786678820848465, 0.059830985963344574, -0.0006002924637869, 0.009874535724520683, 0.027668526396155357, -0.026853449642658234, -0.00047362525947391987, -0.02000240609049797, -0.03031201660633087, 0.009411925449967384, 0.018845878541469574, -0.001744427834637463, 0.02702968381345272, -0.021037772297859192, -0.017832541838288307, 0.0003965234791394323, -0.012831940315663815, -0.03401290252804756, 0.006245244760066271, -0.008376558311283588, 0.024606484919786453, 0.01657688431441784, -0.0026187070179730654, -0.012127009220421314, -0.019319504499435425, -0.020387914031744003, -0.034167107194662094, -0.04996195808053017, -0.0053392983973026276, -0.009830477647483349, 0.031303323805332184, 0.012115994468331337, -0.0505787692964077, 0.0020597190596163273, -0.017402974888682365, 0.01582789421081543, -0.0026779102627187967, -0.025685908272862434, -0.008811632171273232, -0.05961069464683533, 0.005936837289482355, 0.011102656833827496, 0.004292917437851429, 0.0041332063265144825, 0.010931931436061859, -0.006707855500280857, 0.005617415998131037, 0.034167107194662094, -0.01555253192782402, 0.019352547824382782, 0.0024961703456938267, 0.03991669416427612, 0.032801304012537, -0.0029849405400455, 0.0035274066030979156, 0.0004760346782859415, -0.036414071917533875, -0.020498059689998627, -0.016786159947514534, -0.01677514612674713, 0.013856292702257633, 0.0033181305043399334, 0.01962791197001934, 0.00908699631690979, -0.004923499654978514, -0.013272522017359734, -0.02079545333981514, -0.006895102560520172, 0.02252473495900631, -0.01621340401470661, 0.014946731738746166, -0.003907408099621534, -0.020674293860793114, -0.010006709955632687, 0.012237154878675938, -0.010177435353398323, 0.03156767413020134, 0.0010560191003605723, 0.029893463477492332, 0.022546764463186264, -0.00633336091414094, 0.018889937549829483, -0.017832541838288307, -0.01896703988313675, -0.000980982556939125, 0.016709057614207268, -0.02220531366765499, -0.006344375666230917, -0.014274844899773598, -0.0004509077698457986, -0.017160654067993164, -0.00878409668803215, -0.02482677437365055, -0.0031143613159656525, -0.028439544141292572, -0.028439544141292572, -0.05154804885387421, -0.02046501636505127, 0.011653384193778038, -0.017667323350906372, -0.03542276471853256, 0.020718351006507874, -0.0019082691287621856, 0.005361327901482582, 0.03405696153640747, 0.02623663656413555, -0.03579725697636604, -0.0017884860280901194, 0.010474828071892262, 0.004496686160564423, 0.03147955611348152, 0.021180961281061172, -0.024738658219575882, 0.0038908864371478558, 0.02177574671804905, 0.03269115835428238, 0.022359518334269524, -0.019308490678668022, 0.038947414606809616, -0.04533584788441658, -0.014230786822736263, -0.01863660290837288, -0.026677217334508896, 0.009406417608261108, -0.0012887013144791126, 0.04458685964345932, 0.03676653653383255, 0.013845277950167656, -0.04509352892637253, -0.015354270115494728, 0.011455122381448746, 0.02210618369281292, 0.039277851581573486, -0.006074519362300634, -0.039784520864486694, -0.008095687255263329, -0.021797776222229004, 0.005397125147283077, 0.009819462895393372, -0.022778069600462914, -0.02782272920012474, -0.00030135095585137606, 0.028131136670708656, 0.0114771518856287, -0.02253575064241886, 0.021907921880483627, 0.01638963632285595, -0.03731726482510567, 0.006267273798584938, -0.007847860455513, -0.02973926067352295, 0.015321225859224796, 0.034255221486091614, 0.03180999308824539, -0.032382749021053314, -0.009610187262296677, 0.010309610515832901, -0.002533344319090247, -0.03985060751438141, 0.0054466906003654, 0.012237154878675938, -0.008585834875702858, 0.010006709955632687, 0.01397745218127966, -0.007175973150879145, -0.0021092845126986504, 0.017865585163235664, 0.018801821395754814, 0.0035191457718610764, 0.005264950450509787, 0.01245744526386261, -0.03764770179986954, -0.015001804567873478, -0.019727041944861412, -0.03797813504934311, -0.005711039528250694, 0.022216329351067543, 0.009841492399573326, -0.05071094632148743, 0.035576965659856796, 0.002106530824676156, -0.026302723214030266, -0.013999481685459614, -0.011576281860470772, -0.032581012696027756, -0.0028830559458583593, 0.028968242928385735, 0.010827293619513512, -0.041745107620954514, -0.010942946188151836, 0.01765630953013897, 0.007275104057043791, -0.0003152912249788642, -0.009802941232919693, 0.028549689799547195, 0.021434295922517776, 0.024848803877830505, 0.011972805485129356, -0.028880124911665916, -0.0036953783128410578, -0.017028480768203735, -0.012975129298865795, 0.0040588583797216415, 0.04771498963236809, -0.017865585163235664, -0.00027157727163285017, 0.027294032275676727, 0.016786159947514534, -0.0077817728742957115, 0.00951105635613203, 0.0017540656263008714, -0.0021932704839855433, 0.05731967091560364, 0.040026839822530746, 0.06300317496061325, 0.044190336018800735, 0.03385869786143303, 0.02773461304605007, 0.014429048635065556, 0.026192577555775642, 0.0016755870310589671, -0.007633076515048742, 0.03288941830396652, -0.01070062629878521, 0.007605540566146374, 0.00107185251545161, 0.005044659599661827, 0.014891658909618855, -0.002957404125481844, 0.019429650157690048, -0.002716461196541786, 0.011367006227374077, -0.013382666744291782, 0.028792008757591248, 0.02177574671804905, 0.013173391111195087, 0.010689611546695232, -0.000550727010704577, 0.010034246370196342, 0.019187329337000847, 0.009962651878595352, -0.025796053931117058, -0.022822128608822823, -0.005570604000240564, -0.013547885231673717, -0.030245928093791008, -0.041238442063331604, -0.025465618818998337, 0.027558380737900734, -0.03802219405770302, 0.0048023397102952, 0.003744943765923381, -0.008068150840699673, -0.013856292702257633, 0.020674293860793114, -0.0185044277459383, 0.021808790042996407, -0.02370329201221466, 0.02632475271821022, 0.009219170548021793, 0.023923583328723907, 0.029981579631567, -0.016235433518886566, -0.022932274267077446, -0.019594868645071983, 0.025377502664923668, 0.0015310212038457394, -0.0005342052318155766, -0.01376817561686039, -0.007175973150879145, 0.00604147557169199, 0.004956543445587158, 0.025311414152383804, 0.011108164675533772, 0.0036017547827214003, -0.016753116622567177, 0.0024507353082299232, 0.024298077449202538, -0.0013816364808008075, 0.019286461174488068, 0.025796053931117058, 0.017303843051195145, -0.005716546438634396, 0.004345236346125603, 0.008404094725847244, 0.005099732428789139, 0.0035769720561802387, -0.03797813504934311, 0.011201787739992142, 0.011598311364650726, 0.016731087118387222, 0.0332418829202652, -0.0021533428225666285, -0.02220531366765499, 0.02566388063132763, -0.039696406573057175, -0.009444968774914742, -0.0016934856539592147, 0.01119628082960844, 0.029342737048864365, -0.01578383706510067, 0.01620239019393921, 0.007220031227916479, 0.016510795801877975, 0.021489368751645088, -0.0012721794191747904, 0.01607021503150463, 0.035621024668216705, -0.018757762387394905, -0.0015117457369342446, -0.040489450097084045, 0.0196719691157341, 0.0149907898157835, 0.0031859558075666428, -0.010133377276360989, -0.0007090610451996326, -0.01718268357217312, -0.006537130102515221, -0.024606484919786453, -0.0033456666860729456, -0.0033952321391552687, -0.017347902059555054, -0.02636880986392498, -0.03081868588924408, -0.021147917956113815, -0.01854848675429821, 0.032206516712903976, 0.024694601073861122, 0.02131313644349575, 0.009720331989228725, -0.003089578589424491, -0.0017568191979080439, 0.014208757318556309, -0.0075835115276277065, 0.04093003273010254, 0.006867566145956516, -0.023923583328723907, 0.014924703165888786, 0.015299197286367416, 0.017623264342546463, 0.011587296612560749, 0.014902673661708832, -0.018140949308872223, -0.00025832539540715516, -0.002281386638060212, -0.024650542065501213, -0.029342737048864365, 0.013547885231673717, -0.031457528471946716, -0.022689953446388245, -0.0027467510662972927, -0.0009740984532982111, 0.0004240598063915968, -0.012655707076191902, 0.031920138746500015, -0.002008776878938079, -0.021136904135346413, -0.01243541669100523, 0.01793167181313038, 0.008282934315502644, -0.015299197286367416, 0.00214370503090322, -0.014649339020252228, -0.0067629278637468815, 0.017402974888682365, -0.040908005088567734, 0.010331639088690281, 0.008013078011572361, -0.022139227017760277, 0.019363563507795334, -0.008492210879921913, 0.053046029061079025, 0.023196622729301453, -0.03110506385564804, -0.03011375479400158, 0.04811151325702667, -0.02965114451944828, -0.01620239019393921, 0.007357713300734758, -0.002280009910464287, -0.015728764235973358, 0.018526457250118256, 0.03771378844976425, 0.010089319199323654, 0.004502193536609411, 0.03284535929560661, 0.04253815487027168, 0.012259183451533318, 0.024518366903066635, 0.02055313251912594, -0.008470181375741959, -0.0227119829505682, 0.002497547073289752, 0.027976933866739273, -0.0018201528582721949, 0.02744823507964611, 0.0016370360972359776, -0.012490489520132542, 0.028219252824783325, -0.028109107166528702, -0.008205832913517952, -0.01695137843489647, 0.0005610531661659479, 0.010502364486455917, -0.015805866569280624, -0.012986143119633198, 0.01220411155372858, -0.01056294422596693, 0.002346097258850932, 0.02482677437365055, -0.01934153400361538, -0.010315117426216602, 0.017733410000801086, -0.0061240848153829575, -0.010838308371603489, 0.007836845703423023, 0.011950776912271976, 0.0007214524084702134, -0.0035191457718610764, 0.022502707317471504, 0.04203148931264877, 0.01938559114933014, 0.023637205362319946, 0.005377849563956261, -0.022822128608822823, 0.0062342300079762936, 0.008822646923363209, 0.013669044710695744, -0.03694276884198189, 0.01620239019393921, -0.007253075018525124, -0.01611427217721939, 0.021478354930877686, -0.01761225052177906, -0.008481196127831936, -0.002973926020786166, -0.025553734973073006, -0.002346097258850932, 0.013624986633658409, 0.03006969578564167, -0.011400049552321434, -0.0070162625052034855, -0.010959467850625515, -0.04046742245554924, 0.018581530079245567, 0.00976439006626606, -0.002023921813815832, 0.001981240464374423, 0.029210561886429787, -0.02777867205440998, -0.028593746945261955, -0.022084154188632965, 0.03264709934592247, -0.013900350779294968, 0.0049014706164598465, 0.028109107166528702, 0.01027656625956297, -0.003794509219005704, 0.00305653503164649, 0.002720591612160206, 0.024231988936662674, 0.0015668184496462345, -0.01789862848818302, -0.041943371295928955, -0.013591943308711052, -0.024187931790947914, 0.006790464278310537, -0.006019446533173323, -0.006399448029696941, 0.0035274066030979156, -0.02299836091697216, -0.011664398945868015, 0.01266672182828188, -0.002637982601299882, 0.003676102962344885, 0.009610187262296677, -0.004042336251586676, -0.030223900452256203, -0.005636691115796566, -0.00023371478891931474, -0.02047603204846382, 0.009560621343553066, -0.011251353658735752, 0.021324150264263153, -0.0029326213989406824, -0.01293107122182846, 0.0029491432942450047, 0.024320105090737343, 0.011686427518725395, -0.011697442270815372, -0.0024961703456938267, 0.03015781193971634, 0.020409943535923958, 0.00573857594281435, 0.01170845702290535, -0.026545044034719467, 0.028880124911665916, -0.028769981116056442, -0.0019660955294966698, 0.03681059554219246, 0.002101023681461811, 0.0005768865812569857, -0.008244384080171585, -0.005050166975706816, -0.018812835216522217, 0.035290587693452835, -0.0015034847892820835, -0.029056359082460403, 0.011686427518725395, -0.008817140012979507, -0.045027442276477814, 0.012182082049548626, 0.0030813177581876516, 0.015893982723355293, 0.03053230606019497, 0.017722396180033684, -0.04341932013630867, -0.043066855520009995, 0.00531451590359211, 0.022734012454748154, -0.012688751332461834, -0.021797776222229004, 0.020288784056901932, -0.01961689628660679, 0.008249890990555286, 0.02683142200112343, 0.007572496775537729, 0.013404696248471737, 0.011576281860470772, -0.020971685647964478, 0.02683142200112343, -0.008998880162835121, 0.005771619267761707, -0.029012300074100494, -0.020718351006507874, 0.004100163001567125, -0.022128213196992874, -0.02533344365656376, 0.01957283914089203, 0.01827312260866165, 0.030796656385064125, 0.011961791664361954, -0.05141587555408478, -0.016004128381609917, -0.018207035958766937, -0.019826173782348633, -0.016004128381609917, -0.001591601176187396, 0.007087856996804476, 0.02707374095916748, -0.008194818161427975, -0.03771378844976425, -0.008695979602634907, 0.03339608758687973, -0.00791945494711399, 0.0013837016886100173, -0.018438341096043587, -0.03381463885307312, 0.01588296703994274, 0.03764770179986954, 0.004593063611537218, -0.005631183739751577, -0.021610528230667114, 0.008629892952740192, 0.005006108898669481, 0.02365923300385475, 0.03509232774376869, -0.02257980778813362, 0.015277167782187462, -0.008464674465358257, -0.04070974141359329, 0.00880612526088953, -0.004381033591926098, 0.018008774146437645, -0.013867306523025036, -0.007842352613806725, -0.007803801912814379, -0.023615175858139992, 0.006933653261512518, 0.0032878404017537832, -0.03540073335170746, -0.02707374095916748, 0.022326475009322166, -0.00713191507384181, 0.034916095435619354, -0.017458047717809677, -0.002044574124738574, 0.0208395104855299, -0.0013699334813281894, 0.025751996785402298, -0.015034847892820835, -0.003692624857649207, 0.021004728972911835, 0.003970741759985685, -0.027183886617422104, -0.013988466933369637, 0.010722655802965164, -0.007385249715298414, 0.005380603019148111, 0.008960328996181488, 0.013658030889928341, -0.01062903180718422, -0.0351363867521286, -0.008921777829527855, -0.016521811485290527, -0.023108506575226784, 0.05216486379504204, 0.005892779212445021, 0.036788567900657654, -0.01980414427816868, 0.01676413044333458, 0.027888817712664604, 0.004303931724280119, 0.03531261906027794, 0.00741278612986207, -0.01924240216612816, -0.007627569604665041, 0.045644257217645645, -0.0002633163530845195, 0.017061524093151093, 0.018989067524671555, -0.01901109702885151, -0.0120609225705266, 0.004747266881167889, 0.030047666281461716, -0.008745545521378517, 0.03621580824255943, 0.028792008757591248, 0.012820925563573837, 0.03209637105464935, -0.033506233245134354, -0.014407019130885601, 0.017116596922278404, 0.03134738281369209, 0.03507029637694359, -0.007765251211822033, -0.018008774146437645, -0.0061736502684652805, 0.006432491820305586, 0.0037146538961678743, -0.018515443429350853, -0.0180308036506176, -0.022800099104642868, -0.004981325939297676, -0.023483000695705414, 0.048728328198194504, 0.005256689619272947, -0.01257860567420721, -0.037956107407808304, 0.02009052224457264, -0.015607603825628757, 0.0374714657664299, 0.0175681933760643, -0.004036829341202974, -0.042361922562122345, -0.03564305230975151, 0.0021918935235589743, -0.008916270919144154, -0.004034075420349836, -0.023637205362319946, 0.015717750415205956, -0.019638925790786743, -0.008227861486375332, 0.02716185711324215, -0.012710779905319214, -0.002308923052623868, -0.0007063074153847992, -7.12072869646363e-05, 0.00742380041629076, -0.025443589314818382, 0.00022717489628121257, 0.007616554852575064, 0.017733410000801086, -0.007952498272061348, 0.036325953900814056, 0.0059974174946546555, -0.0030317523051053286, -0.0006481368909589946, -0.009373374283313751, 0.00951105635613203, -0.0007765251211822033, 0.017634280025959015, -0.023637205362319946, 0.010673089884221554, 0.04379381239414215, -0.03963031619787216, -0.02932070754468441, -0.03648015856742859, -0.02782272920012474, 0.021158933639526367, 0.01412064116448164, 0.021379223093390465, 0.02603837475180626, 0.006784956902265549, -0.01714964024722576, -0.04599672183394432, -0.027470264583826065, 0.01318440493196249, -0.051680225878953934, -0.010998019017279148, -0.05414748191833496, -0.033043622970581055, 0.0313694104552269, -0.017402974888682365, 0.0047114696353673935, 0.010061782784759998, 0.015012819319963455, -0.035665083676576614, -0.025884170085191727, 0.03733929246664047, 0.0030179840978235006, 0.01461629569530487, -0.0005562343285419047, -0.004191032610833645, -0.026721276342868805, -0.014792528003454208, 0.03685465455055237, -0.0012749331071972847, -0.01536528393626213, -0.003811031114310026, 0.008167281746864319, -0.009538591839373112, -0.021533427760004997, 0.008762067183852196, 0.06626347452402115, 0.028880124911665916, 0.027888817712664604, -0.030510278418660164, -0.012677736580371857, -0.011190772987902164, -0.013085274025797844, -0.02861577644944191, 0.04621701315045357, 0.023989669978618622, -0.022822128608822823, -0.007175973150879145, 0.004213061649352312, -0.004912485368549824, 0.00316668045707047, 0.003488855669274926, 0.022932274267077446, -0.016268476843833923, -0.04088597372174263, 0.017623264342546463, 0.001078736619092524, 0.018140949308872223, -0.0029601578135043383, -0.029540998861193657, 0.0351363867521286, 0.01680818945169449, 0.020035449415445328, 0.01752413436770439, -0.019088199362158775, -0.01278788223862648, 0.02965114451944828, -0.011069613508880138, -0.006482057273387909, 0.020310813561081886, 0.024187931790947914, 0.010287581011652946, -0.011212802492082119, 0.003775233868509531, 0.0006453832611441612, -0.003967988304793835, 0.014935716986656189, 0.01621340401470661, 0.05498458817601204, 0.020740380510687828, 0.005881764926016331, 0.024760687723755836, 0.03141346946358681, -0.014373975805938244, -0.0064490134827792645, -0.029805347323417664, 0.0015117457369342446, -0.0011172874365001917, -0.0059203156270086765, -0.007660612929612398, -0.014748469926416874, -0.028109107166528702, 0.0046371216885745525, 0.012468460015952587, -0.009538591839373112, -0.014539193361997604, -0.012149038724601269, 0.030708540230989456, 0.03586334362626076, 0.02669924683868885, -0.004540744237601757, -0.014318902976810932, -0.018801821395754814, 0.012027878314256668, 0.007247567642480135, -0.0208395104855299, 2.5987432309193537e-05, -0.00323827494867146, -0.019991392269730568, 0.011818602681159973, 0.007930469699203968, 0.0034090003464370966, -0.009544099681079388, 0.018328195437788963, 0.012523532845079899, 0.00807916559278965, 0.006206693593412638, -0.0449613556265831, -0.015100935474038124, -0.005303501151502132, -0.00604147557169199, 0.006795971654355526, -0.009103517979383469, -0.006399448029696941, 0.00015928057837300003, -0.013999481685459614, 0.0015681952936574817, -0.01583890989422798, 0.028439544141292572, -0.006592202465981245, 0.01958385296165943, -0.00859134178608656, 0.007980034686625004, -0.0035274066030979156, -0.004119438119232655, -0.012655707076191902, 0.0184934139251709, -0.032713185995817184, 0.009026416577398777, -0.006283795461058617, 0.044102221727371216, 0.008464674465358257, -0.012369329109787941, -0.014418033882975578, 0.0025003007613122463, 0.007660612929612398, 0.022216329351067543, -0.00924670696258545, 0.005286979489028454, 0.025179240852594376, -0.0035053775645792484, -0.0023075463250279427, 0.006278288085013628, 0.004915238823741674, 0.002091385889798403, 0.019682984799146652, -0.0006925392663106322, -0.0037229147274047136, -0.004598570987582207, 0.012556576170027256, 0.022800099104642868, 0.004750020802021027, 0.015122964046895504, -0.027139827609062195, 0.006906116846948862, -0.052429214119911194, 0.018482400104403496, -0.002631098497658968, -0.03328594192862511, -0.021390238776803017, -0.004265381023287773, -0.00353016029112041, 0.003510884940624237, 0.01016642153263092, 0.029563026502728462, 0.01789862848818302, -0.00639394111931324, 0.008046122267842293, -0.005716546438634396, -0.008982357569038868, 0.0017526887822896242, 0.019881246611475945, -0.018900951370596886, 0.040908005088567734, 0.004805093631148338, -0.006895102560520172, -0.024760687723755836, -0.010067290626466274, -0.017314858734607697, 0.0043865409679710865, 0.005325530655682087, -0.0010849322425201535, -0.021896906197071075, 0.01339368149638176, 0.022645896300673485, -0.008481196127831936, 0.02150038443505764, -0.01360295806080103, -0.01902211271226406, -0.0026476201601326466, -0.00850322563201189, -0.0073411911725997925, -0.001332759391516447, -0.018151963129639626, 0.02965114451944828, -0.026016345247626305, 0.007137422449886799, 0.02328473888337612, -0.009455983527004719, -0.039365969598293304, -0.0037724801804870367, 0.0007627569721080363, -0.020685307681560516, -0.024892862886190414, -0.023549087345600128, 0.0027302291709929705, 0.0030813177581876516, -0.02865983545780182, 0.0022208066657185555, 0.01695137843489647, 0.007616554852575064, 0.001591601176187396, -0.01016642153263092, -0.015023833140730858, 0.01672007329761982, -0.017336886376142502, 0.012986143119633198, -0.007005247753113508, 0.01540934294462204, -0.00034007395152002573, -0.010568452067673206, 0.02753635123372078, -0.0003287151921540499, -0.01070062629878521, 0.0032878404017537832, -0.010667582973837852, 0.006294810213148594, 0.003940451890230179, 0.005766111891716719, -0.004303931724280119, -0.023108506575226784, 0.005936837289482355, 0.017689352855086327, 0.011102656833827496, 0.02795490436255932, 0.010177435353398323, 0.017766453325748444, -0.0011400049552321434, -0.003320883959531784, -0.015310212038457394, -0.010375697165727615, 0.010557437315583229, -0.006239737384021282, 0.01958385296165943, -0.030201870948076248, 0.005631183739751577, 0.0052924868650734425, 0.010964975692331791, -0.0161583311855793, -0.002394285751506686, -0.009863520972430706, 0.011950776912271976, 0.032206516712903976, -0.004248858895152807, 0.014792528003454208, -0.024143872782588005, 0.009687288664281368, -0.04271438717842102, 0.0032547968439757824, 0.02210618369281292, -0.015497459098696709, -0.008497717790305614, 0.027139827609062195, -0.020244725048542023, 0.013283535838127136, 0.013470782898366451, 0.010722655802965164, 0.0444767139852047, 0.012997157871723175, -0.009466997347772121, -0.009147576056420803, -0.01201686356216669, 0.009235692210495472, -0.02070733718574047, -0.002406677231192589, -0.014451077207922935, -0.021985024213790894, -0.008751052431762218, 0.01054091565310955, -0.018162976950407028, 0.001037432113662362, 0.004020307213068008, 0.0332639142870903, 0.010970482602715492, 0.013503827154636383, -0.005366834811866283, -0.006586695555597544, -0.010028739459812641, 0.021489368751645088, -0.016786159947514534, -0.011097149923443794, -0.012270198203623295, 0.02107081562280655, 0.0029326213989406824, 0.002171241445466876, -0.0031088541727513075, 0.009373374283313751, 0.013878321275115013, -0.0019096459727734327, 0.013096288777887821, -0.009819462895393372, 0.035753197968006134, 0.0013320710277184844, 0.0030289986170828342, -0.012589620426297188, -0.016786159947514534, -0.0037724801804870367, 0.017292829230427742, -0.024650542065501213, -0.017369931563735008, -0.021202990785241127, -0.008018585853278637, 0.006917131599038839, 0.0028500123880803585, -0.01836123876273632, 0.014935716986656189, 0.0036375520285218954, -0.00997366663068533, 0.03960828855633736, -0.005256689619272947, 0.005788140930235386, 0.020861539989709854, 0.013591943308711052, 0.007104378659278154, 0.0022992854937911034, -0.01844935491681099, 0.00207211053930223, -0.011009033769369125, -0.03077462688088417, 0.0021602266933768988, 0.024760687723755836, -0.008420616388320923, -0.011488165706396103, 0.023064447566866875, -0.03564305230975151, 0.04187728464603424, 0.029452882707118988, 0.0063608973287045956, 0.026500985026359558, -0.024562425911426544, 0.03914567828178406, -0.0027013160288333893, 0.005969881080091, -0.007677135057747364, 0.019143272191286087, -0.0052291532047092915, -0.015156008303165436, 0.0014552961802110076, -0.014429048635065556, -5.5545984650962055e-05, -0.013691074214875698, 0.010485842823982239, 0.00018982873007189482, -0.01295309979468584, -0.0009782288689166307, -0.014737455174326897, -0.025069095194339752, 0.015728764235973358, -0.012115994468331337, 0.004290163516998291, 0.0019234141800552607, 0.02791084535419941, 0.008470181375741959, 0.002339213155210018, -0.024231988936662674, -0.02782272920012474, 0.006707855500280857, -0.0058707501739263535, 0.011807587929069996, 0.012997157871723175, -0.02758041024208069, 0.0071924952790141106, 0.02112588845193386, -0.0034365367610007524, -0.019881246611475945, -0.02590619958937168, -0.01647775247693062, -0.02324068173766136, -0.01883486472070217, 0.018625589087605476, -0.027976933866739273, 0.008260905742645264, -0.013151361607015133, 0.013426724821329117, 0.001555803930386901, -0.07714584469795227, -0.008888734504580498, 0.01293107122182846, -0.025884170085191727, -0.016312533989548683, 0.007264089770615101, 0.0008205832564271986, 0.02993752248585224, 0.030972888693213463, 0.023901553824543953, 0.009802941232919693, 0.03203028440475464, 0.00815076008439064, 0.05185645818710327, -0.020861539989709854, -0.011840631254017353, 0.021048787981271744, 0.022304445505142212, -0.0030317523051053286, -0.006680319085717201, 0.03910161927342415, 0.008354528807103634, 0.0009699679794721305, -0.0032603039871901274, -0.004477411042898893, 0.01107512041926384, -0.008002064190804958, -0.006724377162754536, -0.008629892952740192, -0.011300918646156788, 0.009455983527004719, -0.005388863850384951, -0.0229543037712574, 0.006267273798584938, -0.016334563493728638, 0.030620424076914787, 0.015904996544122696, -0.02674330584704876, -0.01672007329761982, -0.018482400104403496, 0.016609927639365196, 0.009274243377149105, -0.012776867486536503, -0.022689953446388245, -0.029386794194579124, 0.006338868290185928, 0.007555975113064051, 0.013591943308711052, -0.007302640471607447, 0.009786419570446014, -0.01107512041926384, 0.014528179541230202, 0.018978053703904152, 0.017028480768203735, -0.022216329351067543, -0.030466219410300255, 0.04612889513373375, 0.0055430675856769085, -0.0031281295232474804, -0.01713862456381321, -0.012909041717648506, 0.014065568335354328, 0.00822235457599163, 0.0007145683048292994, -0.0030124769546091557, -0.00794148351997137, 0.02777867205440998, 0.037779875099658966, -0.005716546438634396, 0.006091041024774313, -0.018295152112841606, -0.004805093631148338, 0.012644692324101925, 0.013239477761089802, -0.007803801912814379, 0.005218138452619314, 0.006994233466684818, -0.02262386679649353, 0.021698644384741783, 0.006652782671153545, 0.010210479609668255, -0.0033318984787911177, 0.004909731447696686, -0.02482677437365055, -0.014869630336761475, -0.00878409668803215, 0.007677135057747364, 0.003475087694823742, -0.006338868290185928, -0.008899749256670475, 0.0033263913355767727, 0.0191983450204134, 0.03740537911653519, 0.01505687739700079, -0.014781513251364231, 0.0037642193492501974, 0.024231988936662674, 0.03147955611348152, 0.013206434436142445, 0.008789603598415852, 0.010887873359024525, 0.0010876859305426478, -0.006421477068215609, 0.0010333015816286206, 0.0031226223800331354, 0.002106530824676156, -0.0056064012460410595, 0.00962120108306408, 0.016466738656163216, 0.037119001150131226, -0.005421907640993595, 0.0035852331202477217, 0.0013114187167957425, 0.03967437520623207, -0.004926253575831652, 0.01779949851334095, -0.002855519764125347, -0.0175681933760643, 0.013669044710695744, -0.010061782784759998, 0.019231388345360756, 0.005587125662714243, 0.015244124457240105, -0.01432991772890091, 0.0019082691287621856, -0.005030891392379999, 0.011333961971104145, 0.010959467850625515, -0.006096548400819302, 0.014208757318556309, -0.02239256165921688, 0.020167624577879906, 0.02018965408205986, -0.003816538257524371, -0.02116994746029377, -0.016103258356451988, -0.02786678820848465, 0.0002942947612609714, -0.011741500347852707, 0.02233748883008957, -0.041568875312805176, 0.020619221031665802, 0.013096288777887821, -0.01266672182828188, 0.0052291532047092915, 0.014462091960012913, 0.004039582796394825, -0.017336886376142502, -0.010182943195104599, -0.0217867624014616, -0.0034916093572974205, -0.005523792002350092, -0.02107081562280655, 0.004642629064619541, 0.008299456909298897, -0.01243541669100523, -0.003579725744202733, -0.005364081356674433, -0.007710178382694721, 0.015772823244333267, 0.017391959205269814, 0.009422939270734787, -0.0008908009622246027, -0.012975129298865795, -0.02786678820848465, -0.0077707585878670216, 0.011785558424890041, -0.005127268843352795, 0.012259183451533318, -0.009500041604042053, 0.01592702604830265, 0.017546163871884346, 0.0032603039871901274, 0.029540998861193657, -0.012501503340899944, -0.0009885550243780017, -0.035907402634620667, 0.0012721794191747904, 0.0035824794322252274, -0.014186728745698929, -0.017436018213629723, 0.0030042158905416727, -0.010623524896800518, -0.018933994695544243, 0.010975989513099194, -0.02848360314965248, -0.009356852620840073, 0.007214524317532778, 0.0035549430176615715, 0.02017863839864731, 0.006487564649432898, -0.0028637805953621864, 0.015486444346606731, -0.0229543037712574, -0.011212802492082119, -0.014010495506227016, -0.01882385089993477, 0.012104980647563934, -0.000695637078024447, 0.014131655916571617, -0.012556576170027256, 0.005716546438634396, -0.0010594611521810293, -0.019594868645071983, 0.02557576447725296, 0.0022373285610228777, -0.0245844554156065, 0.002107907785102725, 0.008938299492001534, 0.006052490323781967, 0.006652782671153545, 0.012512518092989922, 0.018140949308872223, -0.005372342187911272, -0.014528179541230202, -0.006289302837103605, -0.0077872802503407, -0.01360295806080103, 0.008960328996181488, 0.013030202127993107, -0.01075019221752882, 0.006773942615836859, -0.037493497133255005, 0.0038192919455468655, 0.011422079056501389, -0.0074678584933280945, -0.017920657992362976, 0.01582789421081543, 0.006151621229946613, 0.012281212955713272, 0.001926167868077755, 0.011212802492082119, -0.00857482012361288, 0.019826173782348633, 0.015189051628112793, 0.003954220097512007, -0.0008694602875038981, -0.011675412766635418, 0.0046508898958563805, 0.005518285091966391, 0.0015227602561935782, 0.012898026965558529, 0.012248169630765915, 0.025597792118787766, -0.022976331412792206, -0.0028665342833846807, -0.011333961971104145, -0.02291024476289749, 0.017083553597331047, 0.027668526396155357, -0.01658789813518524, 0.005655966699123383, -0.004984079860150814, -0.004879441577941179, -0.01723775640130043, 0.006454520858824253, -0.0002080715639749542, -0.0012267444981262088, -0.006933653261512518, 0.0009734100312925875, 0.01301918737590313, 0.019231388345360756, -0.006338868290185928, -0.003510884940624237, -0.004835383500903845, 0.01409861259162426, -0.007148436736315489, 0.013107303529977798, 0.013008172623813152, 0.002644866704940796, -0.01391136460006237, 0.0096046794205904, 0.01330556534230709, 0.023549087345600128, -0.012369329109787941, -0.00044299106230027974, -0.009968159720301628, -0.0030289986170828342, 0.009483519941568375, -0.027139827609062195, -0.043771784752607346, 0.0016879783943295479, -0.015607603825628757, 0.014660353772342205, 0.0045875562354922295, 0.001409861259162426, -0.01278788223862648, -0.009962651878595352, 0.0008570689242333174, -0.009846999309957027, -0.01911022886633873, -0.006928146351128817, 1.742534732329659e-05, 0.01482557225972414, 0.024474309757351875, 0.008376558311283588, -0.008437138050794601, 0.005300747696310282, -0.0083104707300663, -0.0013072883011773229, -0.02116994746029377, 0.006784956902265549, -0.012898026965558529, -0.009522070176899433, 0.017964715138077736, 0.008470181375741959, 0.013107303529977798, -0.020784437656402588, 0.01149918045848608, -0.0023199375718832016, 0.004328714683651924, -0.018625589087605476, -0.01911022886633873, 0.005248428788036108, -0.0020968932658433914, -0.0013196796644479036, -0.00676843523979187, 0.014539193361997604, 0.006906116846948862, -0.006504086311906576, 0.024430250748991966, 0.017997760325670242, -0.012402372434735298, -0.013900350779294968, -0.0025774026289582253, 0.03546682000160217, 0.0003517768927849829, 6.397899414878339e-05, -0.014296873472630978, -0.010573958978056908, 0.003615522990003228, -0.00647654989734292, -0.001037432113662362, -0.0019068924011662602, 0.006190171930938959, -0.00042991130612790585, 0.01063453871756792, 0.0010966352419927716, 0.016169345006346703, 0.00047534628538414836, 0.0013389551313593984, 0.017116596922278404, 0.018416311591863632, 0.0074678584933280945, -0.002538851695135236, -0.025928229093551636, 0.015860939398407936, 0.00414697453379631, 2.689096800168045e-05, 0.014572237618267536, 0.015629632398486137, -0.012831940315663815, 0.01049134973436594, 0.010744684375822544, 0.01699543558061123, -0.002520953072234988, -0.014957746490836143, -0.00559814041480422, 0.003565957536920905, 0.020255740731954575, 0.0037284221034497023, 0.022844158113002777, -0.01761225052177906, -0.0002667584049049765, 0.0030317523051053286, -0.02561982162296772, 0.01301918737590313, -0.01056294422596693, -0.00894380733370781, -0.02973926067352295, 0.014032525010406971, -0.008244384080171585, -0.004692194517701864, 0.007699164096266031, 0.015993112698197365, 0.003384217619895935, -0.004929007031023502, -0.001737543847411871, 0.0036100156139582396, 0.001955081010237336, -0.0018531965324655175, 0.024099815636873245, -0.008778588846325874, -0.023152563720941544, 0.008343514986336231, 0.015122964046895504, 0.01588296703994274, -0.01432991772890091, 0.01700645126402378, -0.026853449642658234, 0.00823887623846531, 0.005452197510749102, -0.012138023972511292, -0.002078994642943144, 0.003202477702870965, -0.009891057386994362, 0.011609326116740704, 0.016235433518886566, 0.001305223093368113, -0.02890215441584587, -0.009075981564819813, 0.02773461304605007, 0.006966697052121162, 0.007726700510829687, -0.0017816019244492054, 0.008338007144629955, 0.014748469926416874, -0.008354528807103634, 0.014902673661708832, 0.008817140012979507, 0.022095168009400368, -0.008998880162835121, 0.012699765153229237, -0.003334652166813612, -0.004560019820928574, -0.010728162713348866, 0.0011620339937508106, -0.02215024083852768, 0.004912485368549824, 0.010028739459812641, 0.021368209272623062, -0.004846397787332535, -0.019561823457479477, 0.018559500575065613, -0.016147317364811897, 0.005295240320265293, 0.014340932480990887, 0.005050166975706816, 0.004314946476370096, -0.0073907566256821156, -0.018482400104403496, 0.0017031233292073011, -0.024672571569681168, 0.008657429367303848, -0.01435194630175829, 0.0014690643874928355, -0.029188532382249832, 0.03317579627037048, 0.024143872782588005, 0.008172789588570595, 0.0010450045811012387, -0.008938299492001534, -0.014528179541230202, -0.005496256053447723, -0.0016700797714293003, -0.006471042521297932, 0.002288270741701126, 0.030796656385064125, -0.0006178469047881663, -0.010849322192370892, -0.0011744253570213914, 0.005964373704046011, 0.01844935491681099, -2.112554466293659e-05, -0.013834263198077679, -0.01534325536340475, 0.021985024213790894, -0.01663195714354515, 0.001478702062740922, 0.016797173768281937, -0.01915428601205349, -0.009053952060639858, 0.0032823330257087946, -0.0022621112875640392, 0.011064106598496437, -0.014682382345199585, 0.026258664205670357, -0.03394681587815285, -0.010072797536849976, 0.011455122381448746, -0.01980414427816868, -0.004394801799207926, -0.008046122267842293, -0.021423282101750374, 0.0075174239464104176, -0.01746906153857708, -0.02324068173766136, -0.01084381528198719, 0.002128560096025467, -0.03462971746921539, -0.00502263056114316, -0.02065226435661316, -0.008178296498954296, -0.019848203286528587, -0.016841232776641846, -8.940709085436538e-05, 0.014175713993608952, 0.01330556534230709, -0.019418634474277496, -0.003780741011723876, 0.009312794543802738, -0.003543928498402238, -0.000927975052036345, -0.005986402742564678, 0.013206434436142445, 0.00034540912020020187, 0.0061846645548939705, -0.00713191507384181, 0.00019705701561179012, 0.029144475236535072, -0.025972286239266396, -0.010816278867423534, -0.013492812402546406, 0.013492812402546406, 0.007572496775537729, -0.008822646923363209, 0.0017554424703121185, 0.01929747499525547, 0.0036375520285218954, 0.008844676427543163, 0.006680319085717201, -0.0166209414601326, -0.006426984444260597, 0.00748438062146306, 0.0007448582910001278, 0.0010112725431099534, 0.032669126987457275, -0.009544099681079388, -0.005969881080091, -0.01638963632285595, -0.01536528393626213, -0.010513379238545895, -0.01128990389406681, 0.01761225052177906, 0.006680319085717201, -0.022370532155036926, 0.031545646488666534, -0.009356852620840073, 0.003959727473556995, 0.016103258356451988, -0.006013939157128334, 0.009698303416371346, 0.005052920430898666, -0.009075981564819813, -0.013470782898366451, -0.02291024476289749, 0.014164699241518974, -0.014539193361997604, -0.003888132981956005, 0.0217867624014616, 0.0030675495509058237, -0.009869028814136982, 0.000650890520773828, 0.02299836091697216, -0.018911967054009438, 0.008035107515752316, -0.004543498158454895, -0.01149918045848608, -0.0028637805953621864, 0.006118577439337969, 0.0054824878461658955, -0.017689352855086327, -0.008723516017198563, -0.023262709379196167, -0.012754837982356548, 0.007726700510829687, 0.002666895743459463, 0.006261766422539949, -0.00044092582538723946, 0.0024961703456938267, -0.030289987102150917, 0.009571636095643044, -0.030884772539138794, -0.0016590652521699667, -0.004303931724280119, 0.015133978798985481, -0.003915669396519661, 0.005196109414100647, -0.011521209962666035, 0.018196022137999535, -0.0060469829477369785, 0.033418115228414536, -0.038859300315380096, 0.026434898376464844, -0.007974527776241302, -0.007561482023447752, 0.007561482023447752, 0.015034847892820835, -0.00353016029112041, -0.027998963370919228, 0.0016576884081587195, -0.010854830034077168, 0.006283795461058617, -0.009345837868750095, -0.02197400853037834, -0.021412266418337822, 0.016147317364811897, -0.005047413520514965, -0.00852525420486927, 0.009654245339334011, -0.006669304333627224, 0.007236553356051445, 0.009659752249717712, -0.01774442568421364, -0.020586175844073296, -0.010766713880002499, 0.018900951370596886, -0.015133978798985481, 0.0021891400683671236, 0.0019633418414741755, -0.006537130102515221, -0.0013726871693506837, -0.011344976723194122, 0.00185595010407269, 0.016191374510526657, 0.0014608034398406744, 0.004571034573018551, 0.03035607375204563, -0.005614662077277899, 0.018383268266916275, 0.017116596922278404, -0.01534325536340475, 0.004303931724280119, 0.00290508521720767, -0.03855089098215103, -0.01424180157482624, -0.003692624857649207, 0.016103258356451988, -0.02586214244365692, 0.00741278612986207, -0.0016411665128543973, 0.016709057614207268, -0.020817482843995094, -0.0043837870471179485, 0.012149038724601269, -0.005887271836400032, 0.007258582394570112, -0.01771138235926628, 0.008040614426136017, 0.011064106598496437, 0.012171067297458649, -0.031259264796972275, -0.005262196995317936, -0.01643369533121586, -0.0014415279729291797, 0.009334823116660118, 0.01774442568421364, 0.0070768422447144985, 0.01522209495306015, -0.012424401938915253, -0.0020349363330751657, 0.0010202218545600772, 0.008101195096969604, -0.0016384129412472248, 0.024231988936662674, 0.020762410014867783, 0.011322948150336742, -0.02965114451944828, 0.002197400899603963, -0.006999740842729807, -0.01821804977953434, -0.0005342052318155766, -0.005521038547158241, -0.005460458341985941, 0.0006684449617750943, 0.019187329337000847, 0.01295309979468584, 0.002580156084150076, -0.009274243377149105, -0.02707374095916748, 0.019936319440603256, 0.008569312281906605, 0.004532483406364918, -0.02144531160593033, -0.007385249715298414, 0.002957404125481844, -0.020960671827197075, 0.008481196127831936, 0.00457929540425539, -0.007660612929612398, 0.002855519764125347, -0.005146543961018324, -4.2014449718408287e-05, -0.011400049552321434, 0.0005820496589876711, -0.004400309175252914, 0.0009665259276516736, 0.002176748588681221, -0.020035449415445328, 0.0038220456335693598, 0.01332759391516447, -0.02848360314965248, 3.2097061193780974e-05, 0.043485406786203384, -0.00771568575873971, 0.017909644171595573, 0.005694517400115728, 0.0120609225705266, 0.01939660683274269, -0.01742500253021717, 0.006746406201273203, -0.02056414820253849, -0.002979433164000511, -0.018669646233320236, 0.004116684664040804, 0.002402546815574169, -0.014814557507634163, 0.0063719116151332855, -0.022051110863685608, 0.0014002234674990177, -0.01573977805674076, -0.006008431781083345, -0.009307286702096462, 0.0012067806674167514, -0.00221942993812263, -0.00537509610876441, -0.006008431781083345, -0.03236072137951851, 0.036039575934410095, -0.007693656720221043, -0.026170548051595688, -0.016598913818597794, -0.008723516017198563, -0.028065050020813942, 0.012049907818436623, 0.0021657340694218874, -0.01938559114933014, 0.011554253287613392, -0.003084071446210146, 0.02702968381345272, 0.008673951029777527, -0.011521209962666035, 0.01630152016878128, -0.0003287151921540499, 0.015916012227535248, 0.003744943765923381, -0.005636691115796566, -0.013239477761089802, 0.015717750415205956, 0.024518366903066635, 0.0113559914752841, 0.01728181354701519, -0.0011654760455712676, -0.005705532152205706, 0.006790464278310537, 0.01470441184937954, -0.008795110508799553, 0.01812993362545967, -0.013547885231673717, -0.009197141975164413, 0.008756560273468494, 0.0075174239464104176, -0.015475429594516754, 0.018295152112841606, -0.01621340401470661, -0.02122502028942108, 0.0095991725102067, -0.0008729023393243551, 0.013492812402546406, 0.00436726538464427, -0.014175713993608952, 0.012424401938915253, 0.013988466933369637, -0.004884948953986168, 0.01496876124292612, 0.0018463124288246036, -0.012281212955713272, 0.013790205121040344, -0.030510278418660164, 0.016290506348013878, -0.003370449412614107, -0.01351484190672636, 0.000799242639914155, 0.027712585404515266, -0.004273641854524612, 0.012853968888521194, -0.01672007329761982, -0.018746748566627502, 0.012325271032750607, -0.0028637805953621864, 0.00668582646176219, -0.02960708551108837, 0.008954822085797787, 0.0025512429419904947, -0.012380343861877918, 0.00910902488976717, 0.022734012454748154, 0.004493932705372572, 0.0054659657180309296, 0.00896583590656519, -0.000553136458620429, 0.004794078879058361, -0.022734012454748154, -0.0013644262216985226, -0.009869028814136982, 0.026567071676254272, 0.01728181354701519, -0.001077359775081277, -0.006515101063996553, 0.0035274066030979156, 0.004857412539422512, 0.00581017043441534, -0.008035107515752316, -0.025311414152383804, 0.016268476843833923, -0.030664481222629547, -0.01266672182828188, 0.011411064304411411, -0.007462351582944393, -0.0035962476395070553, 0.01229222770780325, -0.01243541669100523, 0.013063245452940464, 0.00894380733370781, 0.006895102560520172, 0.022822128608822823, 5.064107244834304e-05, 0.009031923487782478, -0.01041975524276495, -0.017909644171595573, -0.01374614704400301, 0.0016246447339653969, -0.009384389035403728, -0.00014413558528758585, 0.008420616388320923, 0.005127268843352795, 0.0031005931086838245, 0.0060579972341656685, -0.0005417776992544532, 0.003744943765923381, -0.012490489520132542, -0.026567071676254272, 0.015244124457240105, -0.011455122381448746, -0.010640046559274197, -0.028836067765951157, -0.006338868290185928, 0.024716628715395927, 0.03328594192862511, -0.030554335564374924, 0.009433954022824764, -0.0004602012922987342, -0.015728764235973358, 0.027756642550230026, -0.005350313149392605, -0.008679457940161228, 0.0017568191979080439, -0.0038000165950506926, -0.005936837289482355, 0.0008419239311479032, -0.010799757204949856, -0.013966437429189682, 0.013217449188232422, 0.015122964046895504, -0.026258664205670357, -0.00028603384271264076, 0.0014594265958294272, 0.017810512334108353, 0.002742620650678873, -0.013239477761089802, 0.012699765153229237, -0.013724117539823055, 0.01231425628066063, -0.01709456741809845, 0.009296271950006485, -0.003271318506449461, 0.019682984799146652, 0.0005545133026316762, -0.00509422505274415, 0.015486444346606731, 0.0005441871471703053, -0.016147317364811897, -0.014935716986656189, -0.017017465084791183, 0.008117716759443283, -0.006239737384021282, 0.010386711917817593, 0.0014126148307695985, -0.006487564649432898, -0.00962120108306408, 0.02337285503745079, 0.005058427806943655, -0.02590619958937168, 0.013096288777887821, -0.0096046794205904, 0.019220374524593353, 0.005138283129781485, -0.0014690643874928355, -0.014418033882975578, 0.005273211281746626, -0.024187931790947914, -0.008828154765069485, -0.010904395021498203, -0.015475429594516754, 0.01676413044333458, -0.010204971767961979, -0.009191634133458138, 0.005581618752330542, -9.874363968265243e-06, 0.01339368149638176, -0.004995094146579504, -0.012071936391294003, -0.010684104636311531, -0.010425263084471226, 0.019660955294966698, -0.01869167573750019, 0.0007510539726354182, 0.010551930405199528, 0.005325530655682087, -0.0036953783128410578, 0.01397745218127966, -0.023483000695705414, 0.018008774146437645, -0.0032603039871901274, -0.010717147961258888, -0.01658789813518524, 0.015772823244333267, 0.012248169630765915, -0.00903743039816618, -0.008343514986336231, -0.01676413044333458, -0.0035411748103797436, -0.011157729662954807, -0.0009816709207370877, -0.011807587929069996, -0.017920657992362976, 0.014594266191124916, 0.004350743722170591, 0.01568470522761345, 0.0007338437717407942, -0.02177574671804905, -0.005262196995317936, 0.014572237618267536, 0.015849923714995384, 0.016378622502088547, 0.024099815636873245, -0.024936920031905174, -0.0011723601492121816, 0.024804744869470596, 0.007737714797258377, -0.0005534806987270713, -0.00015067547792568803, -0.01293107122182846, 0.034673772752285004, 0.016929348930716515, -0.0013334478717297316, 0.017204713076353073, 0.014869630336761475, 0.005914808250963688, -0.005620169453322887, 0.027470264583826065, -0.0035274066030979156, -0.026567071676254272, -0.019363563507795334, -0.01788761466741562, -0.005270457826554775, 0.012545562349259853, 0.00229515484534204, -0.0006147490348666906, -0.014605280943214893, -0.028351427987217903, 0.004199293442070484, 0.023571116849780083, 0.004705962724983692, -0.0008357283077202737, -0.02088356949388981, -0.008167281746864319, -0.022326475009322166, 0.01892298087477684, -0.019495736807584763, 0.01243541669100523, -0.0008033730555325747, -0.013426724821329117, 0.013525855727493763, -0.007836845703423023, -0.03253695368766785, -0.0004987521679140627, -0.01070062629878521, 0.013713102787733078, -0.006784956902265549, -0.016521811485290527, -0.015860939398407936, -0.015122964046895504, -0.0024466048926115036, 0.028373457491397858, 0.007489887531846762, 0.0012597880559042096, -0.009869028814136982, 0.007858875207602978, -0.024650542065501213, 0.013580928556621075, -0.001207469031214714, 0.00822235457599163, -0.01229222770780325, -0.00488219503313303, -0.005766111891716719, 0.024099815636873245, -0.007489887531846762, 0.003252043155953288, 0.005218138452619314, 0.010942946188151836, -0.001667326083406806, -0.007264089770615101, 0.03804422542452812, 0.018471384420990944, 0.008767574094235897, 0.009995696134865284, -0.027007654309272766, -0.010309610515832901, 0.0002987694169860333, -0.006944668013602495, 0.0070658279582858086, -0.02238154597580433, 0.031920138746500015, -0.013966437429189682, 0.011939762160182, 0.0016494274605065584, 0.01902211271226406, 0.005058427806943655, 0.005942344665527344, -0.0008784095989540219, -0.008376558311283588, -0.0058707501739263535, -0.006746406201273203, -0.00022751910728402436, -0.005168573465198278, 0.017116596922278404, -0.007924961857497692, 0.005231906659901142, 0.0021822559647262096, -0.014759484678506851, 0.010854830034077168, -0.019077183678746223, 0.0196719691157341, 0.008398586884140968, -0.017028480768203735, -0.01185164600610733, 0.0017251524841412902, -0.029298678040504456, -0.005766111891716719, 0.0005011616158299148, 0.0025526199024170637, -0.015938039869070053, 0.02528938464820385, -0.009505548514425755, -0.01187367457896471, -0.03368246555328369, -0.0019839941523969173, 0.00639394111931324, 0.024320105090737343, 0.02449633926153183, 0.0024452279321849346, 0.011455122381448746, -0.012104980647563934, -0.012997157871723175, 0.02163255773484707, 0.019418634474277496, 0.00675742095336318, 0.012545562349259853, -0.008227861486375332, -0.013173391111195087, -0.0064490134827792645, -0.00530625507235527, -0.011212802492082119, 0.014429048635065556, -0.015497459098696709, -0.01278788223862648, 0.004276395309716463, -0.0071429298259317875, 0.007902933284640312, -0.001939935958944261, 0.026919538155198097, 0.015508472919464111, -0.01126787532120943, -0.014913688413798809, -0.006586695555597544, 0.00028500123880803585, -0.017391959205269814, 0.016543840989470482, -0.019088199362158775, -0.01771138235926628, 0.011917732656002045, -0.026302723214030266, 0.011322948150336742, 2.8913169444422238e-05, 0.01755717769265175, 0.031016945838928223, -0.02093864232301712, -0.0012873244704678655, 0.007958006113767624, -0.010502364486455917, -0.0027398669626563787, 0.0009610186680220068, -0.0031005931086838245, -0.001206092187203467, 0.008299456909298897, -0.009676273912191391, 0.015464414842426777, 0.008172789588570595, -0.011510195210576057, 0.0032465357799082994, -0.017491091042757034, 0.005369588732719421, 0.01624644733965397, -0.015045862644910812, -0.008740037679672241, 0.0007538076606579125, -0.008530762046575546, -0.010133377276360989, -0.0054466906003654, -0.005471473094075918, 0.022976331412792206, 0.0015475429827347398, 0.0031997240148484707, -0.00794148351997137, -0.036458130925893784, -0.0005496944067999721, -0.016665000468492508, -0.01360295806080103, 0.004317699931561947, 0.026148520410060883, -0.01887892372906208, 0.006542637012898922, -0.01690731942653656, -0.006950175389647484, 0.00028431284590624273, 0.00974236149340868, -0.01961689628660679, 0.018284138292074203, -0.0012233024463057518, -0.020674293860793114, -0.015706734731793404, 0.01925341784954071, -0.002127183135598898, -0.004408570006489754, -0.02819722518324852, 0.00894931424409151, -0.0002772566513158381, -0.010127870365977287, 0.029629115015268326, 0.01098149735480547, -0.0057936483062803745, 0.014682382345199585, -0.019462693482637405, -0.005011615809053183, 0.006179157178848982, 0.0002757077163551003, -0.026104461401700974, 0.03317579627037048, -0.009164097718894482, -0.017226742580533028, 0.019605882465839386, -0.005925823003053665, -0.010992512106895447, 0.012104980647563934, -0.006256259046494961, 0.04088597372174263, 0.0014181220903992653, -0.014043539762496948, -0.0011978313559666276, 0.005683503113687038, 0.024342134594917297, -0.004832629580050707, -0.0014773253351449966, -0.02365923300385475, 0.0063113318756222725, 0.007247567642480135, -0.0061240848153829575, -0.009208155795931816, -0.021665601059794426, -0.022822128608822823, -0.0009004386956803501, -0.01892298087477684, 0.003692624857649207, 0.016323549672961235, -0.00894380733370781, 0.030289987102150917, -0.0002963599981740117, 0.007253075018525124, -3.7561305362032726e-05, 0.017061524093151093, 0.006619738880544901, -0.008811632171273232, -0.02299836091697216, -0.00822235457599163, 0.014186728745698929, 0.014726441353559494, 0.012479474768042564, 0.007754236459732056, -0.006212200969457626, -0.0024947933852672577, 0.02163255773484707, -0.005672488361597061, 0.006300317123532295, -0.015475429594516754, -0.0031804486643522978, 0.01032613217830658, -0.0008722139173187315, -0.005592633038759232, 0.014594266191124916, -0.004202047362923622, 0.007765251211822033, -0.011807587929069996, 0.004727991763502359, -0.0054797339253127575, -0.019925303757190704, 0.00037621540832333267, -0.014131655916571617, 0.012468460015952587, 0.01877979189157486, 0.02032182738184929, -0.0002373289316892624, 0.016367606818675995, 0.006069011986255646, -0.0037339292466640472, 0.009433954022824764, 0.0036403057165443897, -0.005435675848275423, -0.002233198145404458, -0.01054091565310955, 0.006316839251667261, -0.011609326116740704, -0.0012191720306873322, 0.012776867486536503, 0.0037587119732052088, -0.013834263198077679, -0.015508472919464111, -0.027051711454987526, 0.02324068173766136, -0.011455122381448746, 0.018669646233320236, -0.017270799726247787, -0.007093364372849464, 0.009731346741318703, 0.008998880162835121, -0.0021616036538034678, -0.0007661989657208323, -0.007291626185178757, 0.012710779905319214, 0.02553170546889305, 0.00969279557466507, -0.01658789813518524, -0.020222697407007217, -0.0007173219928517938, -0.024760687723755836, -0.0035411748103797436, 0.00114757742267102, -0.006961189676076174, -0.008541776798665524, 0.005556835792958736, -0.009114532731473446, 0.007991049438714981, -0.002157473238185048, -0.020487045869231224, -0.02782272920012474, -0.015045862644910812, 0.002303415909409523, -0.00508321076631546, -0.004265381023287773, 4.216504021314904e-05, 0.007671627681702375, -0.007302640471607447, -0.022425604984164238, 0.02052008919417858, -0.0035769720561802387, 0.01424180157482624, 0.024738658219575882, -0.008767574094235897, 0.01170845702290535, -0.012501503340899944, 0.0021450817584991455, -0.01681920327246189, 0.011554253287613392, 0.0011689180973917246, 0.019363563507795334, 0.016698043793439865, 0.0313694104552269, 0.011009033769369125, 0.0011331208515912294, 0.015949055552482605, 0.01318440493196249, 0.0184934139251709, -0.005044659599661827, 0.033043622970581055, -0.0077707585878670216, 0.003689871169626713, 0.008602356538176537, 0.014142670668661594, -0.02107081562280655, 0.007913947105407715, -0.005399878602474928, -0.01046932116150856, 0.011091642081737518, 0.0006264519761316478, 0.028549689799547195, -0.004876688122749329, -0.0028830559458583593, -0.010926424525678158, 0.02092762663960457, -0.010920916683971882, -0.0020666031632572412, -0.018427327275276184, -0.006415970157831907, -0.003990017343312502, -0.01990327425301075, -0.025685908272862434, -0.005837706383317709, 0.025928229093551636, -0.018185006454586983, 0.005614662077277899, 0.012115994468331337, 0.02056414820253849, 0.00043197651393711567, -0.008376558311283588, 0.0051024858839809895, -0.011697442270815372, 0.006443506106734276, -0.011422079056501389, 0.00083710509352386, -0.010507872328162193, -0.009202648885548115, -0.005421907640993595, -0.001542035723105073, 0.012710779905319214, -0.007710178382694721, -0.00038619732367806137, -0.01690731942653656, -0.02239256165921688, 0.01653282530605793, 0.010607002303004265, -0.030752597376704216, -0.021522412076592445, -2.1512775560950104e-08, 0.010458306409418583, 0.015805866569280624, -0.02716185711324215, -0.0003672660968732089, -0.007831338793039322, 0.015420356765389442, -0.0071429298259317875, 0.005441183224320412, 0.01201686356216669, 0.01906616985797882, 0.011653384193778038, 0.005432922393083572, 0.006795971654355526, 0.02125806361436844, 0.0029463896062225103, 0.017083553597331047, -0.025641851127147675, -0.025025036185979843, 0.0026765333022922277, -0.010942946188151836, 0.02324068173766136, 0.004182771779596806, -0.002653127536177635, 0.021852849051356316, 0.01435194630175829, 0.007611047476530075, 0.012677736580371857, 0.020762410014867783, -0.0024589961394667625, -0.008635399863123894, 0.020575162023305893, 0.0031584196258336306, -0.021511398255825043, 0.0025058079045265913, -0.016554854810237885, 0.010931931436061859, 0.024738658219575882, -0.021654587239027023, -0.0048023397102952, 0.0061075626872479916, -0.02266792394220829, 0.009042938239872456, 0.001423629350028932, -0.002971172332763672, 0.015673691406846046, 0.013404696248471737, -0.001263918587937951, -0.019055156037211418, -0.0007304017199203372, 0.002094139577820897, -0.018251093104481697, 0.003370449412614107, -0.0019716029055416584, -0.0007090610451996326, -0.0003610704152379185, 0.008497717790305614, -0.007842352613806725, 0.014175713993608952, -0.016455722972750664, 0.0004904912784695625, 0.019374577328562737, -0.01648876816034317, -0.0029849405400455, -0.016290506348013878, 0.00610205577686429, -0.011609326116740704, -0.01201686356216669, 0.004182771779596806, -0.029518969357013702, 0.00258704018779099, 0.02707374095916748, -0.0020129072945564985, -0.02586214244365692, 0.009720331989228725, 0.0061075626872479916, 0.0011420701630413532, 0.0030537813436239958, -0.011895704083144665, 0.01859254390001297, -0.005777126643806696, 0.00371190020814538, 0.010441784746944904, -0.013878321275115013, 0.0032603039871901274, 0.00852525420486927, 0.00713191507384181, -0.015453401021659374, -0.0407538004219532, -0.00668582646176219, 0.005512777715921402, -0.0018256601179018617, 0.015332240611314774, -0.01630152016878128, -0.006316839251667261, 0.00287479511462152, -0.005185095127671957, -0.01812993362545967, 0.008954822085797787, 0.003364942269399762, 0.014252815395593643, -0.006206693593412638, 0.0026352289132773876, 0.013052230700850487, 0.00057378871133551, -0.002085878746584058, -0.012160052545368671, 0.00159848527982831, -0.03216245770454407, -0.007214524317532778, -0.0039019009564071894, 0.001458049868233502, 0.014429048635065556, 0.00374219031073153, -0.006707855500280857, 0.0017912397161126137, 0.01728181354701519, 0.003775233868509531, -0.0022552271839231253, -0.025399530306458473, -0.006955682300031185, -0.015893982723355293, 2.06522645385121e-06, -0.008332500234246254, -0.025465618818998337, -0.0037091465201228857, -0.022227343171834946, -0.024738658219575882, 0.009577143006026745, 0.013217449188232422, -0.0033539277501404285, -0.004959296900779009, 0.027756642550230026, 0.01808587647974491, -0.007765251211822033, -0.011422079056501389, 0.024892862886190414, 0.003147405106574297, 0.005512777715921402, 0.0061846645548939705, 0.020806467160582542, 0.007401771377772093, 0.018350224941968918, -0.011829616501927376, 0.00969279557466507, 0.016609927639365196, -0.014065568335354328, 0.036039575934410095, 0.00214370503090322, 0.005567850545048714, 0.0023695030249655247, -0.009593664668500423, -0.03236072137951851, 0.011807587929069996, 0.003447551280260086, -0.009819462895393372, 0.010684104636311531, 0.011031062342226505, 0.004744513425976038, 0.0038275530096143484, -0.017997760325670242, 0.002030805917456746, 0.020641248673200607, 0.015332240611314774, 0.005107993260025978, -0.022139227017760277, 0.030003609135746956, -0.009362359531223774, 0.021621543914079666, 0.01084381528198719, -0.003084071446210146, -0.02720591612160206, 0.018889937549829483, 0.005127268843352795, -0.022689953446388245, 0.011884689331054688, 0.013316580094397068, 0.02665518783032894, 0.0014828325947746634, -0.004014800302684307, 0.0025980547070503235, -0.012358314357697964, 0.0019716029055416584, 0.014726441353559494, 0.01208295114338398, -0.01840529777109623, 0.006729884538799524, 0.017832541838288307, 0.005788140930235386, 0.017975730821490288, 0.0043204533867537975, -0.008762067183852196, 0.017491091042757034, -0.008998880162835121, 0.0070162625052034855, -0.0023075463250279427, -0.007682641968131065, -0.025091124698519707, 0.029430853202939034, 0.027294032275676727, 0.009031923487782478, 0.002266241703182459, -0.023813437670469284, 0.006713362410664558, 0.006922638975083828, 0.005011615809053183, 0.012215125374495983, -0.015860939398407936, 0.02089458331465721, -0.001576456124894321, -0.013702088966965675, 0.0014318902976810932, 0.0007097494672052562, -0.02121400460600853, 0.04209757596254349, -0.015563545748591423, 0.023989669978618622, 0.0048271226696670055, -0.0030537813436239958, -0.006647275295108557, -0.0030097232665866613, -0.01301918737590313, -0.00873453076928854, 0.012127009220421314, 0.006217708345502615, 0.016797173768281937, -0.020949656143784523, 0.0005080457194708288, 0.0035852331202477217, -0.006256259046494961, -0.01700645126402378, 0.015156008303165436, -0.028131136670708656, -0.0012666721595451236, 0.011400049552321434, -0.002017037710174918, -0.0036540739238262177, -0.017689352855086327, 0.00036933133378624916, 0.01114671491086483, -0.0038000165950506926, 0.017061524093151093, -0.012545562349259853, -0.0057440828531980515, 0.01126787532120943, 0.002463126787915826, 0.005887271836400032, -0.019000083208084106, 0.035665083676576614, 0.014142670668661594, -0.02762446738779545, -0.004653643351048231, 0.0024741413071751595, -0.011234831996262074, -0.027272002771496773, 0.004491178784519434, -0.020531103014945984, -0.020354870706796646, 0.024320105090737343, 0.028065050020813942, 0.004353497177362442, -0.01201686356216669, 0.0017816019244492054, -0.028395485132932663, 0.021412266418337822, 0.003549435641616583, -2.3427412088494748e-05, 0.01625746302306652, 0.0023502276744693518, -0.016609927639365196, -0.02969520166516304, -0.001799500547349453, -0.00021994661074131727, 0.009175112470984459, 0.0013541000662371516, 0.0020597190596163273, -0.005804663058370352, 0.01049134973436594, 0.018669646233320236, -0.006713362410664558, -0.0022510967683047056, -0.010920916683971882, 0.02023371122777462, 0.0028858096338808537, 0.012655707076191902, -0.02487083338201046, 0.018911967054009438, -0.010728162713348866, -0.03209637105464935, 0.007137422449886799, 0.0327792726457119, -0.03321985527873039, -0.0012728678993880749, 0.0013561652740463614, 0.011157729662954807, -0.0017003697576001287, -0.016312533989548683, -0.012215125374495983, -0.00553756020963192, -0.0031501585617661476, -0.012501503340899944, -0.004898717161267996, 0.021368209272623062, 0.026567071676254272, 0.03480594977736473, -0.018900951370596886, 0.020498059689998627, -0.009235692210495472, 0.010232508182525635, -0.021335165947675705, 0.025047065690159798, 0.002728852443397045, -0.003981756512075663, 0.0026682724710553885, 0.005460458341985941, 0.015728764235973358, -0.007302640471607447, 0.02969520166516304, -0.02570793777704239, 0.023769378662109375, -0.011047584004700184, -0.015651661902666092, -0.0021863863803446293, 0.0008481196127831936, -0.02641286887228489, 0.004898717161267996, 0.004471903666853905, -0.0024824021384119987, 0.0037697264924645424, -0.024562425911426544, 0.015960069373250008, 0.012534547597169876, -0.000857757346238941, -0.006652782671153545, -0.0021230527199804783, 0.0012515272246673703, 0.000427157647209242, 0.00633336091414094, -0.019077183678746223, -0.0241218451410532, -0.01719369739294052, -0.023064447566866875, 0.01114671491086483, 0.019782114773988724, 0.00035418631159700453, 0.02017863839864731, 0.00981395598500967, 0.00903743039816618, -0.023879524320364, 0.011322948150336742, -0.012237154878675938, -0.01245744526386261, -0.004020307213068008, 0.013624986633658409, 0.006168142892420292, 0.023593146353960037, -0.010012217797338963, -0.0022152995225042105, -0.023438943549990654, -0.0012838824186474085, -0.013790205121040344, 0.002468633931130171, -0.0006154374568723142, -0.0033539277501404285, -0.011411064304411411, -0.02324068173766136, 0.025047065690159798, -0.009175112470984459, -0.004893209785223007, -2.443851190037094e-05, -0.0005459081730805337, -0.005898286588490009], index=0, object='embedding')], model='text-embedding-3-large', object='list', usage=Usage(prompt_tokens=9, total_tokens=9))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.values[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXNHhRd9Pi8T",
        "outputId": "3e678fe1-e793-4051-f0aa-fa7186bfd757"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['417ede5d-39be-498f-b518-f47ed4e53b90',\n",
              "        array([-0.00876571, -0.02036799, -0.02046485, ...,  0.00973429,\n",
              "                0.0045489 , -0.00439323])                              ,\n",
              "        {'chunk': 0, 'text': '.rst\\n.pdf\\nWelcome to LangChain\\n Contents \\nGetting Started\\nModules\\nUse Cases\\nReference Docs\\nEcosystem\\nAdditional Resources\\nWelcome to LangChain#\\nLangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model, but will also be:\\nData-aware: connect a language model to other sources of data\\nAgentic: allow a language model to interact with its environment\\nThe LangChain framework is designed around these principles.\\nThis is the Python specific portion of the documentation. For a purely conceptual guide to LangChain, see here. For the JavaScript documentation, see here.\\nGetting Started#\\nHow to get started using LangChain to create an Language Model application.\\nQuickstart Guide\\nConcepts and terminology.\\nConcepts and terminology\\nTutorials created by community experts and presented on YouTube.\\nTutorials\\nModules#\\nThese modules are the core abstractions which we view as the building blocks of any LLM-powered application.\\nFor each module LangChain provides standard, extendable interfaces. LangChain also provides external integrations and even end-to-end implementations for off-the-shelf use.\\nThe docs for each module contain quickstart examples, how-to guides, reference docs, and conceptual guides.\\nThe modules are (from least to most complex):\\nModels: Supported model types and integrations.\\nPrompts: Prompt management, optimization, and serialization.\\nMemory: Memory refers to state that is persisted between calls of a chain/agent.\\nIndexes: Language models become much more powerful when combined with application-specific data - this module contains interfaces and integrations for loading, querying and updating external data.\\nChains: Chains are structured sequences of calls (to an LLM or to a different utility).\\nAgents: An agent is a Chain in which an LLM, given a high-level directive and a set of tools, repeatedly decides an action, executes the action and observes the outcome until the high-level directive is complete.\\nCallbacks: Callbacks let you log and stream the intermediate steps of any chain, making it easy to observe, debug, and evaluate the internals of an application.\\nUse Cases#\\nBest practices and built-in implementations for common LangChain use cases:', 'url': 'https://python.langchain.com/en/latest/index.html'}]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.values[:1]"
      ],
      "metadata": {
        "id": "M1SAIeDJVkrQ",
        "outputId": "70ff0cac-9ee7-4689-bd20-709c2fbf8f84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['417ede5d-39be-498f-b518-f47ed4e53b90',\n",
              "        array([-0.00876571, -0.02036799, -0.02046485, ...,  0.00973429,\n",
              "                0.0045489 , -0.00439323])                              ,\n",
              "        {'chunk': 0, 'text': '.rst\\n.pdf\\nWelcome to LangChain\\n Contents \\nGetting Started\\nModules\\nUse Cases\\nReference Docs\\nEcosystem\\nAdditional Resources\\nWelcome to LangChain#\\nLangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model, but will also be:\\nData-aware: connect a language model to other sources of data\\nAgentic: allow a language model to interact with its environment\\nThe LangChain framework is designed around these principles.\\nThis is the Python specific portion of the documentation. For a purely conceptual guide to LangChain, see here. For the JavaScript documentation, see here.\\nGetting Started#\\nHow to get started using LangChain to create an Language Model application.\\nQuickstart Guide\\nConcepts and terminology.\\nConcepts and terminology\\nTutorials created by community experts and presented on YouTube.\\nTutorials\\nModules#\\nThese modules are the core abstractions which we view as the building blocks of any LLM-powered application.\\nFor each module LangChain provides standard, extendable interfaces. LangChain also provides external integrations and even end-to-end implementations for off-the-shelf use.\\nThe docs for each module contain quickstart examples, how-to guides, reference docs, and conceptual guides.\\nThe modules are (from least to most complex):\\nModels: Supported model types and integrations.\\nPrompts: Prompt management, optimization, and serialization.\\nMemory: Memory refers to state that is persisted between calls of a chain/agent.\\nIndexes: Language models become much more powerful when combined with application-specific data - this module contains interfaces and integrations for loading, querying and updating external data.\\nChains: Chains are structured sequences of calls (to an LLM or to a different utility).\\nAgents: An agent is a Chain in which an LLM, given a high-level directive and a set of tools, repeatedly decides an action, executes the action and observes the outcome until the high-level directive is complete.\\nCallbacks: Callbacks let you log and stream the intermediate steps of any chain, making it easy to observe, debug, and evaluate the internals of an application.\\nUse Cases#\\nBest practices and built-in implementations for common LangChain use cases:', 'url': 'https://python.langchain.com/en/latest/index.html'}]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Iterate through the dataset and embed the metadata 'text'\n",
        "for i in range(len(df.values)):\n",
        "    text_value = df.metadata[i]['text']\n",
        "    print(text_value)\n",
        "    embedding_response = generate_embeddings(text_value)\n",
        "    new_val = np.array(embedding_response.data[0].embedding)\n",
        "    print(len(new_val), \" \", type(new_val))\n",
        "    df[\"values\"][i] = new_val\n",
        "\n",
        "# You can then use dataset2 as your embedded dataset.\n",
        "# For example, you could save it to a new file or upload it to a vector database.\n",
        "\n",
        "# Example: print the first 5 embeddings\n",
        "print(df.values[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRheFfL0OEr2",
        "outputId": "8cc1bf2c-1e10-407e-bf2c-fde1bb8bcd04"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".rst\n",
            ".pdf\n",
            "Welcome to LangChain\n",
            " Contents \n",
            "Getting Started\n",
            "Modules\n",
            "Use Cases\n",
            "Reference Docs\n",
            "Ecosystem\n",
            "Additional Resources\n",
            "Welcome to LangChain#\n",
            "LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model, but will also be:\n",
            "Data-aware: connect a language model to other sources of data\n",
            "Agentic: allow a language model to interact with its environment\n",
            "The LangChain framework is designed around these principles.\n",
            "This is the Python specific portion of the documentation. For a purely conceptual guide to LangChain, see here. For the JavaScript documentation, see here.\n",
            "Getting Started#\n",
            "How to get started using LangChain to create an Language Model application.\n",
            "Quickstart Guide\n",
            "Concepts and terminology.\n",
            "Concepts and terminology\n",
            "Tutorials created by community experts and presented on YouTube.\n",
            "Tutorials\n",
            "Modules#\n",
            "These modules are the core abstractions which we view as the building blocks of any LLM-powered application.\n",
            "For each module LangChain provides standard, extendable interfaces. LangChain also provides external integrations and even end-to-end implementations for off-the-shelf use.\n",
            "The docs for each module contain quickstart examples, how-to guides, reference docs, and conceptual guides.\n",
            "The modules are (from least to most complex):\n",
            "Models: Supported model types and integrations.\n",
            "Prompts: Prompt management, optimization, and serialization.\n",
            "Memory: Memory refers to state that is persisted between calls of a chain/agent.\n",
            "Indexes: Language models become much more powerful when combined with application-specific data - this module contains interfaces and integrations for loading, querying and updating external data.\n",
            "Chains: Chains are structured sequences of calls (to an LLM or to a different utility).\n",
            "Agents: An agent is a Chain in which an LLM, given a high-level directive and a set of tools, repeatedly decides an action, executes the action and observes the outcome until the high-level directive is complete.\n",
            "Callbacks: Callbacks let you log and stream the intermediate steps of any chain, making it easy to observe, debug, and evaluate the internals of an application.\n",
            "Use Cases#\n",
            "Best practices and built-in implementations for common LangChain use cases:\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Use Cases#\n",
            "Best practices and built-in implementations for common LangChain use cases:\n",
            "Autonomous Agents: Autonomous agents are long-running agents that take many steps in an attempt to accomplish an objective. Examples include AutoGPT and BabyAGI.\n",
            "Agent Simulations: Putting agents in a sandbox and observing how they interact with each other and react to events can be an effective way to evaluate their long-range reasoning and planning abilities.\n",
            "Personal Assistants: One of the primary LangChain use cases. Personal assistants need to take actions, remember interactions, and have knowledge about your data.\n",
            "Question Answering: Another common LangChain use case. Answering questions over specific documents, only utilizing the information in those documents to construct an answer.\n",
            "Chatbots: Language models love to chat, making this a very natural use of them.\n",
            "Querying Tabular Data: Recommended reading if you want to use language models to query structured data (CSVs, SQL, dataframes, etc).\n",
            "Code Understanding: Recommended reading if you want to use language models to analyze code.\n",
            "Interacting with APIs: Enabling language models to interact with APIs is extremely powerful. It gives them access to up-to-date information and allows them to take actions.\n",
            "Extraction: Extract structured information from text.\n",
            "Summarization: Compressing longer documents. A type of Data-Augmented Generation.\n",
            "Evaluation: Generative models are hard to evaluate with traditional metrics. One promising approach is to use language models themselves to do the evaluation.\n",
            "Reference Docs#\n",
            "Full documentation on all methods, classes, installation methods, and integration setups for LangChain.\n",
            "LangChain Installation\n",
            "Reference Documentation\n",
            "Ecosystem#\n",
            "LangChain integrates a lot of different LLMs, systems, and products.\n",
            "From the other side, many systems and products depend on LangChain.\n",
            "It creates a vibrant and thriving ecosystem.\n",
            "Integrations: Guides for how other products can be used with LangChain.\n",
            "Dependents: List of repositories that use LangChain.\n",
            "Deployments: A collection of instructions, code snippets, and template repositories for deploying LangChain apps.\n",
            "Additional Resources#\n",
            "Additional resources we think may be useful as you develop your application!\n",
            "LangChainHub: The LangChainHub is a place to share and explore other prompts, chains, and agents.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-97-556395370aa5>:9: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  df[\"values\"][i] = new_val\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "length_penalty (langchain.llms.NLPCloud attribute)\n",
            "lib (langchain.llms.CTransformers attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "lib (langchain.llms.CTransformers attribute)\n",
            "list_assertions_prompt (langchain.chains.LLMCheckerChain attribute)\n",
            "llm (langchain.agents.agent_toolkits.PowerBIToolkit attribute)\n",
            "(langchain.agents.agent_toolkits.SparkSQLToolkit attribute)\n",
            "(langchain.agents.agent_toolkits.SQLDatabaseToolkit attribute)\n",
            "(langchain.agents.agent_toolkits.VectorStoreRouterToolkit attribute)\n",
            "(langchain.agents.agent_toolkits.VectorStoreToolkit attribute)\n",
            "(langchain.chains.LLMBashChain attribute)\n",
            "(langchain.chains.LLMChain attribute)\n",
            "(langchain.chains.LLMCheckerChain attribute)\n",
            "(langchain.chains.LLMMathChain attribute)\n",
            "(langchain.chains.LLMSummarizationCheckerChain attribute)\n",
            "(langchain.chains.PALChain attribute)\n",
            "(langchain.chains.SQLDatabaseChain attribute)\n",
            "(langchain.experimental.GenerativeAgent attribute)\n",
            "(langchain.experimental.GenerativeAgentMemory attribute)\n",
            "(langchain.memory.ConversationEntityMemory attribute)\n",
            "(langchain.memory.ConversationKGMemory attribute)\n",
            "(langchain.memory.ConversationTokenBufferMemory attribute)\n",
            "llm_chain (langchain.agents.Agent attribute)\n",
            "(langchain.agents.LLMSingleActionAgent attribute)\n",
            "(langchain.chains.HypotheticalDocumentEmbedder attribute)\n",
            "(langchain.chains.LLMBashChain attribute)\n",
            "(langchain.chains.LLMMathChain attribute)\n",
            "(langchain.chains.LLMRequestsChain attribute)\n",
            "(langchain.chains.PALChain attribute)\n",
            "(langchain.chains.QAGenerationChain attribute)\n",
            "(langchain.chains.SQLDatabaseChain attribute)\n",
            "(langchain.retrievers.document_compressors.LLMChainExtractor attribute)\n",
            "(langchain.retrievers.document_compressors.LLMChainFilter attribute)\n",
            "(langchain.retrievers.SelfQueryRetriever attribute)\n",
            "(langchain.tools.QueryPowerBITool attribute)\n",
            "llm_prefix (langchain.agents.Agent property)\n",
            "(langchain.agents.ConversationalAgent property)\n",
            "(langchain.agents.ConversationalChatAgent property)\n",
            "(langchain.agents.StructuredChatAgent property)\n",
            "(langchain.agents.ZeroShotAgent property)\n",
            "load() (langchain.document_loaders.AirbyteJSONLoader method)\n",
            "(langchain.document_loaders.ApifyDatasetLoader method)\n",
            "(langchain.document_loaders.ArxivLoader method)\n",
            "(langchain.document_loaders.AZLyricsLoader method)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.document_loaders.AZLyricsLoader method)\n",
            "(langchain.document_loaders.AzureBlobStorageContainerLoader method)\n",
            "(langchain.document_loaders.AzureBlobStorageFileLoader method)\n",
            "(langchain.document_loaders.BibtexLoader method)\n",
            "(langchain.document_loaders.BigQueryLoader method)\n",
            "(langchain.document_loaders.BiliBiliLoader method)\n",
            "(langchain.document_loaders.BlackboardLoader method)\n",
            "(langchain.document_loaders.BlockchainDocumentLoader method)\n",
            "(langchain.document_loaders.BSHTMLLoader method)\n",
            "(langchain.document_loaders.ChatGPTLoader method)\n",
            "(langchain.document_loaders.CollegeConfidentialLoader method)\n",
            "(langchain.document_loaders.ConfluenceLoader method)\n",
            "(langchain.document_loaders.CoNLLULoader method)\n",
            "(langchain.document_loaders.CSVLoader method)\n",
            "(langchain.document_loaders.DataFrameLoader method)\n",
            "(langchain.document_loaders.DiffbotLoader method)\n",
            "(langchain.document_loaders.DirectoryLoader method)\n",
            "(langchain.document_loaders.DiscordChatLoader method)\n",
            "(langchain.document_loaders.DocugamiLoader method)\n",
            "(langchain.document_loaders.Docx2txtLoader method)\n",
            "(langchain.document_loaders.DuckDBLoader method)\n",
            "(langchain.document_loaders.EverNoteLoader method)\n",
            "(langchain.document_loaders.FacebookChatLoader method)\n",
            "(langchain.document_loaders.GCSDirectoryLoader method)\n",
            "(langchain.document_loaders.GCSFileLoader method)\n",
            "(langchain.document_loaders.GitbookLoader method)\n",
            "(langchain.document_loaders.GitHubIssuesLoader method)\n",
            "(langchain.document_loaders.GitLoader method)\n",
            "(langchain.document_loaders.GoogleApiYoutubeLoader method)\n",
            "(langchain.document_loaders.GoogleDriveLoader method)\n",
            "(langchain.document_loaders.GutenbergLoader method)\n",
            "(langchain.document_loaders.HNLoader method)\n",
            "(langchain.document_loaders.HuggingFaceDatasetLoader method)\n",
            "(langchain.document_loaders.IFixitLoader method)\n",
            "(langchain.document_loaders.ImageCaptionLoader method)\n",
            "(langchain.document_loaders.IMSDbLoader method)\n",
            "(langchain.document_loaders.JoplinLoader method)\n",
            "(langchain.document_loaders.JSONLoader method)\n",
            "(langchain.document_loaders.MastodonTootsLoader method)\n",
            "(langchain.document_loaders.MathpixPDFLoader method)\n",
            "(langchain.document_loaders.ModernTreasuryLoader method)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.document_loaders.ModernTreasuryLoader method)\n",
            "(langchain.document_loaders.MWDumpLoader method)\n",
            "(langchain.document_loaders.NotebookLoader method)\n",
            "(langchain.document_loaders.NotionDBLoader method)\n",
            "(langchain.document_loaders.NotionDirectoryLoader method)\n",
            "(langchain.document_loaders.ObsidianLoader method)\n",
            "(langchain.document_loaders.OneDriveLoader method)\n",
            "(langchain.document_loaders.OnlinePDFLoader method)\n",
            "(langchain.document_loaders.OutlookMessageLoader method)\n",
            "(langchain.document_loaders.PDFMinerLoader method)\n",
            "(langchain.document_loaders.PDFMinerPDFasHTMLLoader method)\n",
            "(langchain.document_loaders.PDFPlumberLoader method)\n",
            "(langchain.document_loaders.PlaywrightURLLoader method)\n",
            "(langchain.document_loaders.PsychicLoader method)\n",
            "(langchain.document_loaders.PyMuPDFLoader method)\n",
            "(langchain.document_loaders.PyPDFDirectoryLoader method)\n",
            "(langchain.document_loaders.PyPDFium2Loader method)\n",
            "(langchain.document_loaders.PyPDFLoader method)\n",
            "(langchain.document_loaders.PySparkDataFrameLoader method)\n",
            "(langchain.document_loaders.ReadTheDocsLoader method)\n",
            "(langchain.document_loaders.RedditPostsLoader method)\n",
            "(langchain.document_loaders.RoamLoader method)\n",
            "(langchain.document_loaders.S3DirectoryLoader method)\n",
            "(langchain.document_loaders.S3FileLoader method)\n",
            "(langchain.document_loaders.SeleniumURLLoader method)\n",
            "(langchain.document_loaders.SitemapLoader method)\n",
            "(langchain.document_loaders.SlackDirectoryLoader method)\n",
            "(langchain.document_loaders.SpreedlyLoader method)\n",
            "(langchain.document_loaders.SRTLoader method)\n",
            "(langchain.document_loaders.StripeLoader method)\n",
            "(langchain.document_loaders.TelegramChatApiLoader method)\n",
            "(langchain.document_loaders.TelegramChatFileLoader method)\n",
            "(langchain.document_loaders.TextLoader method)\n",
            "(langchain.document_loaders.ToMarkdownLoader method)\n",
            "(langchain.document_loaders.TomlLoader method)\n",
            "(langchain.document_loaders.TrelloLoader method)\n",
            "(langchain.document_loaders.TwitterTweetLoader method)\n",
            "(langchain.document_loaders.UnstructuredURLLoader method)\n",
            "(langchain.document_loaders.WeatherDataLoader method)\n",
            "(langchain.document_loaders.WebBaseLoader method)\n",
            "(langchain.document_loaders.WhatsAppChatLoader method)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.document_loaders.WhatsAppChatLoader method)\n",
            "(langchain.document_loaders.WikipediaLoader method)\n",
            "(langchain.document_loaders.YoutubeLoader method)\n",
            "(langchain.utilities.ArxivAPIWrapper method)\n",
            "(langchain.utilities.WikipediaAPIWrapper method)\n",
            "load_agent() (in module langchain.agents)\n",
            "load_all_available_meta (langchain.utilities.ArxivAPIWrapper attribute)\n",
            "(langchain.utilities.WikipediaAPIWrapper attribute)\n",
            "load_all_recursively (langchain.document_loaders.BlackboardLoader attribute)\n",
            "load_chain() (in module langchain.chains)\n",
            "load_comments() (langchain.document_loaders.HNLoader method)\n",
            "load_device() (langchain.document_loaders.IFixitLoader method)\n",
            "load_file() (langchain.document_loaders.DirectoryLoader method)\n",
            "load_fn_kwargs (langchain.embeddings.SelfHostedHuggingFaceEmbeddings attribute)\n",
            "(langchain.llms.SelfHostedHuggingFaceLLM attribute)\n",
            "(langchain.llms.SelfHostedPipeline attribute)\n",
            "load_guide() (langchain.document_loaders.IFixitLoader method)\n",
            "load_huggingface_tool() (in module langchain.agents)\n",
            "load_local() (langchain.vectorstores.Annoy class method)\n",
            "(langchain.vectorstores.FAISS class method)\n",
            "load_max_docs (langchain.utilities.ArxivAPIWrapper attribute)\n",
            "load_memory_variables() (langchain.experimental.GenerativeAgentMemory method)\n",
            "(langchain.memory.CombinedMemory method)\n",
            "(langchain.memory.ConversationBufferMemory method)\n",
            "(langchain.memory.ConversationBufferWindowMemory method)\n",
            "(langchain.memory.ConversationEntityMemory method)\n",
            "(langchain.memory.ConversationKGMemory method)\n",
            "(langchain.memory.ConversationStringBufferMemory method)\n",
            "(langchain.memory.ConversationSummaryBufferMemory method)\n",
            "(langchain.memory.ConversationSummaryMemory method)\n",
            "(langchain.memory.ConversationTokenBufferMemory method)\n",
            "(langchain.memory.ReadOnlySharedMemory method)\n",
            "(langchain.memory.SimpleMemory method)\n",
            "(langchain.memory.VectorStoreRetrieverMemory method)\n",
            "load_messages() (langchain.memory.CosmosDBChatMessageHistory method)\n",
            "load_page() (langchain.document_loaders.NotionDBLoader method)\n",
            "load_prompt() (in module langchain.prompts)\n",
            "load_questions_and_answers() (langchain.document_loaders.IFixitLoader method)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "load_questions_and_answers() (langchain.document_loaders.IFixitLoader method)\n",
            "load_results() (langchain.document_loaders.HNLoader method)\n",
            "load_suggestions() (langchain.document_loaders.IFixitLoader static method)\n",
            "load_tools() (in module langchain.agents)\n",
            "load_trashed_files (langchain.document_loaders.GoogleDriveLoader attribute)\n",
            "locals (langchain.python.PythonREPL attribute)\n",
            "(langchain.utilities.PythonREPL attribute)\n",
            "location (langchain.llms.VertexAI attribute)\n",
            "log_probs (langchain.llms.AlephAlpha attribute)\n",
            "logit_bias (langchain.llms.AlephAlpha attribute)\n",
            "(langchain.llms.AzureOpenAI attribute)\n",
            "(langchain.llms.GooseAI attribute)\n",
            "(langchain.llms.OpenAI attribute)\n",
            "(langchain.llms.OpenLM attribute)\n",
            "logitBias (langchain.llms.AI21 attribute)\n",
            "logits_all (langchain.embeddings.LlamaCppEmbeddings attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "logprobs (langchain.llms.LlamaCpp attribute)\n",
            "(langchain.llms.Writer attribute)\n",
            "lookup_tool() (langchain.agents.AgentExecutor method)\n",
            "lora_base (langchain.llms.LlamaCpp attribute)\n",
            "lora_path (langchain.llms.LlamaCpp attribute)\n",
            "M\n",
            "MarkdownTextSplitter (class in langchain.text_splitter)\n",
            "MastodonTootsLoader (class in langchain.document_loaders)\n",
            "MathpixPDFLoader (class in langchain.document_loaders)\n",
            "max_checks (langchain.chains.LLMSummarizationCheckerChain attribute)\n",
            "max_execution_time (langchain.agents.AgentExecutor attribute)\n",
            "max_iter (langchain.chains.FlareChain attribute)\n",
            "max_iterations (langchain.agents.agent_toolkits.PowerBIToolkit attribute)\n",
            "(langchain.agents.AgentExecutor attribute)\n",
            "(langchain.tools.QueryPowerBITool attribute)\n",
            "max_length (langchain.llms.NLPCloud attribute)\n",
            "(langchain.llms.Petals attribute)\n",
            "(langchain.prompts.example_selector.LengthBasedExampleSelector attribute)\n",
            "max_marginal_relevance_search() (langchain.vectorstores.Annoy method)\n",
            "(langchain.vectorstores.Chroma method)\n",
            "(langchain.vectorstores.DeepLake method)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.vectorstores.Chroma method)\n",
            "(langchain.vectorstores.DeepLake method)\n",
            "(langchain.vectorstores.FAISS method)\n",
            "(langchain.vectorstores.Milvus method)\n",
            "(langchain.vectorstores.Qdrant method)\n",
            "(langchain.vectorstores.SupabaseVectorStore method)\n",
            "(langchain.vectorstores.VectorStore method)\n",
            "(langchain.vectorstores.Weaviate method)\n",
            "max_marginal_relevance_search_by_vector() (langchain.vectorstores.Annoy method)\n",
            "(langchain.vectorstores.Chroma method)\n",
            "(langchain.vectorstores.DeepLake method)\n",
            "(langchain.vectorstores.FAISS method)\n",
            "(langchain.vectorstores.Milvus method)\n",
            "(langchain.vectorstores.SupabaseVectorStore method)\n",
            "(langchain.vectorstores.VectorStore method)\n",
            "(langchain.vectorstores.Weaviate method)\n",
            "max_new_tokens (langchain.llms.Petals attribute)\n",
            "max_output_tokens (langchain.llms.GooglePalm attribute)\n",
            "(langchain.llms.VertexAI attribute)\n",
            "max_results (langchain.utilities.DuckDuckGoSearchAPIWrapper attribute)\n",
            "max_retries (langchain.chat_models.ChatOpenAI attribute)\n",
            "(langchain.embeddings.OpenAIEmbeddings attribute)\n",
            "(langchain.llms.AzureOpenAI attribute)\n",
            "(langchain.llms.OpenAI attribute)\n",
            "(langchain.llms.OpenAIChat attribute)\n",
            "(langchain.llms.OpenLM attribute)\n",
            "(langchain.llms.PromptLayerOpenAIChat attribute)\n",
            "max_token_limit (langchain.memory.ConversationSummaryBufferMemory attribute)\n",
            "(langchain.memory.ConversationTokenBufferMemory attribute)\n",
            "max_tokens (langchain.chat_models.ChatOpenAI attribute)\n",
            "(langchain.llms.AzureOpenAI attribute)\n",
            "(langchain.llms.Cohere attribute)\n",
            "(langchain.llms.GooseAI attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "(langchain.llms.OpenAI attribute)\n",
            "(langchain.llms.OpenLM attribute)\n",
            "(langchain.llms.PredictionGuard attribute)\n",
            "(langchain.llms.Writer attribute)\n",
            "max_tokens_for_prompt() (langchain.llms.AzureOpenAI method)\n",
            "(langchain.llms.OpenAI method)\n",
            "(langchain.llms.OpenLM method)\n",
            "(langchain.llms.PromptLayerOpenAI method)\n",
            "max_tokens_limit (langchain.chains.ConversationalRetrievalChain attribute)\n",
            "(langchain.chains.RetrievalQAWithSourcesChain attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.chains.RetrievalQAWithSourcesChain attribute)\n",
            "(langchain.chains.VectorDBQAWithSourcesChain attribute)\n",
            "max_tokens_per_generation (langchain.llms.RWKV attribute)\n",
            "max_tokens_to_sample (langchain.llms.Anthropic attribute)\n",
            "maximum_tokens (langchain.llms.AlephAlpha attribute)\n",
            "maxTokens (langchain.llms.AI21 attribute)\n",
            "memories (langchain.memory.CombinedMemory attribute)\n",
            "(langchain.memory.SimpleMemory attribute)\n",
            "memory (langchain.chains.ConversationChain attribute)\n",
            "(langchain.experimental.GenerativeAgent attribute)\n",
            "(langchain.memory.ReadOnlySharedMemory attribute)\n",
            "memory_key (langchain.memory.ConversationSummaryBufferMemory attribute)\n",
            "(langchain.memory.ConversationTokenBufferMemory attribute)\n",
            "(langchain.memory.VectorStoreRetrieverMemory attribute)\n",
            "memory_retriever (langchain.experimental.GenerativeAgentMemory attribute)\n",
            "memory_stream (langchain.retrievers.TimeWeightedVectorStoreRetriever attribute)\n",
            "memory_variables (langchain.experimental.GenerativeAgentMemory property)\n",
            "(langchain.memory.CombinedMemory property)\n",
            "(langchain.memory.ConversationStringBufferMemory property)\n",
            "(langchain.memory.ReadOnlySharedMemory property)\n",
            "(langchain.memory.SimpleMemory property)\n",
            "(langchain.memory.VectorStoreRetrieverMemory property)\n",
            "mentioned (langchain.document_loaders.GitHubIssuesLoader attribute)\n",
            "merge_from() (langchain.vectorstores.FAISS method)\n",
            "messages (langchain.memory.CassandraChatMessageHistory property)\n",
            "(langchain.memory.ChatMessageHistory attribute)\n",
            "(langchain.memory.DynamoDBChatMessageHistory property)\n",
            "(langchain.memory.FileChatMessageHistory property)\n",
            "(langchain.memory.MomentoChatMessageHistory property)\n",
            "(langchain.memory.MongoDBChatMessageHistory property)\n",
            "(langchain.memory.PostgresChatMessageHistory property)\n",
            "(langchain.memory.RedisChatMessageHistory property)\n",
            "metadata_column (langchain.vectorstores.MyScale property)\n",
            "metadata_key (langchain.retrievers.RemoteLangChainRetriever attribute)\n",
            "METADATA_KEY (langchain.vectorstores.Qdrant attribute)\n",
            "MetalRetriever (class in langchain.retrievers)\n",
            "metaphor_api_key (langchain.utilities.MetaphorSearchAPIWrapper attribute)\n",
            "method (langchain.tools.APIOperation attribute)\n",
            "metric (langchain.vectorstores.MyScaleSettings attribute)\n",
            "milestone (langchain.document_loaders.GitHubIssuesLoader attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "milestone (langchain.document_loaders.GitHubIssuesLoader attribute)\n",
            "Milvus (class in langchain.vectorstores)\n",
            "min_chunk_size (langchain.document_loaders.DocugamiLoader attribute)\n",
            "min_length (langchain.llms.NLPCloud attribute)\n",
            "min_prob (langchain.chains.FlareChain attribute)\n",
            "min_token_gap (langchain.chains.FlareChain attribute)\n",
            "min_tokens (langchain.llms.GooseAI attribute)\n",
            "(langchain.llms.Writer attribute)\n",
            "minimax_api_key (langchain.embeddings.MiniMaxEmbeddings attribute)\n",
            "minimax_group_id (langchain.embeddings.MiniMaxEmbeddings attribute)\n",
            "minimum_tokens (langchain.llms.AlephAlpha attribute)\n",
            "minTokens (langchain.llms.AI21 attribute)\n",
            "model (langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding attribute)\n",
            "(langchain.embeddings.CohereEmbeddings attribute)\n",
            "(langchain.embeddings.MiniMaxEmbeddings attribute)\n",
            "(langchain.llms.AI21 attribute)\n",
            "(langchain.llms.AlephAlpha attribute)\n",
            "(langchain.llms.Anthropic attribute)\n",
            "(langchain.llms.Cohere attribute)\n",
            "(langchain.llms.CTransformers attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.PredictionGuard attribute)\n",
            "(langchain.llms.RWKV attribute)\n",
            "(langchain.retrievers.document_compressors.CohereRerank attribute)\n",
            "model_file (langchain.llms.CTransformers attribute)\n",
            "model_id (langchain.embeddings.ModelScopeEmbeddings attribute)\n",
            "(langchain.embeddings.SelfHostedHuggingFaceEmbeddings attribute)\n",
            "(langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings attribute)\n",
            "(langchain.llms.HuggingFacePipeline attribute)\n",
            "(langchain.llms.SelfHostedHuggingFaceLLM attribute)\n",
            "(langchain.llms.Writer attribute)\n",
            "model_key (langchain.llms.Banana attribute)\n",
            "model_kwargs (langchain.chat_models.ChatOpenAI attribute)\n",
            "(langchain.embeddings.HuggingFaceEmbeddings attribute)\n",
            "(langchain.embeddings.HuggingFaceHubEmbeddings attribute)\n",
            "(langchain.embeddings.HuggingFaceInstructEmbeddings attribute)\n",
            "(langchain.embeddings.SagemakerEndpointEmbeddings attribute)\n",
            "(langchain.llms.Anyscale attribute)\n",
            "(langchain.llms.AzureOpenAI attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.llms.Anyscale attribute)\n",
            "(langchain.llms.AzureOpenAI attribute)\n",
            "(langchain.llms.Banana attribute)\n",
            "(langchain.llms.Beam attribute)\n",
            "(langchain.llms.CerebriumAI attribute)\n",
            "(langchain.llms.Databricks attribute)\n",
            "(langchain.llms.GooseAI attribute)\n",
            "(langchain.llms.HuggingFaceEndpoint attribute)\n",
            "(langchain.llms.HuggingFaceHub attribute)\n",
            "(langchain.llms.HuggingFacePipeline attribute)\n",
            "(langchain.llms.Modal attribute)\n",
            "(langchain.llms.MosaicML attribute)\n",
            "(langchain.llms.OpenAI attribute)\n",
            "(langchain.llms.OpenAIChat attribute)\n",
            "(langchain.llms.OpenLM attribute)\n",
            "(langchain.llms.Petals attribute)\n",
            "(langchain.llms.PromptLayerOpenAIChat attribute)\n",
            "(langchain.llms.SagemakerEndpoint attribute)\n",
            "(langchain.llms.SelfHostedHuggingFaceLLM attribute)\n",
            "(langchain.llms.StochasticAI attribute)\n",
            "model_load_fn (langchain.embeddings.SelfHostedHuggingFaceEmbeddings attribute)\n",
            "(langchain.llms.SelfHostedHuggingFaceLLM attribute)\n",
            "(langchain.llms.SelfHostedPipeline attribute)\n",
            "model_name (langchain.chains.OpenAIModerationChain attribute)\n",
            "(langchain.chat_models.ChatGooglePalm attribute)\n",
            "(langchain.chat_models.ChatOpenAI attribute)\n",
            "(langchain.chat_models.ChatVertexAI attribute)\n",
            "(langchain.embeddings.HuggingFaceEmbeddings attribute)\n",
            "(langchain.embeddings.HuggingFaceInstructEmbeddings attribute)\n",
            "(langchain.llms.AzureOpenAI attribute)\n",
            "(langchain.llms.GooglePalm attribute)\n",
            "(langchain.llms.GooseAI attribute)\n",
            "(langchain.llms.NLPCloud attribute)\n",
            "(langchain.llms.OpenAI attribute)\n",
            "(langchain.llms.OpenAIChat attribute)\n",
            "(langchain.llms.OpenLM attribute)\n",
            "(langchain.llms.Petals attribute)\n",
            "(langchain.llms.PromptLayerOpenAIChat attribute)\n",
            "(langchain.tools.SteamshipImageGenerationTool attribute)\n",
            "model_path (langchain.llms.LlamaCpp attribute)\n",
            "model_reqs (langchain.embeddings.SelfHostedHuggingFaceEmbeddings attribute)\n",
            "(langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings attribute)\n",
            "(langchain.llms.SelfHostedHuggingFaceLLM attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.llms.SelfHostedHuggingFaceLLM attribute)\n",
            "(langchain.llms.SelfHostedPipeline attribute)\n",
            "model_type (langchain.llms.CTransformers attribute)\n",
            "model_url (langchain.embeddings.TensorflowHubEmbeddings attribute)\n",
            "modelname_to_contextsize() (langchain.llms.AzureOpenAI method)\n",
            "(langchain.llms.OpenAI method)\n",
            "(langchain.llms.OpenLM method)\n",
            "(langchain.llms.PromptLayerOpenAI method)\n",
            "ModernTreasuryLoader (class in langchain.document_loaders)\n",
            "    module\n",
            "      \n",
            "langchain.agents\n",
            "langchain.agents.agent_toolkits\n",
            "langchain.chains\n",
            "langchain.chat_models\n",
            "langchain.docstore\n",
            "langchain.document_loaders\n",
            "langchain.document_transformers\n",
            "langchain.embeddings\n",
            "langchain.llms\n",
            "langchain.memory\n",
            "langchain.output_parsers\n",
            "langchain.prompts\n",
            "langchain.prompts.example_selector\n",
            "langchain.python\n",
            "langchain.retrievers\n",
            "langchain.retrievers.document_compressors\n",
            "langchain.serpapi\n",
            "langchain.text_splitter\n",
            "langchain.tools\n",
            "langchain.utilities\n",
            "langchain.utilities.searx_search\n",
            "langchain.vectorstores\n",
            "MomentoChatMessageHistory (class in langchain.memory)\n",
            "MongoDBChatMessageHistory (class in langchain.memory)\n",
            "moving_summary_buffer (langchain.memory.ConversationSummaryBufferMemory attribute)\n",
            "MWDumpLoader (class in langchain.document_loaders)\n",
            "MyScale (class in langchain.vectorstores)\n",
            "N\n",
            "n (langchain.chat_models.ChatGooglePalm attribute)\n",
            "(langchain.chat_models.ChatOpenAI attribute)\n",
            "(langchain.llms.AlephAlpha attribute)\n",
            "(langchain.llms.AzureOpenAI attribute)\n",
            "(langchain.llms.GooglePalm attribute)\n",
            "(langchain.llms.GooseAI attribute)\n",
            "(langchain.llms.OpenAI attribute)\n",
            "(langchain.llms.OpenLM attribute)\n",
            "(langchain.llms.Writer attribute)\n",
            "n_batch (langchain.embeddings.LlamaCppEmbeddings attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "n_ctx (langchain.embeddings.LlamaCppEmbeddings attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "n_gpu_layers (langchain.embeddings.LlamaCppEmbeddings attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "n_gpu_layers (langchain.embeddings.LlamaCppEmbeddings attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "n_parts (langchain.embeddings.LlamaCppEmbeddings attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "n_predict (langchain.llms.GPT4All attribute)\n",
            "n_threads (langchain.embeddings.LlamaCppEmbeddings attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "name (langchain.agents.agent_toolkits.VectorStoreInfo attribute)\n",
            "(langchain.experimental.GenerativeAgent attribute)\n",
            "(langchain.output_parsers.ResponseSchema attribute)\n",
            "(langchain.tools.BaseTool attribute)\n",
            "(langchain.tools.ClickTool attribute)\n",
            "(langchain.tools.CopyFileTool attribute)\n",
            "(langchain.tools.CurrentWebPageTool attribute)\n",
            "(langchain.tools.DeleteFileTool attribute)\n",
            "(langchain.tools.ExtractHyperlinksTool attribute)\n",
            "(langchain.tools.ExtractTextTool attribute)\n",
            "(langchain.tools.FileSearchTool attribute)\n",
            "(langchain.tools.GetElementsTool attribute)\n",
            "(langchain.tools.GmailCreateDraft attribute)\n",
            "(langchain.tools.GmailGetMessage attribute)\n",
            "(langchain.tools.GmailGetThread attribute)\n",
            "(langchain.tools.GmailSearch attribute)\n",
            "(langchain.tools.GmailSendMessage attribute)\n",
            "(langchain.tools.ListDirectoryTool attribute)\n",
            "(langchain.tools.MoveFileTool attribute)\n",
            "(langchain.tools.NavigateBackTool attribute)\n",
            "(langchain.tools.NavigateTool attribute)\n",
            "(langchain.tools.ReadFileTool attribute)\n",
            "(langchain.tools.ShellTool attribute)\n",
            "(langchain.tools.Tool attribute)\n",
            "(langchain.tools.WriteFileTool attribute)\n",
            "nla_tools (langchain.agents.agent_toolkits.NLAToolkit attribute)\n",
            "NLTKTextSplitter (class in langchain.text_splitter)\n",
            "no_update_value (langchain.output_parsers.RegexDictParser attribute)\n",
            "normalize (langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding attribute)\n",
            "NotebookLoader (class in langchain.document_loaders)\n",
            "NotionDBLoader (class in langchain.document_loaders)\n",
            "NotionDirectoryLoader (class in langchain.document_loaders)\n",
            "num_beams (langchain.llms.NLPCloud attribute)\n",
            "num_pad_tokens (langchain.chains.FlareChain attribute)\n",
            "num_results (langchain.tools.BingSearchResults attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "num_results (langchain.tools.BingSearchResults attribute)\n",
            "(langchain.tools.DuckDuckGoSearchResults attribute)\n",
            "(langchain.tools.GoogleSearchResults attribute)\n",
            "num_return_sequences (langchain.llms.NLPCloud attribute)\n",
            "numResults (langchain.llms.AI21 attribute)\n",
            "O\n",
            "object_ids (langchain.document_loaders.OneDriveLoader attribute)\n",
            "observation_prefix (langchain.agents.Agent property)\n",
            "(langchain.agents.ConversationalAgent property)\n",
            "(langchain.agents.ConversationalChatAgent property)\n",
            "(langchain.agents.StructuredChatAgent property)\n",
            "(langchain.agents.ZeroShotAgent property)\n",
            "ObsidianLoader (class in langchain.document_loaders)\n",
            "OnlinePDFLoader (class in langchain.document_loaders)\n",
            "openai_api_base (langchain.chat_models.AzureChatOpenAI attribute)\n",
            "(langchain.chat_models.ChatOpenAI attribute)\n",
            "openai_api_key (langchain.chains.OpenAIModerationChain attribute)\n",
            "(langchain.chat_models.AzureChatOpenAI attribute)\n",
            "(langchain.chat_models.ChatOpenAI attribute)\n",
            "openai_api_type (langchain.chat_models.AzureChatOpenAI attribute)\n",
            "openai_api_version (langchain.chat_models.AzureChatOpenAI attribute)\n",
            "openai_organization (langchain.chains.OpenAIModerationChain attribute)\n",
            "(langchain.chat_models.AzureChatOpenAI attribute)\n",
            "(langchain.chat_models.ChatOpenAI attribute)\n",
            "openai_proxy (langchain.chat_models.AzureChatOpenAI attribute)\n",
            "(langchain.chat_models.ChatOpenAI attribute)\n",
            "OpenSearchVectorSearch (class in langchain.vectorstores)\n",
            "openweathermap_api_key (langchain.utilities.OpenWeatherMapAPIWrapper attribute)\n",
            "operation_id (langchain.tools.APIOperation attribute)\n",
            "other_score_keys (langchain.retrievers.TimeWeightedVectorStoreRetriever attribute)\n",
            "OutlookMessageLoader (class in langchain.document_loaders)\n",
            "output (langchain.llms.PredictionGuard attribute)\n",
            "output_key (langchain.chains.QAGenerationChain attribute)\n",
            "(langchain.memory.ConversationStringBufferMemory attribute)\n",
            "output_key_to_format (langchain.output_parsers.RegexDictParser attribute)\n",
            "output_keys (langchain.chains.ConstitutionalChain property)\n",
            "(langchain.chains.FlareChain property)\n",
            "(langchain.chains.HypotheticalDocumentEmbedder property)\n",
            "(langchain.chains.QAGenerationChain property)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.chains.QAGenerationChain property)\n",
            "(langchain.experimental.BabyAGI property)\n",
            "(langchain.output_parsers.RegexParser attribute)\n",
            "output_parser (langchain.agents.Agent attribute)\n",
            "(langchain.agents.ConversationalAgent attribute)\n",
            "(langchain.agents.ConversationalChatAgent attribute)\n",
            "(langchain.agents.LLMSingleActionAgent attribute)\n",
            "(langchain.agents.StructuredChatAgent attribute)\n",
            "(langchain.agents.ZeroShotAgent attribute)\n",
            "(langchain.chains.FlareChain attribute)\n",
            "(langchain.prompts.BasePromptTemplate attribute)\n",
            "output_variables (langchain.chains.TransformChain attribute)\n",
            "owm (langchain.utilities.OpenWeatherMapAPIWrapper attribute)\n",
            "P\n",
            "p (langchain.llms.Cohere attribute)\n",
            "page_content_key (langchain.retrievers.RemoteLangChainRetriever attribute)\n",
            "PagedPDFSplitter (in module langchain.document_loaders)\n",
            "paginate_request() (langchain.document_loaders.ConfluenceLoader method)\n",
            "param_mapping (langchain.chains.OpenAPIEndpointChain attribute)\n",
            "params (langchain.serpapi.SerpAPIWrapper attribute)\n",
            "(langchain.tools.ZapierNLARunAction attribute)\n",
            "(langchain.utilities.searx_search.SearxSearchWrapper attribute)\n",
            "(langchain.utilities.SearxSearchWrapper attribute)\n",
            "(langchain.utilities.SerpAPIWrapper attribute)\n",
            "params_schema (langchain.tools.ZapierNLARunAction attribute)\n",
            "parse() (langchain.agents.AgentOutputParser method)\n",
            "(langchain.output_parsers.CommaSeparatedListOutputParser method)\n",
            "(langchain.output_parsers.DatetimeOutputParser method)\n",
            "(langchain.output_parsers.GuardrailsOutputParser method)\n",
            "(langchain.output_parsers.ListOutputParser method)\n",
            "(langchain.output_parsers.OutputFixingParser method)\n",
            "(langchain.output_parsers.PydanticOutputParser method)\n",
            "(langchain.output_parsers.RegexDictParser method)\n",
            "(langchain.output_parsers.RegexParser method)\n",
            "(langchain.output_parsers.RetryOutputParser method)\n",
            "(langchain.output_parsers.RetryWithErrorOutputParser method)\n",
            "(langchain.output_parsers.StructuredOutputParser method)\n",
            "parse_filename() (langchain.document_loaders.BlackboardLoader method)\n",
            "parse_issue() (langchain.document_loaders.GitHubIssuesLoader method)\n",
            "parse_obj() (langchain.tools.OpenAPISpec class method)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "parse_obj() (langchain.tools.OpenAPISpec class method)\n",
            "parse_sitemap() (langchain.document_loaders.SitemapLoader method)\n",
            "parse_with_prompt() (langchain.output_parsers.RetryOutputParser method)\n",
            "(langchain.output_parsers.RetryWithErrorOutputParser method)\n",
            "parser (langchain.output_parsers.OutputFixingParser attribute)\n",
            "(langchain.output_parsers.RetryOutputParser attribute)\n",
            "(langchain.output_parsers.RetryWithErrorOutputParser attribute)\n",
            "partial() (langchain.prompts.BasePromptTemplate method)\n",
            "(langchain.prompts.ChatPromptTemplate method)\n",
            "password (langchain.vectorstores.MyScaleSettings attribute)\n",
            "patch() (langchain.utilities.TextRequestsWrapper method)\n",
            "path (langchain.tools.APIOperation attribute)\n",
            "path_params (langchain.tools.APIOperation property)\n",
            "pause_to_reflect() (langchain.experimental.GenerativeAgentMemory method)\n",
            "PDFMinerLoader (class in langchain.document_loaders)\n",
            "PDFMinerPDFasHTMLLoader (class in langchain.document_loaders)\n",
            "PDFPlumberLoader (class in langchain.document_loaders)\n",
            "penalty_alpha_frequency (langchain.llms.RWKV attribute)\n",
            "penalty_alpha_presence (langchain.llms.RWKV attribute)\n",
            "penalty_bias (langchain.llms.AlephAlpha attribute)\n",
            "penalty_exceptions (langchain.llms.AlephAlpha attribute)\n",
            "penalty_exceptions_include_stop_sequences (langchain.llms.AlephAlpha attribute)\n",
            "persist() (langchain.vectorstores.Chroma method)\n",
            "(langchain.vectorstores.DeepLake method)\n",
            "(langchain.vectorstores.SKLearnVectorStore method)\n",
            "Pinecone (class in langchain.vectorstores)\n",
            "pipeline_key (langchain.llms.PipelineAI attribute)\n",
            "pipeline_kwargs (langchain.llms.HuggingFacePipeline attribute)\n",
            "(langchain.llms.PipelineAI attribute)\n",
            "pl_tags (langchain.chat_models.PromptLayerChatOpenAI attribute)\n",
            "plan() (langchain.agents.Agent method)\n",
            "(langchain.agents.BaseMultiActionAgent method)\n",
            "(langchain.agents.BaseSingleActionAgent method)\n",
            "(langchain.agents.LLMSingleActionAgent method)\n",
            "playwright_strict (langchain.tools.ClickTool attribute)\n",
            "playwright_timeout (langchain.tools.ClickTool attribute)\n",
            "PlaywrightURLLoader (class in langchain.document_loaders)\n",
            "plugin (langchain.tools.AIPluginTool attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "plugin (langchain.tools.AIPluginTool attribute)\n",
            "port (langchain.vectorstores.MyScaleSettings attribute)\n",
            "post() (langchain.utilities.TextRequestsWrapper method)\n",
            "PostgresChatMessageHistory (class in langchain.memory)\n",
            "powerbi (langchain.agents.agent_toolkits.PowerBIToolkit attribute)\n",
            "(langchain.tools.InfoPowerBITool attribute)\n",
            "(langchain.tools.ListPowerBITool attribute)\n",
            "(langchain.tools.QueryPowerBITool attribute)\n",
            "predict() (langchain.chains.LLMChain method)\n",
            "(langchain.llms.AI21 method)\n",
            "(langchain.llms.AlephAlpha method)\n",
            "(langchain.llms.Anthropic method)\n",
            "(langchain.llms.Anyscale method)\n",
            "(langchain.llms.AzureOpenAI method)\n",
            "(langchain.llms.Banana method)\n",
            "(langchain.llms.Beam method)\n",
            "(langchain.llms.CerebriumAI method)\n",
            "(langchain.llms.Cohere method)\n",
            "(langchain.llms.CTransformers method)\n",
            "(langchain.llms.Databricks method)\n",
            "(langchain.llms.DeepInfra method)\n",
            "(langchain.llms.FakeListLLM method)\n",
            "(langchain.llms.ForefrontAI method)\n",
            "(langchain.llms.GooglePalm method)\n",
            "(langchain.llms.GooseAI method)\n",
            "(langchain.llms.GPT4All method)\n",
            "(langchain.llms.HuggingFaceEndpoint method)\n",
            "(langchain.llms.HuggingFaceHub method)\n",
            "(langchain.llms.HuggingFacePipeline method)\n",
            "(langchain.llms.HuggingFaceTextGenInference method)\n",
            "(langchain.llms.HumanInputLLM method)\n",
            "(langchain.llms.LlamaCpp method)\n",
            "(langchain.llms.Modal method)\n",
            "(langchain.llms.MosaicML method)\n",
            "(langchain.llms.NLPCloud method)\n",
            "(langchain.llms.OpenAI method)\n",
            "(langchain.llms.OpenAIChat method)\n",
            "(langchain.llms.OpenLM method)\n",
            "(langchain.llms.Petals method)\n",
            "(langchain.llms.PipelineAI method)\n",
            "(langchain.llms.PredictionGuard method)\n",
            "(langchain.llms.PromptLayerOpenAI method)\n",
            "(langchain.llms.PromptLayerOpenAIChat method)\n",
            "(langchain.llms.Replicate method)\n",
            "(langchain.llms.RWKV method)\n",
            "(langchain.llms.SagemakerEndpoint method)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.llms.RWKV method)\n",
            "(langchain.llms.SagemakerEndpoint method)\n",
            "(langchain.llms.SelfHostedHuggingFaceLLM method)\n",
            "(langchain.llms.SelfHostedPipeline method)\n",
            "(langchain.llms.StochasticAI method)\n",
            "(langchain.llms.VertexAI method)\n",
            "(langchain.llms.Writer method)\n",
            "predict_and_parse() (langchain.chains.LLMChain method)\n",
            "predict_messages() (langchain.llms.AI21 method)\n",
            "(langchain.llms.AlephAlpha method)\n",
            "(langchain.llms.Anthropic method)\n",
            "(langchain.llms.Anyscale method)\n",
            "(langchain.llms.AzureOpenAI method)\n",
            "(langchain.llms.Banana method)\n",
            "(langchain.llms.Beam method)\n",
            "(langchain.llms.CerebriumAI method)\n",
            "(langchain.llms.Cohere method)\n",
            "(langchain.llms.CTransformers method)\n",
            "(langchain.llms.Databricks method)\n",
            "(langchain.llms.DeepInfra method)\n",
            "(langchain.llms.FakeListLLM method)\n",
            "(langchain.llms.ForefrontAI method)\n",
            "(langchain.llms.GooglePalm method)\n",
            "(langchain.llms.GooseAI method)\n",
            "(langchain.llms.GPT4All method)\n",
            "(langchain.llms.HuggingFaceEndpoint method)\n",
            "(langchain.llms.HuggingFaceHub method)\n",
            "(langchain.llms.HuggingFacePipeline method)\n",
            "(langchain.llms.HuggingFaceTextGenInference method)\n",
            "(langchain.llms.HumanInputLLM method)\n",
            "(langchain.llms.LlamaCpp method)\n",
            "(langchain.llms.Modal method)\n",
            "(langchain.llms.MosaicML method)\n",
            "(langchain.llms.NLPCloud method)\n",
            "(langchain.llms.OpenAI method)\n",
            "(langchain.llms.OpenAIChat method)\n",
            "(langchain.llms.OpenLM method)\n",
            "(langchain.llms.Petals method)\n",
            "(langchain.llms.PipelineAI method)\n",
            "(langchain.llms.PredictionGuard method)\n",
            "(langchain.llms.PromptLayerOpenAI method)\n",
            "(langchain.llms.PromptLayerOpenAIChat method)\n",
            "(langchain.llms.Replicate method)\n",
            "(langchain.llms.RWKV method)\n",
            "(langchain.llms.SagemakerEndpoint method)\n",
            "(langchain.llms.SelfHostedHuggingFaceLLM method)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.llms.SelfHostedHuggingFaceLLM method)\n",
            "(langchain.llms.SelfHostedPipeline method)\n",
            "(langchain.llms.StochasticAI method)\n",
            "(langchain.llms.VertexAI method)\n",
            "(langchain.llms.Writer method)\n",
            "prefix (langchain.prompts.FewShotPromptTemplate attribute)\n",
            "(langchain.prompts.FewShotPromptWithTemplates attribute)\n",
            "prefix_messages (langchain.llms.OpenAIChat attribute)\n",
            "(langchain.llms.PromptLayerOpenAIChat attribute)\n",
            "prep_prompts() (langchain.chains.LLMChain method)\n",
            "prep_streaming_params() (langchain.llms.AzureOpenAI method)\n",
            "(langchain.llms.OpenAI method)\n",
            "(langchain.llms.OpenLM method)\n",
            "(langchain.llms.PromptLayerOpenAI method)\n",
            "prepare_cosmos() (langchain.memory.CosmosDBChatMessageHistory method)\n",
            "presence_penalty (langchain.llms.AlephAlpha attribute)\n",
            "(langchain.llms.AzureOpenAI attribute)\n",
            "(langchain.llms.Cohere attribute)\n",
            "(langchain.llms.GooseAI attribute)\n",
            "(langchain.llms.OpenAI attribute)\n",
            "(langchain.llms.OpenLM attribute)\n",
            "(langchain.llms.Writer attribute)\n",
            "presencePenalty (langchain.llms.AI21 attribute)\n",
            "prioritize_tasks() (langchain.experimental.BabyAGI method)\n",
            "process (langchain.tools.ShellTool attribute)\n",
            "process_attachment() (langchain.document_loaders.ConfluenceLoader method)\n",
            "process_doc() (langchain.document_loaders.ConfluenceLoader method)\n",
            "process_image() (langchain.document_loaders.ConfluenceLoader method)\n",
            "process_index_results() (langchain.vectorstores.Annoy method)\n",
            "process_output() (langchain.utilities.BashProcess method)\n",
            "process_page() (langchain.document_loaders.ConfluenceLoader method)\n",
            "process_pages() (langchain.document_loaders.ConfluenceLoader method)\n",
            "process_pdf() (langchain.document_loaders.ConfluenceLoader method)\n",
            "process_svg() (langchain.document_loaders.ConfluenceLoader method)\n",
            "process_xls() (langchain.document_loaders.ConfluenceLoader method)\n",
            "project (langchain.llms.VertexAI attribute)\n",
            "Prompt (in module langchain.prompts)\n",
            "prompt (langchain.chains.ConversationChain attribute)\n",
            "(langchain.chains.LLMBashChain attribute)\n",
            "(langchain.chains.LLMChain attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.chains.LLMChain attribute)\n",
            "(langchain.chains.LLMMathChain attribute)\n",
            "(langchain.chains.PALChain attribute)\n",
            "(langchain.chains.SQLDatabaseChain attribute)\n",
            "prompt_func (langchain.tools.HumanInputRun attribute)\n",
            "properties (langchain.tools.APIOperation attribute)\n",
            "prune() (langchain.memory.ConversationSummaryBufferMemory method)\n",
            "PsychicLoader (class in langchain.document_loaders)\n",
            "put() (langchain.utilities.TextRequestsWrapper method)\n",
            "pydantic_object (langchain.output_parsers.PydanticOutputParser attribute)\n",
            "PyMuPDFLoader (class in langchain.document_loaders)\n",
            "PyPDFDirectoryLoader (class in langchain.document_loaders)\n",
            "PyPDFium2Loader (class in langchain.document_loaders)\n",
            "PyPDFLoader (class in langchain.document_loaders)\n",
            "PySparkDataFrameLoader (class in langchain.document_loaders)\n",
            "python_globals (langchain.chains.PALChain attribute)\n",
            "python_locals (langchain.chains.PALChain attribute)\n",
            "PythonCodeTextSplitter (class in langchain.text_splitter)\n",
            "PythonLoader (class in langchain.document_loaders)\n",
            "Q\n",
            "qa_chain (langchain.chains.GraphCypherQAChain attribute)\n",
            "(langchain.chains.GraphQAChain attribute)\n",
            "Qdrant (class in langchain.vectorstores)\n",
            "query_checker_prompt (langchain.chains.SQLDatabaseChain attribute)\n",
            "query_instruction (langchain.embeddings.HuggingFaceInstructEmbeddings attribute)\n",
            "(langchain.embeddings.MosaicMLInstructorEmbeddings attribute)\n",
            "(langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings attribute)\n",
            "query_name (langchain.vectorstores.SupabaseVectorStore attribute)\n",
            "query_params (langchain.document_loaders.GitHubIssuesLoader property)\n",
            "(langchain.tools.APIOperation property)\n",
            "query_suffix (langchain.utilities.searx_search.SearxSearchWrapper attribute)\n",
            "(langchain.utilities.SearxSearchWrapper attribute)\n",
            "question_generator_chain (langchain.chains.FlareChain attribute)\n",
            "question_to_checked_assertions_chain (langchain.chains.LLMCheckerChain attribute)\n",
            "R\n",
            "raw_completion (langchain.llms.AlephAlpha attribute)\n",
            "REACT_DOCSTORE (langchain.agents.AgentType attribute)\n",
            "ReadTheDocsLoader (class in langchain.document_loaders)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "ReadTheDocsLoader (class in langchain.document_loaders)\n",
            "recall_ttl (langchain.memory.RedisEntityStore attribute)\n",
            "recursive (langchain.document_loaders.GoogleDriveLoader attribute)\n",
            "RecursiveCharacterTextSplitter (class in langchain.text_splitter)\n",
            "RedditPostsLoader (class in langchain.document_loaders)\n",
            "Redis (class in langchain.vectorstores)\n",
            "redis_client (langchain.memory.RedisEntityStore attribute)\n",
            "RedisChatMessageHistory (class in langchain.memory)\n",
            "RedisEntityStore (class in langchain.memory)\n",
            "reduce_k_below_max_tokens (langchain.chains.RetrievalQAWithSourcesChain attribute)\n",
            "(langchain.chains.VectorDBQAWithSourcesChain attribute)\n",
            "reflection_threshold (langchain.experimental.GenerativeAgentMemory attribute)\n",
            "regex (langchain.output_parsers.RegexParser attribute)\n",
            "regex_pattern (langchain.output_parsers.RegexDictParser attribute)\n",
            "region (langchain.utilities.DuckDuckGoSearchAPIWrapper attribute)\n",
            "region_name (langchain.embeddings.SagemakerEndpointEmbeddings attribute)\n",
            "(langchain.llms.SagemakerEndpoint attribute)\n",
            "relevancy_threshold (langchain.retrievers.KNNRetriever attribute)\n",
            "(langchain.retrievers.SVMRetriever attribute)\n",
            "remove_end_sequence (langchain.llms.NLPCloud attribute)\n",
            "remove_input (langchain.llms.NLPCloud attribute)\n",
            "repeat_last_n (langchain.llms.GPT4All attribute)\n",
            "repeat_penalty (langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "repetition_penalties_include_completion (langchain.llms.AlephAlpha attribute)\n",
            "repetition_penalties_include_prompt (langchain.llms.AlephAlpha attribute)\n",
            "repetition_penalty (langchain.llms.ForefrontAI attribute)\n",
            "(langchain.llms.NLPCloud attribute)\n",
            "(langchain.llms.Writer attribute)\n",
            "repo_id (langchain.embeddings.HuggingFaceHubEmbeddings attribute)\n",
            "(langchain.llms.HuggingFaceHub attribute)\n",
            "request_body (langchain.tools.APIOperation attribute)\n",
            "request_timeout (langchain.chat_models.ChatOpenAI attribute)\n",
            "(langchain.embeddings.OpenAIEmbeddings attribute)\n",
            "(langchain.llms.AzureOpenAI attribute)\n",
            "(langchain.llms.OpenAI attribute)\n",
            "(langchain.llms.OpenLM attribute)\n",
            "request_url (langchain.utilities.PowerBIDataset property)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "request_url (langchain.utilities.PowerBIDataset property)\n",
            "requests (langchain.chains.OpenAPIEndpointChain attribute)\n",
            "(langchain.utilities.TextRequestsWrapper property)\n",
            "requests_per_second (langchain.document_loaders.WebBaseLoader attribute)\n",
            "requests_wrapper (langchain.agents.agent_toolkits.OpenAPIToolkit attribute)\n",
            "(langchain.chains.APIChain attribute)\n",
            "(langchain.chains.LLMRequestsChain attribute)\n",
            "response_chain (langchain.chains.FlareChain attribute)\n",
            "response_key (langchain.retrievers.RemoteLangChainRetriever attribute)\n",
            "response_schemas (langchain.output_parsers.StructuredOutputParser attribute)\n",
            "results() (langchain.serpapi.SerpAPIWrapper method)\n",
            "(langchain.utilities.BingSearchAPIWrapper method)\n",
            "(langchain.utilities.DuckDuckGoSearchAPIWrapper method)\n",
            "(langchain.utilities.GoogleSearchAPIWrapper method)\n",
            "(langchain.utilities.GoogleSerperAPIWrapper method)\n",
            "(langchain.utilities.MetaphorSearchAPIWrapper method)\n",
            "(langchain.utilities.searx_search.SearxSearchWrapper method)\n",
            "(langchain.utilities.SearxSearchWrapper method)\n",
            "(langchain.utilities.SerpAPIWrapper method)\n",
            "results_async() (langchain.utilities.MetaphorSearchAPIWrapper method)\n",
            "retriever (langchain.chains.ConversationalRetrievalChain attribute)\n",
            "(langchain.chains.FlareChain attribute)\n",
            "(langchain.chains.RetrievalQA attribute)\n",
            "(langchain.chains.RetrievalQAWithSourcesChain attribute)\n",
            "(langchain.memory.VectorStoreRetrieverMemory attribute)\n",
            "retry_chain (langchain.output_parsers.OutputFixingParser attribute)\n",
            "(langchain.output_parsers.RetryOutputParser attribute)\n",
            "(langchain.output_parsers.RetryWithErrorOutputParser attribute)\n",
            "retry_sleep (langchain.embeddings.MosaicMLInstructorEmbeddings attribute)\n",
            "(langchain.llms.MosaicML attribute)\n",
            "return_all (langchain.chains.SequentialChain attribute)\n",
            "return_direct (langchain.chains.SQLDatabaseChain attribute)\n",
            "(langchain.tools.BaseTool attribute)\n",
            "(langchain.tools.Tool attribute)\n",
            "return_docs (langchain.memory.VectorStoreRetrieverMemory attribute)\n",
            "return_intermediate_steps (langchain.agents.AgentExecutor attribute)\n",
            "(langchain.chains.ConstitutionalChain attribute)\n",
            "(langchain.chains.OpenAPIEndpointChain attribute)\n",
            "(langchain.chains.PALChain attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.chains.OpenAPIEndpointChain attribute)\n",
            "(langchain.chains.PALChain attribute)\n",
            "(langchain.chains.SQLDatabaseChain attribute)\n",
            "(langchain.chains.SQLDatabaseSequentialChain attribute)\n",
            "return_pl_id (langchain.chat_models.PromptLayerChatOpenAI attribute)\n",
            "return_stopped_response() (langchain.agents.Agent method)\n",
            "(langchain.agents.BaseMultiActionAgent method)\n",
            "(langchain.agents.BaseSingleActionAgent method)\n",
            "return_urls (langchain.tools.SteamshipImageGenerationTool attribute)\n",
            "return_values (langchain.agents.Agent property)\n",
            "(langchain.agents.BaseMultiActionAgent property)\n",
            "(langchain.agents.BaseSingleActionAgent property)\n",
            "revised_answer_prompt (langchain.chains.LLMCheckerChain attribute)\n",
            "revised_summary_prompt (langchain.chains.LLMSummarizationCheckerChain attribute)\n",
            "revision_chain (langchain.chains.ConstitutionalChain attribute)\n",
            "RoamLoader (class in langchain.document_loaders)\n",
            "root_dir (langchain.agents.agent_toolkits.FileManagementToolkit attribute)\n",
            "run() (langchain.python.PythonREPL method)\n",
            "(langchain.serpapi.SerpAPIWrapper method)\n",
            "(langchain.tools.BaseTool method)\n",
            "(langchain.utilities.ArxivAPIWrapper method)\n",
            "(langchain.utilities.BashProcess method)\n",
            "(langchain.utilities.BingSearchAPIWrapper method)\n",
            "(langchain.utilities.DuckDuckGoSearchAPIWrapper method)\n",
            "(langchain.utilities.GooglePlacesAPIWrapper method)\n",
            "(langchain.utilities.GoogleSearchAPIWrapper method)\n",
            "(langchain.utilities.GoogleSerperAPIWrapper method)\n",
            "(langchain.utilities.GraphQLAPIWrapper method)\n",
            "(langchain.utilities.LambdaWrapper method)\n",
            "(langchain.utilities.OpenWeatherMapAPIWrapper method)\n",
            "(langchain.utilities.PowerBIDataset method)\n",
            "(langchain.utilities.PythonREPL method)\n",
            "(langchain.utilities.searx_search.SearxSearchWrapper method)\n",
            "(langchain.utilities.SearxSearchWrapper method)\n",
            "(langchain.utilities.SerpAPIWrapper method)\n",
            "(langchain.utilities.SparkSQL method)\n",
            "(langchain.utilities.TwilioAPIWrapper method)\n",
            "(langchain.utilities.WikipediaAPIWrapper method)\n",
            "(langchain.utilities.WolframAlphaAPIWrapper method)\n",
            "run_creation() (langchain.llms.Beam method)\n",
            "run_no_throw() (langchain.utilities.SparkSQL method)\n",
            "rwkv_verbose (langchain.llms.RWKV attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "rwkv_verbose (langchain.llms.RWKV attribute)\n",
            "S\n",
            "S3DirectoryLoader (class in langchain.document_loaders)\n",
            "S3FileLoader (class in langchain.document_loaders)\n",
            "safesearch (langchain.utilities.DuckDuckGoSearchAPIWrapper attribute)\n",
            "sample_rows_in_table_info (langchain.utilities.PowerBIDataset attribute)\n",
            "save() (langchain.agents.AgentExecutor method)\n",
            "(langchain.agents.BaseMultiActionAgent method)\n",
            "(langchain.agents.BaseSingleActionAgent method)\n",
            "(langchain.llms.AI21 method)\n",
            "(langchain.llms.AlephAlpha method)\n",
            "(langchain.llms.Anthropic method)\n",
            "(langchain.llms.Anyscale method)\n",
            "(langchain.llms.AzureOpenAI method)\n",
            "(langchain.llms.Banana method)\n",
            "(langchain.llms.Beam method)\n",
            "(langchain.llms.CerebriumAI method)\n",
            "(langchain.llms.Cohere method)\n",
            "(langchain.llms.CTransformers method)\n",
            "(langchain.llms.Databricks method)\n",
            "(langchain.llms.DeepInfra method)\n",
            "(langchain.llms.FakeListLLM method)\n",
            "(langchain.llms.ForefrontAI method)\n",
            "(langchain.llms.GooglePalm method)\n",
            "(langchain.llms.GooseAI method)\n",
            "(langchain.llms.GPT4All method)\n",
            "(langchain.llms.HuggingFaceEndpoint method)\n",
            "(langchain.llms.HuggingFaceHub method)\n",
            "(langchain.llms.HuggingFacePipeline method)\n",
            "(langchain.llms.HuggingFaceTextGenInference method)\n",
            "(langchain.llms.HumanInputLLM method)\n",
            "(langchain.llms.LlamaCpp method)\n",
            "(langchain.llms.Modal method)\n",
            "(langchain.llms.MosaicML method)\n",
            "(langchain.llms.NLPCloud method)\n",
            "(langchain.llms.OpenAI method)\n",
            "(langchain.llms.OpenAIChat method)\n",
            "(langchain.llms.OpenLM method)\n",
            "(langchain.llms.Petals method)\n",
            "(langchain.llms.PipelineAI method)\n",
            "(langchain.llms.PredictionGuard method)\n",
            "(langchain.llms.PromptLayerOpenAI method)\n",
            "(langchain.llms.PromptLayerOpenAIChat method)\n",
            "(langchain.llms.Replicate method)\n",
            "(langchain.llms.RWKV method)\n",
            "(langchain.llms.SagemakerEndpoint method)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.llms.RWKV method)\n",
            "(langchain.llms.SagemakerEndpoint method)\n",
            "(langchain.llms.SelfHostedHuggingFaceLLM method)\n",
            "(langchain.llms.SelfHostedPipeline method)\n",
            "(langchain.llms.StochasticAI method)\n",
            "(langchain.llms.VertexAI method)\n",
            "(langchain.llms.Writer method)\n",
            "(langchain.prompts.BasePromptTemplate method)\n",
            "(langchain.prompts.ChatPromptTemplate method)\n",
            "save_agent() (langchain.agents.AgentExecutor method)\n",
            "save_context() (langchain.experimental.GenerativeAgentMemory method)\n",
            "(langchain.memory.CombinedMemory method)\n",
            "(langchain.memory.ConversationEntityMemory method)\n",
            "(langchain.memory.ConversationKGMemory method)\n",
            "(langchain.memory.ConversationStringBufferMemory method)\n",
            "(langchain.memory.ConversationSummaryBufferMemory method)\n",
            "(langchain.memory.ConversationSummaryMemory method)\n",
            "(langchain.memory.ConversationTokenBufferMemory method)\n",
            "(langchain.memory.ReadOnlySharedMemory method)\n",
            "(langchain.memory.SimpleMemory method)\n",
            "(langchain.memory.VectorStoreRetrieverMemory method)\n",
            "save_local() (langchain.vectorstores.Annoy method)\n",
            "(langchain.vectorstores.FAISS method)\n",
            "schemas (langchain.utilities.PowerBIDataset attribute)\n",
            "scrape() (langchain.document_loaders.WebBaseLoader method)\n",
            "scrape_all() (langchain.document_loaders.WebBaseLoader method)\n",
            "scrape_page() (langchain.tools.ExtractHyperlinksTool static method)\n",
            "search() (langchain.docstore.InMemoryDocstore method)\n",
            "(langchain.docstore.Wikipedia method)\n",
            "(langchain.vectorstores.VectorStore method)\n",
            "search_kwargs (langchain.chains.ChatVectorDBChain attribute)\n",
            "(langchain.chains.VectorDBQA attribute)\n",
            "(langchain.chains.VectorDBQAWithSourcesChain attribute)\n",
            "(langchain.retrievers.SelfQueryRetriever attribute)\n",
            "(langchain.retrievers.TimeWeightedVectorStoreRetriever attribute)\n",
            "search_type (langchain.chains.VectorDBQA attribute)\n",
            "(langchain.retrievers.SelfQueryRetriever attribute)\n",
            "searx_host (langchain.utilities.searx_search.SearxSearchWrapper attribute)\n",
            "(langchain.utilities.SearxSearchWrapper attribute)\n",
            "SearxResults (class in langchain.utilities.searx_search)\n",
            "seed (langchain.embeddings.LlamaCppEmbeddings attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "seed (langchain.embeddings.LlamaCppEmbeddings attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "select_examples() (langchain.prompts.example_selector.LengthBasedExampleSelector method)\n",
            "(langchain.prompts.example_selector.MaxMarginalRelevanceExampleSelector method)\n",
            "(langchain.prompts.example_selector.SemanticSimilarityExampleSelector method)\n",
            "selected_tools (langchain.agents.agent_toolkits.FileManagementToolkit attribute)\n",
            "SeleniumURLLoader (class in langchain.document_loaders)\n",
            "SELF_ASK_WITH_SEARCH (langchain.agents.AgentType attribute)\n",
            "send_pdf() (langchain.document_loaders.MathpixPDFLoader method)\n",
            "SentenceTransformerEmbeddings (in module langchain.embeddings)\n",
            "sequential_chain (langchain.chains.LLMSummarizationCheckerChain attribute)\n",
            "serpapi_api_key (langchain.serpapi.SerpAPIWrapper attribute)\n",
            "(langchain.utilities.SerpAPIWrapper attribute)\n",
            "serper_api_key (langchain.utilities.GoogleSerperAPIWrapper attribute)\n",
            "service_account_key (langchain.document_loaders.GoogleDriveLoader attribute)\n",
            "service_account_path (langchain.document_loaders.GoogleApiClient attribute)\n",
            "service_name (langchain.retrievers.AzureCognitiveSearchRetriever attribute)\n",
            "session_cache (langchain.tools.QueryPowerBITool attribute)\n",
            "session_id (langchain.memory.RedisEntityStore attribute)\n",
            "set() (langchain.memory.InMemoryEntityStore method)\n",
            "(langchain.memory.RedisEntityStore method)\n",
            "settings (langchain.document_loaders.OneDriveLoader attribute)\n",
            "similarity_fn (langchain.document_transformers.EmbeddingsRedundantFilter attribute)\n",
            "(langchain.retrievers.document_compressors.EmbeddingsFilter attribute)\n",
            "similarity_search() (langchain.vectorstores.AnalyticDB method)\n",
            "(langchain.vectorstores.Annoy method)\n",
            "(langchain.vectorstores.AtlasDB method)\n",
            "(langchain.vectorstores.Chroma method)\n",
            "(langchain.vectorstores.DeepLake method)\n",
            "(langchain.vectorstores.ElasticVectorSearch method)\n",
            "(langchain.vectorstores.FAISS method)\n",
            "(langchain.vectorstores.LanceDB method)\n",
            "(langchain.vectorstores.Milvus method)\n",
            "(langchain.vectorstores.MyScale method)\n",
            "(langchain.vectorstores.OpenSearchVectorSearch method)\n",
            "(langchain.vectorstores.Pinecone method)\n",
            "(langchain.vectorstores.Qdrant method)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.vectorstores.Pinecone method)\n",
            "(langchain.vectorstores.Qdrant method)\n",
            "(langchain.vectorstores.Redis method)\n",
            "(langchain.vectorstores.SKLearnVectorStore method)\n",
            "(langchain.vectorstores.SupabaseVectorStore method)\n",
            "(langchain.vectorstores.Tair method)\n",
            "(langchain.vectorstores.Typesense method)\n",
            "(langchain.vectorstores.Vectara method)\n",
            "(langchain.vectorstores.VectorStore method)\n",
            "(langchain.vectorstores.Weaviate method)\n",
            "similarity_search_by_index() (langchain.vectorstores.Annoy method)\n",
            "similarity_search_by_text() (langchain.vectorstores.Weaviate method)\n",
            "similarity_search_by_vector() (langchain.vectorstores.AnalyticDB method)\n",
            "(langchain.vectorstores.Annoy method)\n",
            "(langchain.vectorstores.Chroma method)\n",
            "(langchain.vectorstores.DeepLake method)\n",
            "(langchain.vectorstores.FAISS method)\n",
            "(langchain.vectorstores.Milvus method)\n",
            "(langchain.vectorstores.MyScale method)\n",
            "(langchain.vectorstores.SupabaseVectorStore method)\n",
            "(langchain.vectorstores.VectorStore method)\n",
            "(langchain.vectorstores.Weaviate method)\n",
            "similarity_search_by_vector_returning_embeddings() (langchain.vectorstores.SupabaseVectorStore method)\n",
            "similarity_search_by_vector_with_relevance_scores() (langchain.vectorstores.SupabaseVectorStore method)\n",
            "similarity_search_limit_score() (langchain.vectorstores.Redis method)\n",
            "similarity_search_with_relevance_scores() (langchain.vectorstores.MyScale method)\n",
            "(langchain.vectorstores.SupabaseVectorStore method)\n",
            "(langchain.vectorstores.VectorStore method)\n",
            "similarity_search_with_score() (langchain.vectorstores.AnalyticDB method)\n",
            "(langchain.vectorstores.Annoy method)\n",
            "(langchain.vectorstores.Chroma method)\n",
            "(langchain.vectorstores.DeepLake method)\n",
            "(langchain.vectorstores.ElasticVectorSearch method)\n",
            "(langchain.vectorstores.FAISS method)\n",
            "(langchain.vectorstores.Milvus method)\n",
            "(langchain.vectorstores.OpenSearchVectorSearch method)\n",
            "(langchain.vectorstores.Pinecone method)\n",
            "(langchain.vectorstores.Qdrant method)\n",
            "(langchain.vectorstores.Redis method)\n",
            "(langchain.vectorstores.SKLearnVectorStore method)\n",
            "(langchain.vectorstores.Typesense method)\n",
            "(langchain.vectorstores.Vectara method)\n",
            "(langchain.vectorstores.Weaviate method)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.vectorstores.Vectara method)\n",
            "(langchain.vectorstores.Weaviate method)\n",
            "similarity_search_with_score_by_index() (langchain.vectorstores.Annoy method)\n",
            "similarity_search_with_score_by_vector() (langchain.vectorstores.AnalyticDB method)\n",
            "(langchain.vectorstores.Annoy method)\n",
            "(langchain.vectorstores.FAISS method)\n",
            "(langchain.vectorstores.Milvus method)\n",
            "similarity_threshold (langchain.document_transformers.EmbeddingsRedundantFilter attribute)\n",
            "(langchain.retrievers.document_compressors.EmbeddingsFilter attribute)\n",
            "since (langchain.document_loaders.GitHubIssuesLoader attribute)\n",
            "SitemapLoader (class in langchain.document_loaders)\n",
            "siterestrict (langchain.utilities.GoogleSearchAPIWrapper attribute)\n",
            "size (langchain.tools.SteamshipImageGenerationTool attribute)\n",
            "SKLearnVectorStore (class in langchain.vectorstores)\n",
            "SlackDirectoryLoader (class in langchain.document_loaders)\n",
            "sort (langchain.document_loaders.GitHubIssuesLoader attribute)\n",
            "SpacyTextSplitter (class in langchain.text_splitter)\n",
            "SparkSQL (class in langchain.utilities)\n",
            "sparse_encoder (langchain.retrievers.PineconeHybridSearchRetriever attribute)\n",
            "spec (langchain.agents.agent_toolkits.JsonToolkit attribute)\n",
            "split_documents() (langchain.text_splitter.TextSplitter method)\n",
            "split_text() (langchain.text_splitter.CharacterTextSplitter method)\n",
            "(langchain.text_splitter.NLTKTextSplitter method)\n",
            "(langchain.text_splitter.RecursiveCharacterTextSplitter method)\n",
            "(langchain.text_splitter.SpacyTextSplitter method)\n",
            "(langchain.text_splitter.TextSplitter method)\n",
            "(langchain.text_splitter.TokenTextSplitter method)\n",
            "SpreedlyLoader (class in langchain.document_loaders)\n",
            "sql_chain (langchain.chains.SQLDatabaseSequentialChain attribute)\n",
            "SRTLoader (class in langchain.document_loaders)\n",
            "start_with_retrieval (langchain.chains.FlareChain attribute)\n",
            "state (langchain.document_loaders.GitHubIssuesLoader attribute)\n",
            "status (langchain.experimental.GenerativeAgent attribute)\n",
            "steamship (langchain.tools.SteamshipImageGenerationTool attribute)\n",
            "stop (langchain.agents.LLMSingleActionAgent attribute)\n",
            "(langchain.chains.PALChain attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.chains.PALChain attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "(langchain.llms.Writer attribute)\n",
            "stop_sequences (langchain.llms.AlephAlpha attribute)\n",
            "store (langchain.memory.InMemoryEntityStore attribute)\n",
            "strategy (langchain.llms.RWKV attribute)\n",
            "stream() (langchain.llms.Anthropic method)\n",
            "(langchain.llms.AzureOpenAI method)\n",
            "(langchain.llms.LlamaCpp method)\n",
            "(langchain.llms.OpenAI method)\n",
            "(langchain.llms.OpenLM method)\n",
            "(langchain.llms.PromptLayerOpenAI method)\n",
            "streaming (langchain.chat_models.ChatOpenAI attribute)\n",
            "(langchain.llms.Anthropic attribute)\n",
            "(langchain.llms.AzureOpenAI attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "(langchain.llms.OpenAI attribute)\n",
            "(langchain.llms.OpenAIChat attribute)\n",
            "(langchain.llms.OpenLM attribute)\n",
            "(langchain.llms.PromptLayerOpenAIChat attribute)\n",
            "strip_outputs (langchain.chains.SimpleSequentialChain attribute)\n",
            "StripeLoader (class in langchain.document_loaders)\n",
            "STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION (langchain.agents.AgentType attribute)\n",
            "structured_query_translator (langchain.retrievers.SelfQueryRetriever attribute)\n",
            "suffix (langchain.llms.LlamaCpp attribute)\n",
            "(langchain.prompts.FewShotPromptTemplate attribute)\n",
            "(langchain.prompts.FewShotPromptWithTemplates attribute)\n",
            "summarize_related_memories() (langchain.experimental.GenerativeAgent method)\n",
            "summary (langchain.experimental.GenerativeAgent attribute)\n",
            "summary_message_cls (langchain.memory.ConversationKGMemory attribute)\n",
            "summary_refresh_seconds (langchain.experimental.GenerativeAgent attribute)\n",
            "SupabaseVectorStore (class in langchain.vectorstores)\n",
            "sync_browser (langchain.agents.agent_toolkits.PlayWrightBrowserToolkit attribute)\n",
            "T\n",
            "table (langchain.vectorstores.MyScaleSettings attribute)\n",
            "table_info (langchain.utilities.PowerBIDataset property)\n",
            "table_name (langchain.vectorstores.SupabaseVectorStore attribute)\n",
            "table_names (langchain.utilities.PowerBIDataset attribute)\n",
            "Tair (class in langchain.vectorstores)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Tair (class in langchain.vectorstores)\n",
            "task (langchain.embeddings.HuggingFaceHubEmbeddings attribute)\n",
            "(langchain.llms.HuggingFaceEndpoint attribute)\n",
            "(langchain.llms.HuggingFaceHub attribute)\n",
            "(langchain.llms.SelfHostedHuggingFaceLLM attribute)\n",
            "tbs (langchain.utilities.GoogleSerperAPIWrapper attribute)\n",
            "TelegramChatApiLoader (class in langchain.document_loaders)\n",
            "TelegramChatFileLoader (class in langchain.document_loaders)\n",
            "TelegramChatLoader (in module langchain.document_loaders)\n",
            "temp (langchain.llms.GPT4All attribute)\n",
            "temperature (langchain.chat_models.ChatGooglePalm attribute)\n",
            "(langchain.chat_models.ChatOpenAI attribute)\n",
            "(langchain.llms.AI21 attribute)\n",
            "(langchain.llms.AlephAlpha attribute)\n",
            "(langchain.llms.Anthropic attribute)\n",
            "(langchain.llms.AzureOpenAI attribute)\n",
            "(langchain.llms.Cohere attribute)\n",
            "(langchain.llms.ForefrontAI attribute)\n",
            "(langchain.llms.GooglePalm attribute)\n",
            "(langchain.llms.GooseAI attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "(langchain.llms.NLPCloud attribute)\n",
            "(langchain.llms.OpenAI attribute)\n",
            "(langchain.llms.OpenLM attribute)\n",
            "(langchain.llms.Petals attribute)\n",
            "(langchain.llms.PredictionGuard attribute)\n",
            "(langchain.llms.RWKV attribute)\n",
            "(langchain.llms.VertexAI attribute)\n",
            "(langchain.llms.Writer attribute)\n",
            "template (langchain.prompts.PromptTemplate attribute)\n",
            "(langchain.tools.QueryPowerBITool attribute)\n",
            "template_format (langchain.prompts.FewShotPromptTemplate attribute)\n",
            "(langchain.prompts.FewShotPromptWithTemplates attribute)\n",
            "(langchain.prompts.PromptTemplate attribute)\n",
            "template_tool_response (langchain.agents.ConversationalChatAgent attribute)\n",
            "text_length (langchain.chains.LLMRequestsChain attribute)\n",
            "text_splitter (langchain.chains.AnalyzeDocumentChain attribute)\n",
            "(langchain.chains.MapReduceChain attribute)\n",
            "(langchain.chains.QAGenerationChain attribute)\n",
            "TextLoader (class in langchain.document_loaders)\n",
            "texts (langchain.retrievers.KNNRetriever attribute)\n",
            "(langchain.retrievers.SVMRetriever attribute)\n",
            "TextSplitter (class in langchain.text_splitter)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "TextSplitter (class in langchain.text_splitter)\n",
            "tfidf_array (langchain.retrievers.TFIDFRetriever attribute)\n",
            "time (langchain.utilities.DuckDuckGoSearchAPIWrapper attribute)\n",
            "to_typescript() (langchain.tools.APIOperation method)\n",
            "token (langchain.llms.PredictionGuard attribute)\n",
            "(langchain.utilities.PowerBIDataset attribute)\n",
            "token_path (langchain.document_loaders.GoogleApiClient attribute)\n",
            "(langchain.document_loaders.GoogleDriveLoader attribute)\n",
            "tokenizer (langchain.llms.Petals attribute)\n",
            "tokens (langchain.llms.AlephAlpha attribute)\n",
            "tokens_path (langchain.llms.RWKV attribute)\n",
            "TokenTextSplitter (class in langchain.text_splitter)\n",
            "ToMarkdownLoader (class in langchain.document_loaders)\n",
            "TomlLoader (class in langchain.document_loaders)\n",
            "tool() (in module langchain.agents)\n",
            "(in module langchain.tools)\n",
            "tool_run_logging_kwargs() (langchain.agents.Agent method)\n",
            "(langchain.agents.BaseMultiActionAgent method)\n",
            "(langchain.agents.BaseSingleActionAgent method)\n",
            "(langchain.agents.LLMSingleActionAgent method)\n",
            "tools (langchain.agents.agent_toolkits.JiraToolkit attribute)\n",
            "(langchain.agents.agent_toolkits.ZapierToolkit attribute)\n",
            "(langchain.agents.AgentExecutor attribute)\n",
            "top_k (langchain.chains.SQLDatabaseChain attribute)\n",
            "(langchain.chat_models.ChatGooglePalm attribute)\n",
            "(langchain.llms.AlephAlpha attribute)\n",
            "(langchain.llms.Anthropic attribute)\n",
            "(langchain.llms.ForefrontAI attribute)\n",
            "(langchain.llms.GooglePalm attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "(langchain.llms.NLPCloud attribute)\n",
            "(langchain.llms.Petals attribute)\n",
            "(langchain.llms.VertexAI attribute)\n",
            "(langchain.retrievers.ChatGPTPluginRetriever attribute)\n",
            "(langchain.retrievers.DataberryRetriever attribute)\n",
            "(langchain.retrievers.PineconeHybridSearchRetriever attribute)\n",
            "top_k_docs_for_context (langchain.chains.ChatVectorDBChain attribute)\n",
            "top_k_results (langchain.utilities.ArxivAPIWrapper attribute)\n",
            "(langchain.utilities.GooglePlacesAPIWrapper attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.utilities.GooglePlacesAPIWrapper attribute)\n",
            "(langchain.utilities.WikipediaAPIWrapper attribute)\n",
            "top_n (langchain.retrievers.document_compressors.CohereRerank attribute)\n",
            "top_p (langchain.chat_models.ChatGooglePalm attribute)\n",
            "(langchain.llms.AlephAlpha attribute)\n",
            "(langchain.llms.Anthropic attribute)\n",
            "(langchain.llms.AzureOpenAI attribute)\n",
            "(langchain.llms.ForefrontAI attribute)\n",
            "(langchain.llms.GooglePalm attribute)\n",
            "(langchain.llms.GooseAI attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "(langchain.llms.NLPCloud attribute)\n",
            "(langchain.llms.OpenAI attribute)\n",
            "(langchain.llms.OpenLM attribute)\n",
            "(langchain.llms.Petals attribute)\n",
            "(langchain.llms.RWKV attribute)\n",
            "(langchain.llms.VertexAI attribute)\n",
            "(langchain.llms.Writer attribute)\n",
            "topP (langchain.llms.AI21 attribute)\n",
            "traits (langchain.experimental.GenerativeAgent attribute)\n",
            "transform (langchain.chains.TransformChain attribute)\n",
            "transform_documents() (langchain.document_transformers.EmbeddingsRedundantFilter method)\n",
            "(langchain.text_splitter.TextSplitter method)\n",
            "transform_input_fn (langchain.llms.Databricks attribute)\n",
            "transform_output_fn (langchain.llms.Databricks attribute)\n",
            "transformers (langchain.retrievers.document_compressors.DocumentCompressorPipeline attribute)\n",
            "TrelloLoader (class in langchain.document_loaders)\n",
            "truncate (langchain.embeddings.CohereEmbeddings attribute)\n",
            "(langchain.llms.Cohere attribute)\n",
            "ts_type_from_python() (langchain.tools.APIOperation static method)\n",
            "ttl (langchain.memory.RedisEntityStore attribute)\n",
            "tuned_model_name (langchain.llms.VertexAI attribute)\n",
            "TwitterTweetLoader (class in langchain.document_loaders)\n",
            "type (langchain.utilities.GoogleSerperAPIWrapper attribute)\n",
            "Typesense (class in langchain.vectorstores)\n",
            "U\n",
            "unsecure (langchain.utilities.searx_search.SearxSearchWrapper attribute)\n",
            "(langchain.utilities.SearxSearchWrapper attribute)\n",
            "UnstructuredAPIFileIOLoader (class in langchain.document_loaders)\n",
            "UnstructuredAPIFileLoader (class in langchain.document_loaders)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "UnstructuredAPIFileLoader (class in langchain.document_loaders)\n",
            "UnstructuredEmailLoader (class in langchain.document_loaders)\n",
            "UnstructuredEPubLoader (class in langchain.document_loaders)\n",
            "UnstructuredFileIOLoader (class in langchain.document_loaders)\n",
            "UnstructuredFileLoader (class in langchain.document_loaders)\n",
            "UnstructuredHTMLLoader (class in langchain.document_loaders)\n",
            "UnstructuredImageLoader (class in langchain.document_loaders)\n",
            "UnstructuredMarkdownLoader (class in langchain.document_loaders)\n",
            "UnstructuredODTLoader (class in langchain.document_loaders)\n",
            "UnstructuredPDFLoader (class in langchain.document_loaders)\n",
            "UnstructuredPowerPointLoader (class in langchain.document_loaders)\n",
            "UnstructuredRTFLoader (class in langchain.document_loaders)\n",
            "UnstructuredURLLoader (class in langchain.document_loaders)\n",
            "UnstructuredWordDocumentLoader (class in langchain.document_loaders)\n",
            "update_document() (langchain.vectorstores.Chroma method)\n",
            "update_forward_refs() (langchain.llms.AI21 class method)\n",
            "(langchain.llms.AlephAlpha class method)\n",
            "(langchain.llms.Anthropic class method)\n",
            "(langchain.llms.Anyscale class method)\n",
            "(langchain.llms.AzureOpenAI class method)\n",
            "(langchain.llms.Banana class method)\n",
            "(langchain.llms.Beam class method)\n",
            "(langchain.llms.CerebriumAI class method)\n",
            "(langchain.llms.Cohere class method)\n",
            "(langchain.llms.CTransformers class method)\n",
            "(langchain.llms.Databricks class method)\n",
            "(langchain.llms.DeepInfra class method)\n",
            "(langchain.llms.FakeListLLM class method)\n",
            "(langchain.llms.ForefrontAI class method)\n",
            "(langchain.llms.GooglePalm class method)\n",
            "(langchain.llms.GooseAI class method)\n",
            "(langchain.llms.GPT4All class method)\n",
            "(langchain.llms.HuggingFaceEndpoint class method)\n",
            "(langchain.llms.HuggingFaceHub class method)\n",
            "(langchain.llms.HuggingFacePipeline class method)\n",
            "(langchain.llms.HuggingFaceTextGenInference class method)\n",
            "(langchain.llms.HumanInputLLM class method)\n",
            "(langchain.llms.LlamaCpp class method)\n",
            "(langchain.llms.Modal class method)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.llms.LlamaCpp class method)\n",
            "(langchain.llms.Modal class method)\n",
            "(langchain.llms.MosaicML class method)\n",
            "(langchain.llms.NLPCloud class method)\n",
            "(langchain.llms.OpenAI class method)\n",
            "(langchain.llms.OpenAIChat class method)\n",
            "(langchain.llms.OpenLM class method)\n",
            "(langchain.llms.Petals class method)\n",
            "(langchain.llms.PipelineAI class method)\n",
            "(langchain.llms.PredictionGuard class method)\n",
            "(langchain.llms.PromptLayerOpenAI class method)\n",
            "(langchain.llms.PromptLayerOpenAIChat class method)\n",
            "(langchain.llms.Replicate class method)\n",
            "(langchain.llms.RWKV class method)\n",
            "(langchain.llms.SagemakerEndpoint class method)\n",
            "(langchain.llms.SelfHostedHuggingFaceLLM class method)\n",
            "(langchain.llms.SelfHostedPipeline class method)\n",
            "(langchain.llms.StochasticAI class method)\n",
            "(langchain.llms.VertexAI class method)\n",
            "(langchain.llms.Writer class method)\n",
            "upsert_messages() (langchain.memory.CosmosDBChatMessageHistory method)\n",
            "url (langchain.document_loaders.GitHubIssuesLoader property)\n",
            "(langchain.document_loaders.MathpixPDFLoader property)\n",
            "(langchain.llms.Beam attribute)\n",
            "(langchain.retrievers.ChatGPTPluginRetriever attribute)\n",
            "(langchain.retrievers.RemoteLangChainRetriever attribute)\n",
            "(langchain.tools.IFTTTWebhook attribute)\n",
            "urls (langchain.document_loaders.PlaywrightURLLoader attribute)\n",
            "(langchain.document_loaders.SeleniumURLLoader attribute)\n",
            "use_mlock (langchain.embeddings.LlamaCppEmbeddings attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "use_mmap (langchain.llms.LlamaCpp attribute)\n",
            "use_multiplicative_presence_penalty (langchain.llms.AlephAlpha attribute)\n",
            "use_query_checker (langchain.chains.SQLDatabaseChain attribute)\n",
            "username (langchain.vectorstores.MyScaleSettings attribute)\n",
            "V\n",
            "validate_channel_or_videoIds_is_set() (langchain.document_loaders.GoogleApiClient class method)\n",
            "(langchain.document_loaders.GoogleApiYoutubeLoader class method)\n",
            "validate_init_args() (langchain.document_loaders.ConfluenceLoader static method)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "validate_init_args() (langchain.document_loaders.ConfluenceLoader static method)\n",
            "validate_template (langchain.prompts.FewShotPromptTemplate attribute)\n",
            "(langchain.prompts.FewShotPromptWithTemplates attribute)\n",
            "(langchain.prompts.PromptTemplate attribute)\n",
            "Vectara (class in langchain.vectorstores)\n",
            "vectorizer (langchain.retrievers.TFIDFRetriever attribute)\n",
            "VectorStore (class in langchain.vectorstores)\n",
            "vectorstore (langchain.agents.agent_toolkits.VectorStoreInfo attribute)\n",
            "(langchain.chains.ChatVectorDBChain attribute)\n",
            "(langchain.chains.VectorDBQA attribute)\n",
            "(langchain.chains.VectorDBQAWithSourcesChain attribute)\n",
            "(langchain.prompts.example_selector.SemanticSimilarityExampleSelector attribute)\n",
            "(langchain.retrievers.SelfQueryRetriever attribute)\n",
            "(langchain.retrievers.TimeWeightedVectorStoreRetriever attribute)\n",
            "vectorstore_info (langchain.agents.agent_toolkits.VectorStoreToolkit attribute)\n",
            "vectorstores (langchain.agents.agent_toolkits.VectorStoreRouterToolkit attribute)\n",
            "verbose (langchain.llms.AI21 attribute)\n",
            "(langchain.llms.AlephAlpha attribute)\n",
            "(langchain.llms.Anthropic attribute)\n",
            "(langchain.llms.Anyscale attribute)\n",
            "(langchain.llms.AzureOpenAI attribute)\n",
            "(langchain.llms.Banana attribute)\n",
            "(langchain.llms.Beam attribute)\n",
            "(langchain.llms.CerebriumAI attribute)\n",
            "(langchain.llms.Cohere attribute)\n",
            "(langchain.llms.CTransformers attribute)\n",
            "(langchain.llms.Databricks attribute)\n",
            "(langchain.llms.DeepInfra attribute)\n",
            "(langchain.llms.FakeListLLM attribute)\n",
            "(langchain.llms.ForefrontAI attribute)\n",
            "(langchain.llms.GooglePalm attribute)\n",
            "(langchain.llms.GooseAI attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.HuggingFaceEndpoint attribute)\n",
            "(langchain.llms.HuggingFaceHub attribute)\n",
            "(langchain.llms.HuggingFacePipeline attribute)\n",
            "(langchain.llms.HuggingFaceTextGenInference attribute)\n",
            "(langchain.llms.HumanInputLLM attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "(langchain.llms.Modal attribute)\n",
            "(langchain.llms.MosaicML attribute)\n",
            "(langchain.llms.NLPCloud attribute)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(langchain.llms.MosaicML attribute)\n",
            "(langchain.llms.NLPCloud attribute)\n",
            "(langchain.llms.OpenAI attribute)\n",
            "(langchain.llms.OpenAIChat attribute)\n",
            "(langchain.llms.OpenLM attribute)\n",
            "(langchain.llms.Petals attribute)\n",
            "(langchain.llms.PipelineAI attribute)\n",
            "(langchain.llms.PredictionGuard attribute)\n",
            "(langchain.llms.Replicate attribute)\n",
            "(langchain.llms.RWKV attribute)\n",
            "(langchain.llms.SagemakerEndpoint attribute)\n",
            "(langchain.llms.SelfHostedHuggingFaceLLM attribute)\n",
            "(langchain.llms.SelfHostedPipeline attribute)\n",
            "(langchain.llms.StochasticAI attribute)\n",
            "(langchain.llms.VertexAI attribute)\n",
            "(langchain.llms.Writer attribute)\n",
            "(langchain.retrievers.SelfQueryRetriever attribute)\n",
            "(langchain.tools.BaseTool attribute)\n",
            "(langchain.tools.Tool attribute)\n",
            "VespaRetriever (class in langchain.retrievers)\n",
            "video_ids (langchain.document_loaders.GoogleApiYoutubeLoader attribute)\n",
            "visible_only (langchain.tools.ClickTool attribute)\n",
            "vocab_only (langchain.embeddings.LlamaCppEmbeddings attribute)\n",
            "(langchain.llms.GPT4All attribute)\n",
            "(langchain.llms.LlamaCpp attribute)\n",
            "W\n",
            "wait_for_processing() (langchain.document_loaders.MathpixPDFLoader method)\n",
            "WeatherDataLoader (class in langchain.document_loaders)\n",
            "Weaviate (class in langchain.vectorstores)\n",
            "WeaviateHybridSearchRetriever (class in langchain.retrievers)\n",
            "WeaviateHybridSearchRetriever.Config (class in langchain.retrievers)\n",
            "web_path (langchain.document_loaders.WebBaseLoader property)\n",
            "web_paths (langchain.document_loaders.WebBaseLoader attribute)\n",
            "WebBaseLoader (class in langchain.document_loaders)\n",
            "WhatsAppChatLoader (class in langchain.document_loaders)\n",
            "Wikipedia (class in langchain.docstore)\n",
            "WikipediaLoader (class in langchain.document_loaders)\n",
            "wolfram_alpha_appid (langchain.utilities.WolframAlphaAPIWrapper attribute)\n",
            "writer_api_key (langchain.llms.Writer attribute)\n",
            "writer_org_id (langchain.llms.Writer attribute)\n",
            "Y\n",
            "YoutubeLoader (class in langchain.document_loaders)\n",
            "Z\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Y\n",
            "YoutubeLoader (class in langchain.document_loaders)\n",
            "Z\n",
            "zapier_description (langchain.tools.ZapierNLARunAction attribute)\n",
            "ZepRetriever (class in langchain.retrievers)\n",
            "ZERO_SHOT_REACT_DESCRIPTION (langchain.agents.AgentType attribute)\n",
            "Zilliz (class in langchain.vectorstores)\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".rst\n",
            ".pdf\n",
            "Memory\n",
            "Memory#\n",
            "Note\n",
            "Conceptual Guide\n",
            "By default, Chains and Agents are stateless,\n",
            "meaning that they treat each incoming query independently (as are the underlying LLMs and chat models).\n",
            "In some applications (chatbots being a GREAT example) it is highly important\n",
            "to remember previous interactions, both at a short term but also at a long term level.\n",
            "The concept of “Memory” exists to do exactly that.\n",
            "LangChain provides memory components in two forms.\n",
            "First, LangChain provides helper utilities for managing and manipulating previous chat messages.\n",
            "These are designed to be modular and useful regardless of how they are used.\n",
            "Secondly, LangChain provides easy ways to incorporate these utilities into chains.\n",
            "The following sections of documentation are provided:\n",
            "Getting Started: An overview of how to get started with different types of memory.\n",
            "How-To Guides: A collection of how-to guides. These highlight different types of memory, as well as how to use memory in chains.\n",
            "Memory\n",
            "Getting Started\n",
            "How-To Guides\n",
            "previous\n",
            "Structured Output Parser\n",
            "next\n",
            "Getting Started\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".rst\n",
            ".pdf\n",
            "Indexes\n",
            " Contents \n",
            "Go Deeper\n",
            "Indexes#\n",
            "Note\n",
            "Conceptual Guide\n",
            "Indexes refer to ways to structure documents so that LLMs can best interact with them.\n",
            "This module contains utility functions for working with documents, different types of indexes, and then examples for using those indexes in chains.\n",
            "The most common way that indexes are used in chains is in a “retrieval” step.\n",
            "This step refers to taking a user’s query and returning the most relevant documents.\n",
            "We draw this distinction because (1) an index can be used for other things besides retrieval, and (2) retrieval can use other logic besides an index to find relevant documents.\n",
            "We therefore have a concept of a “Retriever” interface - this is the interface that most chains work with.\n",
            "Most of the time when we talk about indexes and retrieval we are talking about indexing and retrieving unstructured data (like text documents).\n",
            "For interacting with structured data (SQL tables, etc) or APIs, please see the corresponding use case sections for links to relevant functionality.\n",
            "The primary index and retrieval types supported by LangChain are currently centered around vector databases, and therefore\n",
            "a lot of the functionality we dive deep on those topics.\n",
            "For an overview of everything related to this, please see the below notebook for getting started:\n",
            "Getting Started\n",
            "We then provide a deep dive on the four main components.\n",
            "Document Loaders\n",
            "How to load documents from a variety of sources.\n",
            "Text Splitters\n",
            "An overview of the abstractions and implementions around splitting text.\n",
            "VectorStores\n",
            "An overview of VectorStores and the many integrations LangChain provides.\n",
            "Retrievers\n",
            "An overview of Retrievers and the implementations LangChain provides.\n",
            "Go Deeper#\n",
            "Document Loaders\n",
            "Text Splitters\n",
            "Vectorstores\n",
            "Retrievers\n",
            "previous\n",
            "Zep Memory\n",
            "next\n",
            "Getting Started\n",
            " Contents\n",
            "  \n",
            "Go Deeper\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".rst\n",
            ".pdf\n",
            "Prompts\n",
            " Contents \n",
            "Getting Started\n",
            "Go Deeper\n",
            "Prompts#\n",
            "Note\n",
            "Conceptual Guide\n",
            "The new way of programming models is through prompts.\n",
            "A “prompt” refers to the input to the model.\n",
            "This input is rarely hard coded, but rather is often constructed from multiple components.\n",
            "A PromptTemplate is responsible for the construction of this input.\n",
            "LangChain provides several classes and functions to make constructing and working with prompts easy.\n",
            "This section of documentation is split into four sections:\n",
            "LLM Prompt Templates\n",
            "How to use PromptTemplates to prompt Language Models.\n",
            "Chat Prompt Templates\n",
            "How to use PromptTemplates to prompt Chat Models.\n",
            "Example Selectors\n",
            "Often times it is useful to include examples in prompts.\n",
            "These examples can be hardcoded, but it is often more powerful if they are dynamically selected.\n",
            "This section goes over example selection.\n",
            "Output Parsers\n",
            "Language models (and Chat Models) output text.\n",
            "But many times you may want to get more structured information than just text back.\n",
            "This is where output parsers come in.\n",
            "Output Parsers are responsible for (1) instructing the model how output should be formatted,\n",
            "(2) parsing output into the desired formatting (including retrying if necessary).\n",
            "Getting Started#\n",
            "Getting Started\n",
            "Go Deeper#\n",
            "Prompt Templates\n",
            "Chat Prompt Template\n",
            "Example Selectors\n",
            "Output Parsers\n",
            "previous\n",
            "TensorflowHub\n",
            "next\n",
            "Getting Started\n",
            " Contents\n",
            "  \n",
            "Getting Started\n",
            "Go Deeper\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".rst\n",
            ".pdf\n",
            "Models\n",
            " Contents \n",
            "Getting Started\n",
            "Go Deeper\n",
            "Models#\n",
            "Note\n",
            "Conceptual Guide\n",
            "This section of the documentation deals with different types of models that are used in LangChain.\n",
            "On this page we will go over the model types at a high level,\n",
            "but we have individual pages for each model type.\n",
            "The pages contain more detailed “how-to” guides for working with that model,\n",
            "as well as a list of different model providers.\n",
            "LLMs\n",
            "Large Language Models (LLMs) are the first type of models we cover.\n",
            "These models take a text string as input, and return a text string as output.\n",
            "Chat Models\n",
            "Chat Models are the second type of models we cover.\n",
            "These models are usually backed by a language model, but their APIs are more structured.\n",
            "Specifically, these models take a list of Chat Messages as input, and return a Chat Message.\n",
            "Text Embedding Models\n",
            "The third type of models we cover are text embedding models.\n",
            "These models take text as input and return a list of floats.\n",
            "Getting Started#\n",
            "Getting Started\n",
            "Go Deeper#\n",
            "LLMs\n",
            "Chat Models\n",
            "Text Embedding Models\n",
            "previous\n",
            "Tutorials\n",
            "next\n",
            "Getting Started\n",
            " Contents\n",
            "  \n",
            "Getting Started\n",
            "Go Deeper\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".rst\n",
            ".pdf\n",
            "Chains\n",
            "Chains#\n",
            "Note\n",
            "Conceptual Guide\n",
            "Using an LLM in isolation is fine for some simple applications,\n",
            "but many more complex ones require chaining LLMs - either with each other or with other experts.\n",
            "LangChain provides a standard interface for Chains, as well as some common implementations of chains for ease of use.\n",
            "The following sections of documentation are provided:\n",
            "Getting Started: A getting started guide for chains, to get you up and running quickly.\n",
            "How-To Guides: A collection of how-to guides. These highlight how to use various types of chains.\n",
            "Reference: API reference documentation for all Chain classes.\n",
            "previous\n",
            "Zep Memory\n",
            "next\n",
            "Getting Started\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".rst\n",
            ".pdf\n",
            "Agents\n",
            " Contents \n",
            "Action Agents\n",
            "Plan-and-Execute Agents\n",
            "Agents#\n",
            "Note\n",
            "Conceptual Guide\n",
            "Some applications will require not just a predetermined chain of calls to LLMs/other tools,\n",
            "but potentially an unknown chain that depends on the user’s input.\n",
            "In these types of chains, there is a “agent” which has access to a suite of tools.\n",
            "Depending on the user input, the agent can then decide which, if any, of these tools to call.\n",
            "At the moment, there are two main types of agents:\n",
            "“Action Agents”: these agents decide an action to take and take that action one step at a time\n",
            "“Plan-and-Execute Agents”: these agents first decide a plan of actions to take, and then execute those actions one at a time.\n",
            "When should you use each one? Action Agents are more conventional, and good for small tasks.\n",
            "For more complex or long running tasks, the initial planning step helps to maintain long term objectives and focus. However, that comes at the expense of generally more calls and higher latency.\n",
            "These two agents are also not mutually exclusive - in fact, it is often best to have an Action Agent be in charge of the execution for the Plan and Execute agent.\n",
            "Action Agents#\n",
            "High level pseudocode of agents looks something like:\n",
            "Some user input is received\n",
            "The agent decides which tool - if any - to use, and what the input to that tool should be\n",
            "That tool is then called with that tool input, and an observation is recorded (this is just the output of calling that tool with that tool input)\n",
            "That history of tool, tool input, and observation is passed back into the agent, and it decides what step to take next\n",
            "This is repeated until the agent decides it no longer needs to use a tool, and then it responds directly to the user.\n",
            "The different abstractions involved in agents are as follows:\n",
            "Agent: this is where the logic of the application lives. Agents expose an interface that takes in user input along with a list of previous steps the agent has taken, and returns either an AgentAction or AgentFinish\n",
            "AgentAction corresponds to the tool to use and the input to that tool\n",
            "AgentFinish means the agent is done, and has information around what to return to the user\n",
            "3072   <class 'numpy.ndarray'>\n",
            "AgentFinish means the agent is done, and has information around what to return to the user\n",
            "Tools: these are the actions an agent can take. What tools you give an agent highly depend on what you want the agent to do\n",
            "Toolkits: these are groups of tools designed for a specific use case. For example, in order for an agent to interact with a SQL database in the best way it may need access to one tool to execute queries and another tool to inspect tables.\n",
            "Agent Executor: this wraps an agent and a list of tools. This is responsible for the loop of running the agent iteratively until the stopping criteria is met.\n",
            "The most important abstraction of the four above to understand is that of the agent.\n",
            "Although an agent can be defined in whatever way one chooses, the typical way to construct an agent is with:\n",
            "PromptTemplate: this is responsible for taking the user input and previous steps and constructing a prompt to send to the language model\n",
            "Language Model: this takes the prompt constructed by the PromptTemplate and returns some output\n",
            "Output Parser: this takes the output of the Language Model and parses it into an AgentAction or AgentFinish object.\n",
            "In this section of documentation, we first start with a Getting Started notebook to cover how to use all things related to agents in an end-to-end manner.\n",
            "We then split the documentation into the following sections:\n",
            "Tools\n",
            "In this section we cover the different types of tools LangChain supports natively.\n",
            "We then cover how to add your own tools.\n",
            "Agents\n",
            "In this section we cover the different types of agents LangChain supports natively.\n",
            "We then cover how to modify and create your own agents.\n",
            "Toolkits\n",
            "In this section we go over the various toolkits that LangChain supports out of the box,\n",
            "and how to create an agent from them.\n",
            "Agent Executor\n",
            "In this section we go over the Agent Executor class, which is responsible for calling\n",
            "the agent and tools in a loop. We go over different ways to customize this, and options you\n",
            "can use for more control.\n",
            "Go Deeper\n",
            "Tools\n",
            "Agents\n",
            "Toolkits\n",
            "Agent Executors\n",
            "Plan-and-Execute Agents#\n",
            "High level pseudocode of agents looks something like:\n",
            "Some user input is received\n",
            "The planner lists out the steps to take\n",
            "The executor goes through the list of steps, executing them\n",
            "The most typical implementation is to have the planner be a language model,\n",
            "3072   <class 'numpy.ndarray'>\n",
            "The most typical implementation is to have the planner be a language model,\n",
            "and the executor be an action agent.\n",
            "Go Deeper\n",
            "Plan and Execute\n",
            "Imports\n",
            "Tools\n",
            "Planner, Executor, and Agent\n",
            "Run Example\n",
            "previous\n",
            "Chains\n",
            "next\n",
            "Getting Started\n",
            " Contents\n",
            "  \n",
            "Action Agents\n",
            "Plan-and-Execute Agents\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Getting Started\n",
            " Contents \n",
            "ChatMessageHistory\n",
            "ConversationBufferMemory\n",
            "Using in a chain\n",
            "Saving Message History\n",
            "Getting Started#\n",
            "This notebook walks through how LangChain thinks about memory.\n",
            "Memory involves keeping a concept of state around throughout a user’s interactions with an language model. A user’s interactions with a language model are captured in the concept of ChatMessages, so this boils down to ingesting, capturing, transforming and extracting knowledge from a sequence of chat messages. There are many different ways to do this, each of which exists as its own memory type.\n",
            "In general, for each type of memory there are two ways to understanding using memory. These are the standalone functions which extract information from a sequence of messages, and then there is the way you can use this type of memory in a chain.\n",
            "Memory can return multiple pieces of information (for example, the most recent N messages and a summary of all previous messages). The returned information can either be a string or a list of messages.\n",
            "In this notebook, we will walk through the simplest form of memory: “buffer” memory, which just involves keeping a buffer of all prior messages. We will show how to use the modular utility functions here, then show how it can be used in a chain (both returning a string as well as a list of messages).\n",
            "ChatMessageHistory#\n",
            "One of the core utility classes underpinning most (if not all) memory modules is the ChatMessageHistory class. This is a super lightweight wrapper which exposes convenience methods for saving Human messages, AI messages, and then fetching them all.\n",
            "You may want to use this class directly if you are managing memory outside of a chain.\n",
            "from langchain.memory import ChatMessageHistory\n",
            "history = ChatMessageHistory()\n",
            "history.add_user_message(\"hi!\")\n",
            "history.add_ai_message(\"whats up?\")\n",
            "history.messages\n",
            "[HumanMessage(content='hi!', additional_kwargs={}),\n",
            " AIMessage(content='whats up?', additional_kwargs={})]\n",
            "ConversationBufferMemory#\n",
            "We now show how to use this simple concept in a chain. We first showcase ConversationBufferMemory which is just a wrapper around ChatMessageHistory that extracts the messages in a variable.\n",
            "We can first extract it as a string.\n",
            "from langchain.memory import ConversationBufferMemory\n",
            "memory = ConversationBufferMemory()\n",
            "memory.chat_memory.add_user_message(\"hi!\")\n",
            "3072   <class 'numpy.ndarray'>\n",
            "memory = ConversationBufferMemory()\n",
            "memory.chat_memory.add_user_message(\"hi!\")\n",
            "memory.chat_memory.add_ai_message(\"whats up?\")\n",
            "memory.load_memory_variables({})\n",
            "{'history': 'Human: hi!\\nAI: whats up?'}\n",
            "We can also get the history as a list of messages\n",
            "memory = ConversationBufferMemory(return_messages=True)\n",
            "memory.chat_memory.add_user_message(\"hi!\")\n",
            "memory.chat_memory.add_ai_message(\"whats up?\")\n",
            "memory.load_memory_variables({})\n",
            "{'history': [HumanMessage(content='hi!', additional_kwargs={}),\n",
            "  AIMessage(content='whats up?', additional_kwargs={})]}\n",
            "Using in a chain#\n",
            "Finally, let’s take a look at using this in a chain (setting verbose=True so we can see the prompt).\n",
            "from langchain.llms import OpenAI\n",
            "from langchain.chains import ConversationChain\n",
            "llm = OpenAI(temperature=0)\n",
            "conversation = ConversationChain(\n",
            "    llm=llm, \n",
            "    verbose=True, \n",
            "    memory=ConversationBufferMemory()\n",
            ")\n",
            "conversation.predict(input=\"Hi there!\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Hi there! It's nice to meet you. How can I help you today?\"\n",
            "conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
            "Human: I'm doing well! Just having a conversation with an AI.\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\"\n",
            "3072   <class 'numpy.ndarray'>\n",
            "conversation.predict(input=\"Tell me about yourself.\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
            "Human: I'm doing well! Just having a conversation with an AI.\n",
            "AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n",
            "Human: Tell me about yourself.\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Sure! I'm an AI created to help people with their everyday tasks. I'm programmed to understand natural language and provide helpful information. I'm also constantly learning and updating my knowledge base so I can provide more accurate and helpful answers.\"\n",
            "Saving Message History#\n",
            "You may often have to save messages, and then load them to use again. This can be done easily by first converting the messages to normal python dictionaries, saving those (as json or something) and then loading those. Here is an example of doing that.\n",
            "import json\n",
            "from langchain.memory import ChatMessageHistory\n",
            "from langchain.schema import messages_from_dict, messages_to_dict\n",
            "history = ChatMessageHistory()\n",
            "history.add_user_message(\"hi!\")\n",
            "history.add_ai_message(\"whats up?\")\n",
            "dicts = messages_to_dict(history.messages)\n",
            "dicts\n",
            "[{'type': 'human', 'data': {'content': 'hi!', 'additional_kwargs': {}}},\n",
            " {'type': 'ai', 'data': {'content': 'whats up?', 'additional_kwargs': {}}}]\n",
            "new_messages = messages_from_dict(dicts)\n",
            "new_messages\n",
            "[HumanMessage(content='hi!', additional_kwargs={}),\n",
            " AIMessage(content='whats up?', additional_kwargs={})]\n",
            "And that’s it for the getting started! There are plenty of different types of memory, check out our examples to see them all\n",
            "previous\n",
            "Memory\n",
            "next\n",
            "How-To Guides\n",
            " Contents\n",
            "  \n",
            "ChatMessageHistory\n",
            "ConversationBufferMemory\n",
            "Using in a chain\n",
            "Saving Message History\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".rst\n",
            ".pdf\n",
            "How-To Guides\n",
            " Contents \n",
            "Types\n",
            "Usage\n",
            "How-To Guides#\n",
            "Types#\n",
            "The first set of examples all highlight different types of memory.\n",
            "ConversationBufferMemory\n",
            "ConversationBufferWindowMemory\n",
            "Entity Memory\n",
            "Conversation Knowledge Graph Memory\n",
            "ConversationSummaryMemory\n",
            "ConversationSummaryBufferMemory\n",
            "ConversationTokenBufferMemory\n",
            "VectorStore-Backed Memory\n",
            "Usage#\n",
            "The examples here all highlight how to use memory in different ways.\n",
            "How to add Memory to an LLMChain\n",
            "How to add memory to a Multi-Input Chain\n",
            "How to add Memory to an Agent\n",
            "Adding Message Memory backed by a database to an Agent\n",
            "Cassandra Chat Message History\n",
            "How to customize conversational memory\n",
            "How to create a custom Memory class\n",
            "Dynamodb Chat Message History\n",
            "Momento\n",
            "Mongodb Chat Message History\n",
            "Motörhead Memory\n",
            "How to use multiple memory classes in the same chain\n",
            "Postgres Chat Message History\n",
            "Redis Chat Message History\n",
            "Zep Memory\n",
            "previous\n",
            "Getting Started\n",
            "next\n",
            "ConversationBufferMemory\n",
            " Contents\n",
            "  \n",
            "Types\n",
            "Usage\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Entity Memory\n",
            " Contents \n",
            "Using in a chain\n",
            "Inspecting the memory store\n",
            "Entity Memory#\n",
            "This notebook shows how to work with a memory module that remembers things about specific entities. It extracts information on entities (using LLMs) and builds up its knowledge about that entity over time (also using LLMs).\n",
            "Let’s first walk through using this functionality.\n",
            "from langchain.llms import OpenAI\n",
            "from langchain.memory import ConversationEntityMemory\n",
            "llm = OpenAI(temperature=0)\n",
            "memory = ConversationEntityMemory(llm=llm)\n",
            "_input = {\"input\": \"Deven & Sam are working on a hackathon project\"}\n",
            "memory.load_memory_variables(_input)\n",
            "memory.save_context(\n",
            "    _input,\n",
            "    {\"output\": \" That sounds like a great project! What kind of project are they working on?\"}\n",
            ")\n",
            "memory.load_memory_variables({\"input\": 'who is Sam'})\n",
            "{'history': 'Human: Deven & Sam are working on a hackathon project\\nAI:  That sounds like a great project! What kind of project are they working on?',\n",
            " 'entities': {'Sam': 'Sam is working on a hackathon project with Deven.'}}\n",
            "memory = ConversationEntityMemory(llm=llm, return_messages=True)\n",
            "_input = {\"input\": \"Deven & Sam are working on a hackathon project\"}\n",
            "memory.load_memory_variables(_input)\n",
            "memory.save_context(\n",
            "    _input,\n",
            "    {\"output\": \" That sounds like a great project! What kind of project are they working on?\"}\n",
            ")\n",
            "memory.load_memory_variables({\"input\": 'who is Sam'})\n",
            "{'history': [HumanMessage(content='Deven & Sam are working on a hackathon project', additional_kwargs={}),\n",
            "  AIMessage(content=' That sounds like a great project! What kind of project are they working on?', additional_kwargs={})],\n",
            " 'entities': {'Sam': 'Sam is working on a hackathon project with Deven.'}}\n",
            "Using in a chain#\n",
            "Let’s now use it in a chain!\n",
            "from langchain.chains import ConversationChain\n",
            "from langchain.memory import ConversationEntityMemory\n",
            "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
            "from pydantic import BaseModel\n",
            "from typing import List, Dict, Any\n",
            "conversation = ConversationChain(\n",
            "    llm=llm,\n",
            "3072   <class 'numpy.ndarray'>\n",
            "conversation = ConversationChain(\n",
            "    llm=llm, \n",
            "    verbose=True,\n",
            "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
            "    memory=ConversationEntityMemory(llm=llm)\n",
            ")\n",
            "conversation.predict(input=\"Deven & Sam are working on a hackathon project\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "Context:\n",
            "{'Deven': 'Deven is working on a hackathon project with Sam.', 'Sam': 'Sam is working on a hackathon project with Deven.'}\n",
            "Current conversation:\n",
            "Last line:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "You:\n",
            "> Finished chain.\n",
            "' That sounds like a great project! What kind of project are they working on?'\n",
            "conversation.memory.entity_store.store\n",
            "{'Deven': 'Deven is working on a hackathon project with Sam, which they are entering into a hackathon.',\n",
            " 'Sam': 'Sam is working on a hackathon project with Deven.'}\n",
            "conversation.predict(input=\"They are trying to add more complex memory structures to Langchain\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "3072   <class 'numpy.ndarray'>\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "Context:\n",
            "{'Deven': 'Deven is working on a hackathon project with Sam, which they are entering into a hackathon.', 'Sam': 'Sam is working on a hackathon project with Deven.', 'Langchain': ''}\n",
            "Current conversation:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "AI:  That sounds like a great project! What kind of project are they working on?\n",
            "Last line:\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "You:\n",
            "> Finished chain.\n",
            "' That sounds like an interesting project! What kind of memory structures are they trying to add?'\n",
            "conversation.predict(input=\"They are adding in a key-value store for entities mentioned so far in the conversation.\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "Context:\n",
            "{'Deven': 'Deven is working on a hackathon project with Sam, which they are entering into a hackathon. They are trying to add more complex memory structures to Langchain.', 'Sam': 'Sam is working on a hackathon project with Deven, trying to add more complex memory structures to Langchain.', 'Langchain': 'Langchain is a project that is trying to add more complex memory structures.', 'Key-Value Store': ''}\n",
            "Current conversation:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "AI:  That sounds like a great project! What kind of project are they working on?\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI:  That sounds like an interesting project! What kind of memory structures are they trying to add?\n",
            "Last line:\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "You:\n",
            "> Finished chain.\n",
            "' That sounds like a great idea! How will the key-value store help with the project?'\n",
            "conversation.predict(input=\"What do you know about Deven & Sam?\")\n",
            "> Entering new ConversationChain chain...\n",
            "3072   <class 'numpy.ndarray'>\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "Context:\n",
            "{'Deven': 'Deven is working on a hackathon project with Sam, which they are entering into a hackathon. They are trying to add more complex memory structures to Langchain, including a key-value store for entities mentioned so far in the conversation.', 'Sam': 'Sam is working on a hackathon project with Deven, trying to add more complex memory structures to Langchain, including a key-value store for entities mentioned so far in the conversation.'}\n",
            "Current conversation:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "AI:  That sounds like a great project! What kind of project are they working on?\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI:  That sounds like an interesting project! What kind of memory structures are they trying to add?\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI:  That sounds like a great idea! How will the key-value store help with the project?\n",
            "Last line:\n",
            "Human: What do you know about Deven & Sam?\n",
            "You:\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Last line:\n",
            "Human: What do you know about Deven & Sam?\n",
            "You:\n",
            "> Finished chain.\n",
            "' Deven and Sam are working on a hackathon project together, trying to add more complex memory structures to Langchain, including a key-value store for entities mentioned so far in the conversation. They seem to be working hard on this project and have a great idea for how the key-value store can help.'\n",
            "Inspecting the memory store#\n",
            "We can also inspect the memory store directly. In the following examaples, we look at it directly, and then go through some examples of adding information and watch how it changes.\n",
            "from pprint import pprint\n",
            "pprint(conversation.memory.entity_store.store)\n",
            "{'Daimon': 'Daimon is a company founded by Sam, a successful entrepreneur.',\n",
            " 'Deven': 'Deven is working on a hackathon project with Sam, which they are '\n",
            "          'entering into a hackathon. They are trying to add more complex '\n",
            "          'memory structures to Langchain, including a key-value store for '\n",
            "          'entities mentioned so far in the conversation, and seem to be '\n",
            "          'working hard on this project with a great idea for how the '\n",
            "          'key-value store can help.',\n",
            " 'Key-Value Store': 'A key-value store is being added to the project to store '\n",
            "                    'entities mentioned in the conversation.',\n",
            " 'Langchain': 'Langchain is a project that is trying to add more complex '\n",
            "              'memory structures, including a key-value store for entities '\n",
            "              'mentioned so far in the conversation.',\n",
            " 'Sam': 'Sam is working on a hackathon project with Deven, trying to add more '\n",
            "        'complex memory structures to Langchain, including a key-value store '\n",
            "        'for entities mentioned so far in the conversation. They seem to have '\n",
            "        'a great idea for how the key-value store can help, and Sam is also '\n",
            "        'the founder of a company called Daimon.'}\n",
            "conversation.predict(input=\"Sam is the founder of a company called Daimon.\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "Context:\n",
            "{'Daimon': 'Daimon is a company founded by Sam, a successful entrepreneur.', 'Sam': 'Sam is working on a hackathon project with Deven, trying to add more complex memory structures to Langchain, including a key-value store for entities mentioned so far in the conversation. They seem to have a great idea for how the key-value store can help, and Sam is also the founder of a company called Daimon.'}\n",
            "Current conversation:\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI:  That sounds like a great idea! How will the key-value store help with the project?\n",
            "Human: What do you know about Deven & Sam?\n",
            "AI:  Deven and Sam are working on a hackathon project together, trying to add more complex memory structures to Langchain, including a key-value store for entities mentioned so far in the conversation. They seem to be working hard on this project and have a great idea for how the key-value store can help.\n",
            "Human: Sam is the founder of a company called Daimon.\n",
            "AI:\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Human: Sam is the founder of a company called Daimon.\n",
            "AI: \n",
            "That's impressive! It sounds like Sam is a very successful entrepreneur. What kind of company is Daimon?\n",
            "Last line:\n",
            "Human: Sam is the founder of a company called Daimon.\n",
            "You:\n",
            "> Finished chain.\n",
            "\" That's impressive! It sounds like Sam is a very successful entrepreneur. What kind of company is Daimon?\"\n",
            "from pprint import pprint\n",
            "pprint(conversation.memory.entity_store.store)\n",
            "{'Daimon': 'Daimon is a company founded by Sam, a successful entrepreneur, who '\n",
            "           'is working on a hackathon project with Deven to add more complex '\n",
            "           'memory structures to Langchain.',\n",
            " 'Deven': 'Deven is working on a hackathon project with Sam, which they are '\n",
            "          'entering into a hackathon. They are trying to add more complex '\n",
            "          'memory structures to Langchain, including a key-value store for '\n",
            "          'entities mentioned so far in the conversation, and seem to be '\n",
            "          'working hard on this project with a great idea for how the '\n",
            "          'key-value store can help.',\n",
            " 'Key-Value Store': 'A key-value store is being added to the project to store '\n",
            "                    'entities mentioned in the conversation.',\n",
            " 'Langchain': 'Langchain is a project that is trying to add more complex '\n",
            "              'memory structures, including a key-value store for entities '\n",
            "              'mentioned so far in the conversation.',\n",
            " 'Sam': 'Sam is working on a hackathon project with Deven, trying to add more '\n",
            "        'complex memory structures to Langchain, including a key-value store '\n",
            "        'for entities mentioned so far in the conversation. They seem to have '\n",
            "        'a great idea for how the key-value store can help, and Sam is also '\n",
            "        'the founder of a successful company called Daimon.'}\n",
            "conversation.predict(input=\"What do you know about Sam?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "Context:\n",
            "{'Deven': 'Deven is working on a hackathon project with Sam, which they are entering into a hackathon. They are trying to add more complex memory structures to Langchain, including a key-value store for entities mentioned so far in the conversation, and seem to be working hard on this project with a great idea for how the key-value store can help.', 'Sam': 'Sam is working on a hackathon project with Deven, trying to add more complex memory structures to Langchain, including a key-value store for entities mentioned so far in the conversation. They seem to have a great idea for how the key-value store can help, and Sam is also the founder of a successful company called Daimon.', 'Langchain': 'Langchain is a project that is trying to add more complex memory structures, including a key-value store for entities mentioned so far in the conversation.', 'Daimon': 'Daimon is a company founded by Sam, a successful entrepreneur, who is working on a hackathon project with Deven to add more complex memory structures to Langchain.'}\n",
            "Current conversation:\n",
            "Human: What do you know about Deven & Sam?\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Current conversation:\n",
            "Human: What do you know about Deven & Sam?\n",
            "AI:  Deven and Sam are working on a hackathon project together, trying to add more complex memory structures to Langchain, including a key-value store for entities mentioned so far in the conversation. They seem to be working hard on this project and have a great idea for how the key-value store can help.\n",
            "Human: Sam is the founder of a company called Daimon.\n",
            "AI: \n",
            "That's impressive! It sounds like Sam is a very successful entrepreneur. What kind of company is Daimon?\n",
            "Human: Sam is the founder of a company called Daimon.\n",
            "AI:  That's impressive! It sounds like Sam is a very successful entrepreneur. What kind of company is Daimon?\n",
            "Last line:\n",
            "Human: What do you know about Sam?\n",
            "You:\n",
            "> Finished chain.\n",
            "' Sam is the founder of a successful company called Daimon. He is also working on a hackathon project with Deven to add more complex memory structures to Langchain. They seem to have a great idea for how the key-value store can help.'\n",
            "previous\n",
            "ConversationBufferWindowMemory\n",
            "next\n",
            "Conversation Knowledge Graph Memory\n",
            " Contents\n",
            "  \n",
            "Using in a chain\n",
            "Inspecting the memory store\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Conversation Knowledge Graph Memory\n",
            " Contents \n",
            "Using in a chain\n",
            "Conversation Knowledge Graph Memory#\n",
            "This type of memory uses a knowledge graph to recreate memory.\n",
            "Let’s first walk through how to use the utilities\n",
            "from langchain.memory import ConversationKGMemory\n",
            "from langchain.llms import OpenAI\n",
            "llm = OpenAI(temperature=0)\n",
            "memory = ConversationKGMemory(llm=llm)\n",
            "memory.save_context({\"input\": \"say hi to sam\"}, {\"output\": \"who is sam\"})\n",
            "memory.save_context({\"input\": \"sam is a friend\"}, {\"output\": \"okay\"})\n",
            "memory.load_memory_variables({\"input\": 'who is sam'})\n",
            "{'history': 'On Sam: Sam is friend.'}\n",
            "We can also get the history as a list of messages (this is useful if you are using this with a chat model).\n",
            "memory = ConversationKGMemory(llm=llm, return_messages=True)\n",
            "memory.save_context({\"input\": \"say hi to sam\"}, {\"output\": \"who is sam\"})\n",
            "memory.save_context({\"input\": \"sam is a friend\"}, {\"output\": \"okay\"})\n",
            "memory.load_memory_variables({\"input\": 'who is sam'})\n",
            "{'history': [SystemMessage(content='On Sam: Sam is friend.', additional_kwargs={})]}\n",
            "We can also more modularly get current entities from a new message (will use previous messages as context.)\n",
            "memory.get_current_entities(\"what's Sams favorite color?\")\n",
            "['Sam']\n",
            "We can also more modularly get knowledge triplets from a new message (will use previous messages as context.)\n",
            "memory.get_knowledge_triplets(\"her favorite color is red\")\n",
            "[KnowledgeTriple(subject='Sam', predicate='favorite color', object_='red')]\n",
            "Using in a chain#\n",
            "Let’s now use this in a chain!\n",
            "llm = OpenAI(temperature=0)\n",
            "from langchain.prompts.prompt import PromptTemplate\n",
            "from langchain.chains import ConversationChain\n",
            "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "Relevant Information:\n",
            "{history}\n",
            "Conversation:\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Relevant Information:\n",
            "{history}\n",
            "Conversation:\n",
            "Human: {input}\n",
            "AI:\"\"\"\n",
            "prompt = PromptTemplate(\n",
            "    input_variables=[\"history\", \"input\"], template=template\n",
            ")\n",
            "conversation_with_kg = ConversationChain(\n",
            "    llm=llm, \n",
            "    verbose=True, \n",
            "    prompt=prompt,\n",
            "    memory=ConversationKGMemory(llm=llm)\n",
            ")\n",
            "conversation_with_kg.predict(input=\"Hi, what's up?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "Relevant Information:\n",
            "Conversation:\n",
            "Human: Hi, what's up?\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Hi there! I'm doing great. I'm currently in the process of learning about the world around me. I'm learning about different cultures, languages, and customs. It's really fascinating! How about you?\"\n",
            "conversation_with_kg.predict(input=\"My name is James and I'm helping Will. He's an engineer.\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "Relevant Information:\n",
            "Conversation:\n",
            "Human: My name is James and I'm helping Will. He's an engineer.\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Hi James, it's nice to meet you. I'm an AI and I understand you're helping Will, the engineer. What kind of engineering does he do?\"\n",
            "conversation_with_kg.predict(input=\"What do you know about Will?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "Relevant Information:\n",
            "On Will: Will is an engineer.\n",
            "Conversation:\n",
            "Human: What do you know about Will?\n",
            "AI:\n",
            "> Finished chain.\n",
            "' Will is an engineer.'\n",
            "previous\n",
            "Entity Memory\n",
            "next\n",
            "ConversationSummaryMemory\n",
            " Contents\n",
            "  \n",
            "Using in a chain\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "ConversationTokenBufferMemory\n",
            " Contents \n",
            "Using in a chain\n",
            "ConversationTokenBufferMemory#\n",
            "ConversationTokenBufferMemory keeps a buffer of recent interactions in memory, and uses token length rather than number of interactions to determine when to flush interactions.\n",
            "Let’s first walk through how to use the utilities\n",
            "from langchain.memory import ConversationTokenBufferMemory\n",
            "from langchain.llms import OpenAI\n",
            "llm = OpenAI()\n",
            "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=10)\n",
            "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
            "memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})\n",
            "memory.load_memory_variables({})\n",
            "{'history': 'Human: not much you\\nAI: not much'}\n",
            "We can also get the history as a list of messages (this is useful if you are using this with a chat model).\n",
            "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=10, return_messages=True)\n",
            "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
            "memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})\n",
            "Using in a chain#\n",
            "Let’s walk through an example, again setting verbose=True so we can see the prompt.\n",
            "from langchain.chains import ConversationChain\n",
            "conversation_with_summary = ConversationChain(\n",
            "    llm=llm, \n",
            "    # We set a very low max_token_limit for the purposes of testing.\n",
            "    memory=ConversationTokenBufferMemory(llm=OpenAI(), max_token_limit=60),\n",
            "    verbose=True\n",
            ")\n",
            "conversation_with_summary.predict(input=\"Hi, what's up?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi, what's up?\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Hi there! I'm doing great, just enjoying the day. How about you?\"\n",
            "conversation_with_summary.predict(input=\"Just working on writing some documentation!\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "3072   <class 'numpy.ndarray'>\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi, what's up?\n",
            "AI:  Hi there! I'm doing great, just enjoying the day. How about you?\n",
            "Human: Just working on writing some documentation!\n",
            "AI:\n",
            "> Finished chain.\n",
            "' Sounds like a productive day! What kind of documentation are you writing?'\n",
            "conversation_with_summary.predict(input=\"For LangChain! Have you heard of it?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi, what's up?\n",
            "AI:  Hi there! I'm doing great, just enjoying the day. How about you?\n",
            "Human: Just working on writing some documentation!\n",
            "AI:  Sounds like a productive day! What kind of documentation are you writing?\n",
            "Human: For LangChain! Have you heard of it?\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Yes, I have heard of LangChain! It is a decentralized language-learning platform that connects native speakers and learners in real time. Is that the documentation you're writing about?\"\n",
            "# We can see here that the buffer is updated\n",
            "conversation_with_summary.predict(input=\"Haha nope, although a lot of people confuse it for that\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: For LangChain! Have you heard of it?\n",
            "AI:  Yes, I have heard of LangChain! It is a decentralized language-learning platform that connects native speakers and learners in real time. Is that the documentation you're writing about?\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Human: Haha nope, although a lot of people confuse it for that\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Oh, I see. Is there another language learning platform you're referring to?\"\n",
            "previous\n",
            "ConversationSummaryBufferMemory\n",
            "next\n",
            "VectorStore-Backed Memory\n",
            " Contents\n",
            "  \n",
            "Using in a chain\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "ConversationBufferMemory\n",
            " Contents \n",
            "Using in a chain\n",
            "ConversationBufferMemory#\n",
            "This notebook shows how to use ConversationBufferMemory. This memory allows for storing of messages and then extracts the messages in a variable.\n",
            "We can first extract it as a string.\n",
            "from langchain.memory import ConversationBufferMemory\n",
            "memory = ConversationBufferMemory()\n",
            "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
            "memory.load_memory_variables({})\n",
            "{'history': 'Human: hi\\nAI: whats up'}\n",
            "We can also get the history as a list of messages (this is useful if you are using this with a chat model).\n",
            "memory = ConversationBufferMemory(return_messages=True)\n",
            "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
            "memory.load_memory_variables({})\n",
            "{'history': [HumanMessage(content='hi', additional_kwargs={}),\n",
            "  AIMessage(content='whats up', additional_kwargs={})]}\n",
            "Using in a chain#\n",
            "Finally, let’s take a look at using this in a chain (setting verbose=True so we can see the prompt).\n",
            "from langchain.llms import OpenAI\n",
            "from langchain.chains import ConversationChain\n",
            "llm = OpenAI(temperature=0)\n",
            "conversation = ConversationChain(\n",
            "    llm=llm, \n",
            "    verbose=True, \n",
            "    memory=ConversationBufferMemory()\n",
            ")\n",
            "conversation.predict(input=\"Hi there!\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Hi there! It's nice to meet you. How can I help you today?\"\n",
            "conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
            "Human: I'm doing well! Just having a conversation with an AI.\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\"\n",
            "conversation.predict(input=\"Tell me about yourself.\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
            "Human: I'm doing well! Just having a conversation with an AI.\n",
            "AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n",
            "Human: Tell me about yourself.\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Sure! I'm an AI created to help people with their everyday tasks. I'm programmed to understand natural language and provide helpful information. I'm also constantly learning and updating my knowledge base so I can provide more accurate and helpful answers.\"\n",
            "And that’s it for the getting started! There are plenty of different types of memory, check out our examples to see them all\n",
            "previous\n",
            "How-To Guides\n",
            "next\n",
            "ConversationBufferWindowMemory\n",
            " Contents\n",
            "  \n",
            "Using in a chain\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "ConversationSummaryMemory\n",
            " Contents \n",
            "Initializing with messages\n",
            "Using in a chain\n",
            "ConversationSummaryMemory#\n",
            "Now let’s take a look at using a slightly more complex type of memory - ConversationSummaryMemory. This type of memory creates a summary of the conversation over time. This can be useful for condensing information from the conversation over time.\n",
            "Let’s first explore the basic functionality of this type of memory.\n",
            "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
            "from langchain.llms import OpenAI\n",
            "memory = ConversationSummaryMemory(llm=OpenAI(temperature=0))\n",
            "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
            "memory.load_memory_variables({})\n",
            "{'history': '\\nThe human greets the AI, to which the AI responds.'}\n",
            "We can also get the history as a list of messages (this is useful if you are using this with a chat model).\n",
            "memory = ConversationSummaryMemory(llm=OpenAI(temperature=0), return_messages=True)\n",
            "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
            "memory.load_memory_variables({})\n",
            "{'history': [SystemMessage(content='\\nThe human greets the AI, to which the AI responds.', additional_kwargs={})]}\n",
            "We can also utilize the predict_new_summary method directly.\n",
            "messages = memory.chat_memory.messages\n",
            "previous_summary = \"\"\n",
            "memory.predict_new_summary(messages, previous_summary)\n",
            "'\\nThe human greets the AI, to which the AI responds.'\n",
            "Initializing with messages#\n",
            "If you have messages outside this class, you can easily initialize the class with ChatMessageHistory. During loading, a summary will be calculated.\n",
            "history = ChatMessageHistory()\n",
            "history.add_user_message(\"hi\")\n",
            "history.add_ai_message(\"hi there!\")\n",
            "memory = ConversationSummaryMemory.from_messages(llm=OpenAI(temperature=0), chat_memory=history, return_messages=True)\n",
            "memory.buffer\n",
            "'\\nThe human greets the AI, to which the AI responds with a friendly greeting.'\n",
            "Using in a chain#\n",
            "Let’s walk through an example of using this in a chain, again setting verbose=True so we can see the prompt.\n",
            "from langchain.llms import OpenAI\n",
            "from langchain.chains import ConversationChain\n",
            "llm = OpenAI(temperature=0)\n",
            "conversation_with_summary = ConversationChain(\n",
            "3072   <class 'numpy.ndarray'>\n",
            "llm = OpenAI(temperature=0)\n",
            "conversation_with_summary = ConversationChain(\n",
            "    llm=llm, \n",
            "    memory=ConversationSummaryMemory(llm=OpenAI()),\n",
            "    verbose=True\n",
            ")\n",
            "conversation_with_summary.predict(input=\"Hi, what's up?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi, what's up?\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Hi there! I'm doing great. I'm currently helping a customer with a technical issue. How about you?\"\n",
            "conversation_with_summary.predict(input=\"Tell me more about it!\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "The human greeted the AI and asked how it was doing. The AI replied that it was doing great and was currently helping a customer with a technical issue.\n",
            "Human: Tell me more about it!\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Sure! The customer is having trouble with their computer not connecting to the internet. I'm helping them troubleshoot the issue and figure out what the problem is. So far, we've tried resetting the router and checking the network settings, but the issue still persists. We're currently looking into other possible solutions.\"\n",
            "conversation_with_summary.predict(input=\"Very cool -- what is the scope of the project?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Current conversation:\n",
            "The human greeted the AI and asked how it was doing. The AI replied that it was doing great and was currently helping a customer with a technical issue where their computer was not connecting to the internet. The AI was troubleshooting the issue and had already tried resetting the router and checking the network settings, but the issue still persisted and they were looking into other possible solutions.\n",
            "Human: Very cool -- what is the scope of the project?\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" The scope of the project is to troubleshoot the customer's computer issue and find a solution that will allow them to connect to the internet. We are currently exploring different possibilities and have already tried resetting the router and checking the network settings, but the issue still persists.\"\n",
            "previous\n",
            "Conversation Knowledge Graph Memory\n",
            "next\n",
            "ConversationSummaryBufferMemory\n",
            " Contents\n",
            "  \n",
            "Initializing with messages\n",
            "Using in a chain\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "ConversationBufferWindowMemory\n",
            " Contents \n",
            "Using in a chain\n",
            "ConversationBufferWindowMemory#\n",
            "ConversationBufferWindowMemory keeps a list of the interactions of the conversation over time. It only uses the last K interactions. This can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large\n",
            "Let’s first explore the basic functionality of this type of memory.\n",
            "from langchain.memory import ConversationBufferWindowMemory\n",
            "memory = ConversationBufferWindowMemory( k=1)\n",
            "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
            "memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})\n",
            "memory.load_memory_variables({})\n",
            "{'history': 'Human: not much you\\nAI: not much'}\n",
            "We can also get the history as a list of messages (this is useful if you are using this with a chat model).\n",
            "memory = ConversationBufferWindowMemory( k=1, return_messages=True)\n",
            "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
            "memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})\n",
            "memory.load_memory_variables({})\n",
            "{'history': [HumanMessage(content='not much you', additional_kwargs={}),\n",
            "  AIMessage(content='not much', additional_kwargs={})]}\n",
            "Using in a chain#\n",
            "Let’s walk through an example, again setting verbose=True so we can see the prompt.\n",
            "from langchain.llms import OpenAI\n",
            "from langchain.chains import ConversationChain\n",
            "conversation_with_summary = ConversationChain(\n",
            "    llm=OpenAI(temperature=0), \n",
            "    # We set a low k=2, to only keep the last 2 interactions in memory\n",
            "    memory=ConversationBufferWindowMemory(k=2), \n",
            "    verbose=True\n",
            ")\n",
            "conversation_with_summary.predict(input=\"Hi, what's up?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi, what's up?\n",
            "AI:\n",
            "> Finished chain.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Current conversation:\n",
            "Human: Hi, what's up?\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Hi there! I'm doing great. I'm currently helping a customer with a technical issue. How about you?\"\n",
            "conversation_with_summary.predict(input=\"What's their issues?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi, what's up?\n",
            "AI:  Hi there! I'm doing great. I'm currently helping a customer with a technical issue. How about you?\n",
            "Human: What's their issues?\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" The customer is having trouble connecting to their Wi-Fi network. I'm helping them troubleshoot the issue and get them connected.\"\n",
            "conversation_with_summary.predict(input=\"Is it going well?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi, what's up?\n",
            "AI:  Hi there! I'm doing great. I'm currently helping a customer with a technical issue. How about you?\n",
            "Human: What's their issues?\n",
            "AI:  The customer is having trouble connecting to their Wi-Fi network. I'm helping them troubleshoot the issue and get them connected.\n",
            "Human: Is it going well?\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Yes, it's going well so far. We've already identified the problem and are now working on a solution.\"\n",
            "# Notice here that the first interaction does not appear.\n",
            "conversation_with_summary.predict(input=\"What's the solution?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Current conversation:\n",
            "Human: What's their issues?\n",
            "AI:  The customer is having trouble connecting to their Wi-Fi network. I'm helping them troubleshoot the issue and get them connected.\n",
            "Human: Is it going well?\n",
            "AI:  Yes, it's going well so far. We've already identified the problem and are now working on a solution.\n",
            "Human: What's the solution?\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" The solution is to reset the router and reconfigure the settings. We're currently in the process of doing that.\"\n",
            "previous\n",
            "ConversationBufferMemory\n",
            "next\n",
            "Entity Memory\n",
            " Contents\n",
            "  \n",
            "Using in a chain\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "ConversationSummaryBufferMemory\n",
            " Contents \n",
            "Using in a chain\n",
            "ConversationSummaryBufferMemory#\n",
            "ConversationSummaryBufferMemory combines the last two ideas. It keeps a buffer of recent interactions in memory, but rather than just completely flushing old interactions it compiles them into a summary and uses both. Unlike the previous implementation though, it uses token length rather than number of interactions to determine when to flush interactions.\n",
            "Let’s first walk through how to use the utilities\n",
            "from langchain.memory import ConversationSummaryBufferMemory\n",
            "from langchain.llms import OpenAI\n",
            "llm = OpenAI()\n",
            "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=10)\n",
            "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
            "memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})\n",
            "memory.load_memory_variables({})\n",
            "{'history': 'System: \\nThe human says \"hi\", and the AI responds with \"whats up\".\\nHuman: not much you\\nAI: not much'}\n",
            "We can also get the history as a list of messages (this is useful if you are using this with a chat model).\n",
            "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=10, return_messages=True)\n",
            "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
            "memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})\n",
            "We can also utilize the predict_new_summary method directly.\n",
            "messages = memory.chat_memory.messages\n",
            "previous_summary = \"\"\n",
            "memory.predict_new_summary(messages, previous_summary)\n",
            "'\\nThe human and AI state that they are not doing much.'\n",
            "Using in a chain#\n",
            "Let’s walk through an example, again setting verbose=True so we can see the prompt.\n",
            "from langchain.chains import ConversationChain\n",
            "conversation_with_summary = ConversationChain(\n",
            "    llm=llm, \n",
            "    # We set a very low max_token_limit for the purposes of testing.\n",
            "    memory=ConversationSummaryBufferMemory(llm=OpenAI(), max_token_limit=40),\n",
            "    verbose=True\n",
            ")\n",
            "conversation_with_summary.predict(input=\"Hi, what's up?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "3072   <class 'numpy.ndarray'>\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi, what's up?\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Hi there! I'm doing great. I'm learning about the latest advances in artificial intelligence. What about you?\"\n",
            "conversation_with_summary.predict(input=\"Just working on writing some documentation!\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi, what's up?\n",
            "AI:  Hi there! I'm doing great. I'm spending some time learning about the latest developments in AI technology. How about you?\n",
            "Human: Just working on writing some documentation!\n",
            "AI:\n",
            "> Finished chain.\n",
            "' That sounds like a great use of your time. Do you have experience with writing documentation?'\n",
            "# We can see here that there is a summary of the conversation and then some previous interactions\n",
            "conversation_with_summary.predict(input=\"For LangChain! Have you heard of it?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "System: \n",
            "The human asked the AI what it was up to and the AI responded that it was learning about the latest developments in AI technology.\n",
            "Human: Just working on writing some documentation!\n",
            "AI:  That sounds like a great use of your time. Do you have experience with writing documentation?\n",
            "Human: For LangChain! Have you heard of it?\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" No, I haven't heard of LangChain. Can you tell me more about it?\"\n",
            "# We can see here that the summary and the buffer are updated\n",
            "3072   <class 'numpy.ndarray'>\n",
            "# We can see here that the summary and the buffer are updated\n",
            "conversation_with_summary.predict(input=\"Haha nope, although a lot of people confuse it for that\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "System: \n",
            "The human asked the AI what it was up to and the AI responded that it was learning about the latest developments in AI technology. The human then mentioned they were writing documentation, to which the AI responded that it sounded like a great use of their time and asked if they had experience with writing documentation.\n",
            "Human: For LangChain! Have you heard of it?\n",
            "AI:  No, I haven't heard of LangChain. Can you tell me more about it?\n",
            "Human: Haha nope, although a lot of people confuse it for that\n",
            "AI:\n",
            "> Finished chain.\n",
            "' Oh, okay. What is LangChain?'\n",
            "previous\n",
            "ConversationSummaryMemory\n",
            "next\n",
            "ConversationTokenBufferMemory\n",
            " Contents\n",
            "  \n",
            "Using in a chain\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "VectorStore-Backed Memory\n",
            " Contents \n",
            "Initialize your VectorStore\n",
            "Create your the VectorStoreRetrieverMemory\n",
            "Using in a chain\n",
            "VectorStore-Backed Memory#\n",
            "VectorStoreRetrieverMemory stores memories in a VectorDB and queries the top-K most “salient” docs every time it is called.\n",
            "This differs from most of the other Memory classes in that it doesn’t explicitly track the order of interactions.\n",
            "In this case, the “docs” are previous conversation snippets. This can be useful to refer to relevant pieces of information that the AI was told earlier in the conversation.\n",
            "from datetime import datetime\n",
            "from langchain.embeddings.openai import OpenAIEmbeddings\n",
            "from langchain.llms import OpenAI\n",
            "from langchain.memory import VectorStoreRetrieverMemory\n",
            "from langchain.chains import ConversationChain\n",
            "from langchain.prompts import PromptTemplate\n",
            "Initialize your VectorStore#\n",
            "Depending on the store you choose, this step may look different. Consult the relevant VectorStore documentation for more details.\n",
            "import faiss\n",
            "from langchain.docstore import InMemoryDocstore\n",
            "from langchain.vectorstores import FAISS\n",
            "embedding_size = 1536 # Dimensions of the OpenAIEmbeddings\n",
            "index = faiss.IndexFlatL2(embedding_size)\n",
            "embedding_fn = OpenAIEmbeddings().embed_query\n",
            "vectorstore = FAISS(embedding_fn, index, InMemoryDocstore({}), {})\n",
            "Create your the VectorStoreRetrieverMemory#\n",
            "The memory object is instantiated from any VectorStoreRetriever.\n",
            "# In actual usage, you would set `k` to be a higher value, but we use k=1 to show that\n",
            "# the vector lookup still returns the semantically relevant information\n",
            "retriever = vectorstore.as_retriever(search_kwargs=dict(k=1))\n",
            "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
            "# When added to an agent, the memory object can save pertinent information from conversations or used tools\n",
            "memory.save_context({\"input\": \"My favorite food is pizza\"}, {\"output\": \"thats good to know\"})\n",
            "memory.save_context({\"input\": \"My favorite sport is soccer\"}, {\"output\": \"...\"})\n",
            "memory.save_context({\"input\": \"I don't the Celtics\"}, {\"output\": \"ok\"}) #\n",
            "3072   <class 'numpy.ndarray'>\n",
            "# Notice the first result returned is the memory pertaining to tax help, which the language model deems more semantically relevant\n",
            "# to a 1099 than the other documents, despite them both containing numbers.\n",
            "print(memory.load_memory_variables({\"prompt\": \"what sport should i watch?\"})[\"history\"])\n",
            "input: My favorite sport is soccer\n",
            "output: ...\n",
            "Using in a chain#\n",
            "Let’s walk through an example, again setting verbose=True so we can see the prompt.\n",
            "llm = OpenAI(temperature=0) # Can be any valid LLM\n",
            "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Relevant pieces of previous conversation:\n",
            "{history}\n",
            "(You do not need to use these pieces of information if not relevant)\n",
            "Current conversation:\n",
            "Human: {input}\n",
            "AI:\"\"\"\n",
            "PROMPT = PromptTemplate(\n",
            "    input_variables=[\"history\", \"input\"], template=_DEFAULT_TEMPLATE\n",
            ")\n",
            "conversation_with_summary = ConversationChain(\n",
            "    llm=llm, \n",
            "    prompt=PROMPT,\n",
            "    # We set a very low max_token_limit for the purposes of testing.\n",
            "    memory=memory,\n",
            "    verbose=True\n",
            ")\n",
            "conversation_with_summary.predict(input=\"Hi, my name is Perry, what's up?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Relevant pieces of previous conversation:\n",
            "input: My favorite food is pizza\n",
            "output: thats good to know\n",
            "(You do not need to use these pieces of information if not relevant)\n",
            "Current conversation:\n",
            "Human: Hi, my name is Perry, what's up?\n",
            "AI:\n",
            "> Finished chain.\n",
            "\" Hi Perry, I'm doing well. How about you?\"\n",
            "# Here, the basketball related content is surfaced\n",
            "conversation_with_summary.predict(input=\"what's my favorite sport?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "3072   <class 'numpy.ndarray'>\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Relevant pieces of previous conversation:\n",
            "input: My favorite sport is soccer\n",
            "output: ...\n",
            "(You do not need to use these pieces of information if not relevant)\n",
            "Current conversation:\n",
            "Human: what's my favorite sport?\n",
            "AI:\n",
            "> Finished chain.\n",
            "' You told me earlier that your favorite sport is soccer.'\n",
            "# Even though the language model is stateless, since relavent memory is fetched, it can \"reason\" about the time.\n",
            "# Timestamping memories and data is useful in general to let the agent determine temporal relevance\n",
            "conversation_with_summary.predict(input=\"Whats my favorite food\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Relevant pieces of previous conversation:\n",
            "input: My favorite food is pizza\n",
            "output: thats good to know\n",
            "(You do not need to use these pieces of information if not relevant)\n",
            "Current conversation:\n",
            "Human: Whats my favorite food\n",
            "AI:\n",
            "> Finished chain.\n",
            "' You said your favorite food is pizza.'\n",
            "# The memories from the conversation are automatically stored,\n",
            "# since this query best matches the introduction chat above,\n",
            "# the agent is able to 'remember' the user's name.\n",
            "conversation_with_summary.predict(input=\"What's my name?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Relevant pieces of previous conversation:\n",
            "input: Hi, my name is Perry, what's up?\n",
            "response:  Hi Perry, I'm doing well. How about you?\n",
            "(You do not need to use these pieces of information if not relevant)\n",
            "Current conversation:\n",
            "3072   <class 'numpy.ndarray'>\n",
            "(You do not need to use these pieces of information if not relevant)\n",
            "Current conversation:\n",
            "Human: What's my name?\n",
            "AI:\n",
            "> Finished chain.\n",
            "' Your name is Perry.'\n",
            "previous\n",
            "ConversationTokenBufferMemory\n",
            "next\n",
            "How to add Memory to an LLMChain\n",
            " Contents\n",
            "  \n",
            "Initialize your VectorStore\n",
            "Create your the VectorStoreRetrieverMemory\n",
            "Using in a chain\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Motörhead Memory\n",
            " Contents \n",
            "Setup\n",
            "Motörhead Memory#\n",
            "Motörhead is a memory server implemented in Rust. It automatically handles incremental summarization in the background and allows for stateless applications.\n",
            "Setup#\n",
            "See instructions at Motörhead for running the server locally.\n",
            "from langchain.memory.motorhead_memory import MotorheadMemory\n",
            "from langchain import OpenAI, LLMChain, PromptTemplate\n",
            "template = \"\"\"You are a chatbot having a conversation with a human.\n",
            "{chat_history}\n",
            "Human: {human_input}\n",
            "AI:\"\"\"\n",
            "prompt = PromptTemplate(\n",
            "    input_variables=[\"chat_history\", \"human_input\"], \n",
            "    template=template\n",
            ")\n",
            "memory = MotorheadMemory(\n",
            "    session_id=\"testing-1\",\n",
            "    url=\"http://localhost:8080\",\n",
            "    memory_key=\"chat_history\"\n",
            ")\n",
            "await memory.init();  # loads previous state from Motörhead 🤘\n",
            "llm_chain = LLMChain(\n",
            "    llm=OpenAI(), \n",
            "    prompt=prompt, \n",
            "    verbose=True, \n",
            "    memory=memory,\n",
            ")\n",
            "llm_chain.run(\"hi im bob\")\n",
            "> Entering new LLMChain chain...\n",
            "Prompt after formatting:\n",
            "You are a chatbot having a conversation with a human.\n",
            "Human: hi im bob\n",
            "AI:\n",
            "> Finished chain.\n",
            "' Hi Bob, nice to meet you! How are you doing today?'\n",
            "llm_chain.run(\"whats my name?\")\n",
            "> Entering new LLMChain chain...\n",
            "Prompt after formatting:\n",
            "You are a chatbot having a conversation with a human.\n",
            "Human: hi im bob\n",
            "AI:  Hi Bob, nice to meet you! How are you doing today?\n",
            "Human: whats my name?\n",
            "AI:\n",
            "> Finished chain.\n",
            "' You said your name is Bob. Is that correct?'\n",
            "llm_chain.run(\"whats for dinner?\")\n",
            "> Entering new LLMChain chain...\n",
            "Prompt after formatting:\n",
            "You are a chatbot having a conversation with a human.\n",
            "Human: hi im bob\n",
            "AI:  Hi Bob, nice to meet you! How are you doing today?\n",
            "Human: whats my name?\n",
            "AI:  You said your name is Bob. Is that correct?\n",
            "Human: whats for dinner?\n",
            "AI:\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Human: whats for dinner?\n",
            "AI:\n",
            "> Finished chain.\n",
            "\"  I'm sorry, I'm not sure what you're asking. Could you please rephrase your question?\"\n",
            "previous\n",
            "Mongodb Chat Message History\n",
            "next\n",
            "How to use multiple memory classes in the same chain\n",
            " Contents\n",
            "  \n",
            "Setup\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Adding Message Memory backed by a database to an Agent\n",
            "Adding Message Memory backed by a database to an Agent#\n",
            "This notebook goes over adding memory to an Agent where the memory uses an external message store. Before going through this notebook, please walkthrough the following notebooks, as this will build on top of both of them:\n",
            "Adding memory to an LLM Chain\n",
            "Custom Agents\n",
            "Agent with Memory\n",
            "In order to add a memory with an external message store to an agent we are going to do the following steps:\n",
            "We are going to create a RedisChatMessageHistory to connect to an external database to store the messages in.\n",
            "We are going to create an LLMChain using that chat history as memory.\n",
            "We are going to use that LLMChain to create a custom Agent.\n",
            "For the purposes of this exercise, we are going to create a simple custom Agent that has access to a search tool and utilizes the ConversationBufferMemory class.\n",
            "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
            "from langchain.memory import ConversationBufferMemory\n",
            "from langchain.memory.chat_memory import ChatMessageHistory\n",
            "from langchain.memory.chat_message_histories import RedisChatMessageHistory\n",
            "from langchain import OpenAI, LLMChain\n",
            "from langchain.utilities import GoogleSearchAPIWrapper\n",
            "search = GoogleSearchAPIWrapper()\n",
            "tools = [\n",
            "    Tool(\n",
            "        name = \"Search\",\n",
            "        func=search.run,\n",
            "        description=\"useful for when you need to answer questions about current events\"\n",
            "    )\n",
            "]\n",
            "Notice the usage of the chat_history variable in the PromptTemplate, which matches up with the dynamic key name in the ConversationBufferMemory.\n",
            "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
            "suffix = \"\"\"Begin!\"\n",
            "{chat_history}\n",
            "Question: {input}\n",
            "{agent_scratchpad}\"\"\"\n",
            "prompt = ZeroShotAgent.create_prompt(\n",
            "    tools, \n",
            "    prefix=prefix, \n",
            "    suffix=suffix, \n",
            "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
            ")\n",
            "Now we can create the ChatMessageHistory backed by the database.\n",
            "message_history = RedisChatMessageHistory(url='redis://localhost:6379/0', ttl=600, session_id='my-session')\n",
            "3072   <class 'numpy.ndarray'>\n",
            "memory = ConversationBufferMemory(memory_key=\"chat_history\", chat_memory=message_history)\n",
            "We can now construct the LLMChain, with the Memory object, and then create the agent.\n",
            "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
            "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
            "agent_chain = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)\n",
            "agent_chain.run(input=\"How many people live in canada?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "Thought: I need to find out the population of Canada\n",
            "Action: Search\n",
            "Action Input: Population of Canada\n",
            "Observation: The current population of Canada is 38,566,192 as of Saturday, December 31, 2022, based on Worldometer elaboration of the latest United Nations data. · Canada ... Additional information related to Canadian population trends can be found on Statistics Canada's Population and Demography Portal. Population of Canada (real- ... Index to the latest information from the Census of Population. This survey conducted by Statistics Canada provides a statistical portrait of Canada and its ... 14 records ... Estimated number of persons by quarter of a year and by year, Canada, provinces and territories. The 2021 Canadian census counted a total population of 36,991,981, an increase of around 5.2 percent over the 2016 figure. ... Between 1990 and 2008, the ... ( 2 ) Census reports and other statistical publications from national statistical offices, ( 3 ) Eurostat: Demographic Statistics, ( 4 ) United Nations ... Canada is a country in North America. Its ten provinces and three territories extend from ... Population. • Q4 2022 estimate. 39,292,355 (37th). Information is available for the total Indigenous population and each of the three ... The term 'Aboriginal' or 'Indigenous' used on the Statistics Canada ... Jun 14, 2022 ... Determinants of health are the broad range of personal, social, economic and environmental factors that determine individual and population ... COVID-19 vaccination coverage across Canada by demographics and key populations. Updated every Friday at 12:00 PM Eastern Time.\n",
            "Thought: I now know the final answer\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Thought: I now know the final answer\n",
            "Final Answer: The current population of Canada is 38,566,192 as of Saturday, December 31, 2022, based on Worldometer elaboration of the latest United Nations data.\n",
            "> Finished AgentExecutor chain.\n",
            "'The current population of Canada is 38,566,192 as of Saturday, December 31, 2022, based on Worldometer elaboration of the latest United Nations data.'\n",
            "To test the memory of this agent, we can ask a followup question that relies on information in the previous exchange to be answered correctly.\n",
            "agent_chain.run(input=\"what is their national anthem called?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "Thought: I need to find out what the national anthem of Canada is called.\n",
            "Action: Search\n",
            "Action Input: National Anthem of Canada\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Action: Search\n",
            "Action Input: National Anthem of Canada\n",
            "Observation: Jun 7, 2010 ... https://twitter.com/CanadaImmigrantCanadian National Anthem O Canada in HQ - complete with lyrics, captions, vocals & music.LYRICS:O Canada! Nov 23, 2022 ... After 100 years of tradition, O Canada was proclaimed Canada's national anthem in 1980. The music for O Canada was composed in 1880 by Calixa ... O Canada, national anthem of Canada. It was proclaimed the official national anthem on July 1, 1980. “God Save the Queen” remains the royal anthem of Canada ... O Canada! Our home and native land! True patriot love in all of us command. Car ton bras sait porter l'épée,. Il sait porter la croix! \"O Canada\" (French: Ô Canada) is the national anthem of Canada. The song was originally commissioned by Lieutenant Governor of Quebec Théodore Robitaille ... Feb 1, 2018 ... It was a simple tweak — just two words. But with that, Canada just voted to make its national anthem, “O Canada,” gender neutral, ... \"O Canada\" was proclaimed Canada's national anthem on July 1,. 1980, 100 years after it was first sung on June 24, 1880. The music. Patriotic music in Canada dates back over 200 years as a distinct category from British or French patriotism, preceding the first legal steps to ... Feb 4, 2022 ... English version: O Canada! Our home and native land! True patriot love in all of us command. With glowing hearts we ... Feb 1, 2018 ... Canada's Senate has passed a bill making the country's national anthem gender-neutral. If you're not familiar with the words to “O Canada,” ...\n",
            "Thought: I now know the final answer.\n",
            "Final Answer: The national anthem of Canada is called \"O Canada\".\n",
            "> Finished AgentExecutor chain.\n",
            "'The national anthem of Canada is called \"O Canada\".'\n",
            "We can see that the agent remembered that the previous question was about Canada, and properly asked Google Search what the name of Canada’s national anthem was.\n",
            "For fun, let’s compare this to an agent that does NOT have memory.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "For fun, let’s compare this to an agent that does NOT have memory.\n",
            "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
            "suffix = \"\"\"Begin!\"\n",
            "Question: {input}\n",
            "{agent_scratchpad}\"\"\"\n",
            "prompt = ZeroShotAgent.create_prompt(\n",
            "    tools, \n",
            "    prefix=prefix, \n",
            "    suffix=suffix, \n",
            "    input_variables=[\"input\", \"agent_scratchpad\"]\n",
            ")\n",
            "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
            "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
            "agent_without_memory = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
            "agent_without_memory.run(\"How many people live in canada?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "Thought: I need to find out the population of Canada\n",
            "Action: Search\n",
            "Action Input: Population of Canada\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Action: Search\n",
            "Action Input: Population of Canada\n",
            "Observation: The current population of Canada is 38,566,192 as of Saturday, December 31, 2022, based on Worldometer elaboration of the latest United Nations data. · Canada ... Additional information related to Canadian population trends can be found on Statistics Canada's Population and Demography Portal. Population of Canada (real- ... Index to the latest information from the Census of Population. This survey conducted by Statistics Canada provides a statistical portrait of Canada and its ... 14 records ... Estimated number of persons by quarter of a year and by year, Canada, provinces and territories. The 2021 Canadian census counted a total population of 36,991,981, an increase of around 5.2 percent over the 2016 figure. ... Between 1990 and 2008, the ... ( 2 ) Census reports and other statistical publications from national statistical offices, ( 3 ) Eurostat: Demographic Statistics, ( 4 ) United Nations ... Canada is a country in North America. Its ten provinces and three territories extend from ... Population. • Q4 2022 estimate. 39,292,355 (37th). Information is available for the total Indigenous population and each of the three ... The term 'Aboriginal' or 'Indigenous' used on the Statistics Canada ... Jun 14, 2022 ... Determinants of health are the broad range of personal, social, economic and environmental factors that determine individual and population ... COVID-19 vaccination coverage across Canada by demographics and key populations. Updated every Friday at 12:00 PM Eastern Time.\n",
            "Thought: I now know the final answer\n",
            "Final Answer: The current population of Canada is 38,566,192 as of Saturday, December 31, 2022, based on Worldometer elaboration of the latest United Nations data.\n",
            "> Finished AgentExecutor chain.\n",
            "'The current population of Canada is 38,566,192 as of Saturday, December 31, 2022, based on Worldometer elaboration of the latest United Nations data.'\n",
            "agent_without_memory.run(\"what is their national anthem called?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "Thought: I should look up the answer\n",
            "Action: Search\n",
            "Action Input: national anthem of [country]\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Action: Search\n",
            "Action Input: national anthem of [country]\n",
            "Observation: Most nation states have an anthem, defined as \"a song, as of praise, devotion, or patriotism\"; most anthems are either marches or hymns in style. List of all countries around the world with its national anthem. ... Title and lyrics in the language of the country and translated into English, Aug 1, 2021 ... 1. Afghanistan, \"Milli Surood\" (National Anthem) · 2. Armenia, \"Mer Hayrenik\" (Our Fatherland) · 3. Azerbaijan (a transcontinental country with ... A national anthem is a patriotic musical composition symbolizing and evoking eulogies of the history and traditions of a country or nation. National Anthem of Every Country ; Fiji, “Meda Dau Doka” (“God Bless Fiji”) ; Finland, “Maamme”. (“Our Land”) ; France, “La Marseillaise” (“The Marseillaise”). You can find an anthem in the menu at the top alphabetically or you can use the search feature. This site is focussed on the scholarly study of national anthems ... Feb 13, 2022 ... The 38-year-old country music artist had the honor of singing the National Anthem during this year's big game, and she did not disappoint. Oldest of the World's National Anthems ; France, La Marseillaise (“The Marseillaise”), 1795 ; Argentina, Himno Nacional Argentino (“Argentine National Anthem”) ... Mar 3, 2022 ... Country music star Jessie James Decker gained the respect of music and hockey fans alike after a jaw-dropping rendition of \"The Star-Spangled ... This list shows the country on the left, the national anthem in the ... There are many countries over the world who have a national anthem of their own.\n",
            "Thought: I now know the final answer\n",
            "Final Answer: The national anthem of [country] is [name of anthem].\n",
            "> Finished AgentExecutor chain.\n",
            "'The national anthem of [country] is [name of anthem].'\n",
            "previous\n",
            "How to add Memory to an Agent\n",
            "next\n",
            "Cassandra Chat Message History\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "How to create a custom Memory class\n",
            "How to create a custom Memory class#\n",
            "Although there are a few predefined types of memory in LangChain, it is highly possible you will want to add your own type of memory that is optimal for your application. This notebook covers how to do that.\n",
            "For this notebook, we will add a custom memory type to ConversationChain. In order to add a custom memory class, we need to import the base memory class and subclass it.\n",
            "from langchain import OpenAI, ConversationChain\n",
            "from langchain.schema import BaseMemory\n",
            "from pydantic import BaseModel\n",
            "from typing import List, Dict, Any\n",
            "In this example, we will write a custom memory class that uses spacy to extract entities and save information about them in a simple hash table. Then, during the conversation, we will look at the input text, extract any entities, and put any information about them into the context.\n",
            "Please note that this implementation is pretty simple and brittle and probably not useful in a production setting. Its purpose is to showcase that you can add custom memory implementations.\n",
            "For this, we will need spacy.\n",
            "# !pip install spacy\n",
            "# !python -m spacy download en_core_web_lg\n",
            "import spacy\n",
            "nlp = spacy.load('en_core_web_lg')\n",
            "class SpacyEntityMemory(BaseMemory, BaseModel):\n",
            "    \"\"\"Memory class for storing information about entities.\"\"\"\n",
            "    # Define dictionary to store information about entities.\n",
            "    entities: dict = {}\n",
            "    # Define key to pass information about entities into prompt.\n",
            "    memory_key: str = \"entities\"\n",
            "        \n",
            "    def clear(self):\n",
            "        self.entities = {}\n",
            "    @property\n",
            "    def memory_variables(self) -> List[str]:\n",
            "        \"\"\"Define the variables we are providing to the prompt.\"\"\"\n",
            "        return [self.memory_key]\n",
            "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, str]:\n",
            "        \"\"\"Load the memory variables, in this case the entity key.\"\"\"\n",
            "        # Get the input text and run through spacy\n",
            "        doc = nlp(inputs[list(inputs.keys())[0]])\n",
            "        # Extract known information about entities, if they exist.\n",
            "        entities = [self.entities[str(ent)] for ent in doc.ents if str(ent) in self.entities]\n",
            "        # Return combined information about entities to put into context.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "# Return combined information about entities to put into context.\n",
            "        return {self.memory_key: \"\\n\".join(entities)}\n",
            "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
            "        \"\"\"Save context from this conversation to buffer.\"\"\"\n",
            "        # Get the input text and run through spacy\n",
            "        text = inputs[list(inputs.keys())[0]]\n",
            "        doc = nlp(text)\n",
            "        # For each entity that was mentioned, save this information to the dictionary.\n",
            "        for ent in doc.ents:\n",
            "            ent_str = str(ent)\n",
            "            if ent_str in self.entities:\n",
            "                self.entities[ent_str] += f\"\\n{text}\"\n",
            "            else:\n",
            "                self.entities[ent_str] = text\n",
            "We now define a prompt that takes in information about entities as well as user input\n",
            "from langchain.prompts.prompt import PromptTemplate\n",
            "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know. You are provided with information about entities the Human mentions, if relevant.\n",
            "Relevant entity information:\n",
            "{entities}\n",
            "Conversation:\n",
            "Human: {input}\n",
            "AI:\"\"\"\n",
            "prompt = PromptTemplate(\n",
            "    input_variables=[\"entities\", \"input\"], template=template\n",
            ")\n",
            "And now we put it all together!\n",
            "llm = OpenAI(temperature=0)\n",
            "conversation = ConversationChain(llm=llm, prompt=prompt, verbose=True, memory=SpacyEntityMemory())\n",
            "In the first example, with no prior knowledge about Harrison, the “Relevant entity information” section is empty.\n",
            "conversation.predict(input=\"Harrison likes machine learning\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know. You are provided with information about entities the Human mentions, if relevant.\n",
            "Relevant entity information:\n",
            "Conversation:\n",
            "Human: Harrison likes machine learning\n",
            "AI:\n",
            "> Finished ConversationChain chain.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Conversation:\n",
            "Human: Harrison likes machine learning\n",
            "AI:\n",
            "> Finished ConversationChain chain.\n",
            "\" That's great to hear! Machine learning is a fascinating field of study. It involves using algorithms to analyze data and make predictions. Have you ever studied machine learning, Harrison?\"\n",
            "Now in the second example, we can see that it pulls in information about Harrison.\n",
            "conversation.predict(input=\"What do you think Harrison's favorite subject in college was?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know. You are provided with information about entities the Human mentions, if relevant.\n",
            "Relevant entity information:\n",
            "Harrison likes machine learning\n",
            "Conversation:\n",
            "Human: What do you think Harrison's favorite subject in college was?\n",
            "AI:\n",
            "> Finished ConversationChain chain.\n",
            "' From what I know about Harrison, I believe his favorite subject in college was machine learning. He has expressed a strong interest in the subject and has mentioned it often.'\n",
            "Again, please note that this implementation is pretty simple and brittle and probably not useful in a production setting. Its purpose is to showcase that you can add custom memory implementations.\n",
            "previous\n",
            "How to customize conversational memory\n",
            "next\n",
            "Dynamodb Chat Message History\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "How to customize conversational memory\n",
            " Contents \n",
            "AI Prefix\n",
            "Human Prefix\n",
            "How to customize conversational memory#\n",
            "This notebook walks through a few ways to customize conversational memory.\n",
            "from langchain.llms import OpenAI\n",
            "from langchain.chains import ConversationChain\n",
            "from langchain.memory import ConversationBufferMemory\n",
            "llm = OpenAI(temperature=0)\n",
            "AI Prefix#\n",
            "The first way to do so is by changing the AI prefix in the conversation summary. By default, this is set to “AI”, but you can set this to be anything you want. Note that if you change this, you should also change the prompt used in the chain to reflect this naming change. Let’s walk through an example of that in the example below.\n",
            "# Here it is by default set to \"AI\"\n",
            "conversation = ConversationChain(\n",
            "    llm=llm, \n",
            "    verbose=True, \n",
            "    memory=ConversationBufferMemory()\n",
            ")\n",
            "conversation.predict(input=\"Hi there!\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:\n",
            "> Finished ConversationChain chain.\n",
            "\" Hi there! It's nice to meet you. How can I help you today?\"\n",
            "conversation.predict(input=\"What's the weather?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
            "Human: What's the weather?\n",
            "AI:\n",
            "> Finished ConversationChain chain.\n",
            "' The current weather is sunny and warm with a temperature of 75 degrees Fahrenheit. The forecast for the next few days is sunny with temperatures in the mid-70s.'\n",
            "# Now we can override it and set it to \"AI Assistant\"\n",
            "from langchain.prompts.prompt import PromptTemplate\n",
            "3072   <class 'numpy.ndarray'>\n",
            "from langchain.prompts.prompt import PromptTemplate\n",
            "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI Assistant:\"\"\"\n",
            "PROMPT = PromptTemplate(\n",
            "    input_variables=[\"history\", \"input\"], template=template\n",
            ")\n",
            "conversation = ConversationChain(\n",
            "    prompt=PROMPT,\n",
            "    llm=llm, \n",
            "    verbose=True, \n",
            "    memory=ConversationBufferMemory(ai_prefix=\"AI Assistant\")\n",
            ")\n",
            "conversation.predict(input=\"Hi there!\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI Assistant:\n",
            "> Finished ConversationChain chain.\n",
            "\" Hi there! It's nice to meet you. How can I help you today?\"\n",
            "conversation.predict(input=\"What's the weather?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI Assistant:  Hi there! It's nice to meet you. How can I help you today?\n",
            "Human: What's the weather?\n",
            "AI Assistant:\n",
            "> Finished ConversationChain chain.\n",
            "' The current weather is sunny and warm with a temperature of 75 degrees Fahrenheit. The forecast for the rest of the day is sunny with a high of 78 degrees and a low of 65 degrees.'\n",
            "Human Prefix#\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Human Prefix#\n",
            "The next way to do so is by changing the Human prefix in the conversation summary. By default, this is set to “Human”, but you can set this to be anything you want. Note that if you change this, you should also change the prompt used in the chain to reflect this naming change. Let’s walk through an example of that in the example below.\n",
            "# Now we can override it and set it to \"Friend\"\n",
            "from langchain.prompts.prompt import PromptTemplate\n",
            "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "{history}\n",
            "Friend: {input}\n",
            "AI:\"\"\"\n",
            "PROMPT = PromptTemplate(\n",
            "    input_variables=[\"history\", \"input\"], template=template\n",
            ")\n",
            "conversation = ConversationChain(\n",
            "    prompt=PROMPT,\n",
            "    llm=llm, \n",
            "    verbose=True, \n",
            "    memory=ConversationBufferMemory(human_prefix=\"Friend\")\n",
            ")\n",
            "conversation.predict(input=\"Hi there!\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Friend: Hi there!\n",
            "AI:\n",
            "> Finished ConversationChain chain.\n",
            "\" Hi there! It's nice to meet you. How can I help you today?\"\n",
            "conversation.predict(input=\"What's the weather?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Current conversation:\n",
            "Friend: Hi there!\n",
            "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
            "Friend: What's the weather?\n",
            "AI:\n",
            "> Finished ConversationChain chain.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Friend: What's the weather?\n",
            "AI:\n",
            "> Finished ConversationChain chain.\n",
            "' The weather right now is sunny and warm with a temperature of 75 degrees Fahrenheit. The forecast for the rest of the day is mostly sunny with a high of 82 degrees.'\n",
            "previous\n",
            "Cassandra Chat Message History\n",
            "next\n",
            "How to create a custom Memory class\n",
            " Contents\n",
            "  \n",
            "AI Prefix\n",
            "Human Prefix\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "How to add Memory to an LLMChain\n",
            "How to add Memory to an LLMChain#\n",
            "This notebook goes over how to use the Memory class with an LLMChain. For the purposes of this walkthrough, we will add  the ConversationBufferMemory class, although this can be any memory class.\n",
            "from langchain.memory import ConversationBufferMemory\n",
            "from langchain import OpenAI, LLMChain, PromptTemplate\n",
            "The most important step is setting up the prompt correctly. In the below prompt, we have two input keys: one for the actual input, another for the input from the Memory class. Importantly, we make sure the keys in the PromptTemplate and the ConversationBufferMemory match up (chat_history).\n",
            "template = \"\"\"You are a chatbot having a conversation with a human.\n",
            "{chat_history}\n",
            "Human: {human_input}\n",
            "Chatbot:\"\"\"\n",
            "prompt = PromptTemplate(\n",
            "    input_variables=[\"chat_history\", \"human_input\"], \n",
            "    template=template\n",
            ")\n",
            "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
            "llm_chain = LLMChain(\n",
            "    llm=OpenAI(), \n",
            "    prompt=prompt, \n",
            "    verbose=True, \n",
            "    memory=memory,\n",
            ")\n",
            "llm_chain.predict(human_input=\"Hi there my friend\")\n",
            "> Entering new LLMChain chain...\n",
            "Prompt after formatting:\n",
            "You are a chatbot having a conversation with a human.\n",
            "Human: Hi there my friend\n",
            "Chatbot:\n",
            "> Finished LLMChain chain.\n",
            "' Hi there, how are you doing today?'\n",
            "llm_chain.predict(human_input=\"Not too bad - how are you?\")\n",
            "> Entering new LLMChain chain...\n",
            "Prompt after formatting:\n",
            "You are a chatbot having a conversation with a human.\n",
            "Human: Hi there my friend\n",
            "AI:  Hi there, how are you doing today?\n",
            "Human: Not to bad - how are you?\n",
            "Chatbot:\n",
            "> Finished LLMChain chain.\n",
            "\" I'm doing great, thank you for asking!\"\n",
            "previous\n",
            "VectorStore-Backed Memory\n",
            "next\n",
            "How to add memory to a Multi-Input Chain\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Cassandra Chat Message History\n",
            "Cassandra Chat Message History#\n",
            "This notebook goes over how to use Cassandra to store chat message history.\n",
            "Cassandra is a distributed database that is well suited for storing large amounts of data.\n",
            "It is a good choice for storing chat message history because it is easy to scale and can handle a large number of writes.\n",
            "# List of contact points to try connecting to Cassandra cluster.\n",
            "contact_points = [\"cassandra\"]\n",
            "from langchain.memory import CassandraChatMessageHistory\n",
            "message_history = CassandraChatMessageHistory(\n",
            "    contact_points=contact_points, session_id=\"test-session\"\n",
            ")\n",
            "message_history.add_user_message(\"hi!\")\n",
            "message_history.add_ai_message(\"whats up?\")\n",
            "message_history.messages\n",
            "[HumanMessage(content='hi!', additional_kwargs={}, example=False),\n",
            " AIMessage(content='whats up?', additional_kwargs={}, example=False)]\n",
            "previous\n",
            "Adding Message Memory backed by a database to an Agent\n",
            "next\n",
            "How to customize conversational memory\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Momento\n",
            "Momento#\n",
            "This notebook goes over how to use Momento Cache to store chat message history using the MomentoChatMessageHistory class. See the Momento docs for more detail on how to get set up with Momento.\n",
            "Note that, by default we will create a cache if one with the given name doesn’t already exist.\n",
            "You’ll need to get a Momento auth token to use this class. This can either be passed in to a momento.CacheClient if you’d like to instantiate that directly, as a named parameter auth_token to MomentoChatMessageHistory.from_client_params, or can just be set as an environment variable MOMENTO_AUTH_TOKEN.\n",
            "from datetime import timedelta\n",
            "from langchain.memory import MomentoChatMessageHistory\n",
            "session_id = \"foo\"\n",
            "cache_name = \"langchain\"\n",
            "ttl = timedelta(days=1),\n",
            "history = MomentoChatMessageHistory.from_client_params(\n",
            "    session_id, \n",
            "    cache_name,\n",
            "    ttl,\n",
            ")\n",
            "history.add_user_message(\"hi!\")\n",
            "history.add_ai_message(\"whats up?\")\n",
            "history.messages\n",
            "[HumanMessage(content='hi!', additional_kwargs={}, example=False),\n",
            " AIMessage(content='whats up?', additional_kwargs={}, example=False)]\n",
            "previous\n",
            "Dynamodb Chat Message History\n",
            "next\n",
            "Mongodb Chat Message History\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Dynamodb Chat Message History\n",
            " Contents \n",
            "DynamoDBChatMessageHistory\n",
            "Agent with DynamoDB Memory\n",
            "Dynamodb Chat Message History#\n",
            "This notebook goes over how to use Dynamodb to store chat message history.\n",
            "First make sure you have correctly configured the AWS CLI. Then make sure you have installed boto3.\n",
            "Next, create the DynamoDB Table where we will be storing messages:\n",
            "import boto3\n",
            "# Get the service resource.\n",
            "dynamodb = boto3.resource('dynamodb')\n",
            "# Create the DynamoDB table.\n",
            "table = dynamodb.create_table(\n",
            "    TableName='SessionTable',\n",
            "    KeySchema=[\n",
            "        {\n",
            "            'AttributeName': 'SessionId',\n",
            "            'KeyType': 'HASH'\n",
            "        }\n",
            "    ],\n",
            "    AttributeDefinitions=[\n",
            "        {\n",
            "            'AttributeName': 'SessionId',\n",
            "            'AttributeType': 'S'\n",
            "        }\n",
            "    ],\n",
            "    BillingMode='PAY_PER_REQUEST',\n",
            ")\n",
            "# Wait until the table exists.\n",
            "table.meta.client.get_waiter('table_exists').wait(TableName='SessionTable')\n",
            "# Print out some data about the table.\n",
            "print(table.item_count)\n",
            "0\n",
            "DynamoDBChatMessageHistory#\n",
            "from langchain.memory.chat_message_histories import DynamoDBChatMessageHistory\n",
            "history = DynamoDBChatMessageHistory(table_name=\"SessionTable\", session_id=\"0\")\n",
            "history.add_user_message(\"hi!\")\n",
            "history.add_ai_message(\"whats up?\")\n",
            "history.messages\n",
            "[HumanMessage(content='hi!', additional_kwargs={}, example=False),\n",
            " AIMessage(content='whats up?', additional_kwargs={}, example=False)]\n",
            "Agent with DynamoDB Memory#\n",
            "from langchain.agents import Tool\n",
            "from langchain.memory import ConversationBufferMemory\n",
            "from langchain.chat_models import ChatOpenAI\n",
            "from langchain.agents import initialize_agent\n",
            "from langchain.agents import AgentType\n",
            "from langchain.utilities import PythonREPL\n",
            "from getpass import getpass\n",
            "message_history = DynamoDBChatMessageHistory(table_name=\"SessionTable\", session_id=\"1\")\n",
            "memory = ConversationBufferMemory(memory_key=\"chat_history\", chat_memory=message_history, return_messages=True)\n",
            "python_repl = PythonREPL()\n",
            "# You can create the tool to pass to an agent\n",
            "tools = [Tool(\n",
            "    name=\"python_repl\",\n",
            "3072   <class 'numpy.ndarray'>\n",
            "tools = [Tool(\n",
            "    name=\"python_repl\",\n",
            "    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n",
            "    func=python_repl.run\n",
            ")]\n",
            "llm=ChatOpenAI(temperature=0)\n",
            "agent_chain = initialize_agent(tools, llm, agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory)\n",
            "agent_chain.run(input=\"Hello!\")\n",
            "> Entering new AgentExecutor chain...\n",
            "{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"Hello! How can I assist you today?\"\n",
            "}\n",
            "> Finished chain.\n",
            "'Hello! How can I assist you today?'\n",
            "agent_chain.run(input=\"Who owns Twitter?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "{\n",
            "    \"action\": \"python_repl\",\n",
            "    \"action_input\": \"import requests\\nfrom bs4 import BeautifulSoup\\n\\nurl = 'https://en.wikipedia.org/wiki/Twitter'\\nresponse = requests.get(url)\\nsoup = BeautifulSoup(response.content, 'html.parser')\\nowner = soup.find('th', text='Owner').find_next_sibling('td').text.strip()\\nprint(owner)\"\n",
            "}\n",
            "Observation: X Corp. (2023–present)Twitter, Inc. (2006–2023)\n",
            "Thought:{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"X Corp. (2023–present)Twitter, Inc. (2006–2023)\"\n",
            "}\n",
            "> Finished chain.\n",
            "'X Corp. (2023–present)Twitter, Inc. (2006–2023)'\n",
            "agent_chain.run(input=\"My name is Bob.\")\n",
            "> Entering new AgentExecutor chain...\n",
            "{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"Hello Bob! How can I assist you today?\"\n",
            "}\n",
            "> Finished chain.\n",
            "'Hello Bob! How can I assist you today?'\n",
            "agent_chain.run(input=\"Who am I?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"Your name is Bob.\"\n",
            "}\n",
            "> Finished chain.\n",
            "'Your name is Bob.'\n",
            "previous\n",
            "3072   <class 'numpy.ndarray'>\n",
            "}\n",
            "> Finished chain.\n",
            "'Your name is Bob.'\n",
            "previous\n",
            "How to create a custom Memory class\n",
            "next\n",
            "Momento\n",
            " Contents\n",
            "  \n",
            "DynamoDBChatMessageHistory\n",
            "Agent with DynamoDB Memory\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "How to add Memory to an Agent\n",
            "How to add Memory to an Agent#\n",
            "This notebook goes over adding memory to an Agent. Before going through this notebook, please walkthrough the following notebooks, as this will build on top of both of them:\n",
            "Adding memory to an LLM Chain\n",
            "Custom Agents\n",
            "In order to add a memory to an agent we are going to the the following steps:\n",
            "We are going to create an LLMChain with memory.\n",
            "We are going to use that LLMChain to create a custom Agent.\n",
            "For the purposes of this exercise, we are going to create a simple custom Agent that has access to a search tool and utilizes the ConversationBufferMemory class.\n",
            "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
            "from langchain.memory import ConversationBufferMemory\n",
            "from langchain import OpenAI, LLMChain\n",
            "from langchain.utilities import GoogleSearchAPIWrapper\n",
            "search = GoogleSearchAPIWrapper()\n",
            "tools = [\n",
            "    Tool(\n",
            "        name = \"Search\",\n",
            "        func=search.run,\n",
            "        description=\"useful for when you need to answer questions about current events\"\n",
            "    )\n",
            "]\n",
            "Notice the usage of the chat_history variable in the PromptTemplate, which matches up with the dynamic key name in the ConversationBufferMemory.\n",
            "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
            "suffix = \"\"\"Begin!\"\n",
            "{chat_history}\n",
            "Question: {input}\n",
            "{agent_scratchpad}\"\"\"\n",
            "prompt = ZeroShotAgent.create_prompt(\n",
            "    tools, \n",
            "    prefix=prefix, \n",
            "    suffix=suffix, \n",
            "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
            ")\n",
            "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
            "We can now construct the LLMChain, with the Memory object, and then create the agent.\n",
            "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
            "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
            "agent_chain = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)\n",
            "agent_chain.run(input=\"How many people live in canada?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "3072   <class 'numpy.ndarray'>\n",
            "> Entering new AgentExecutor chain...\n",
            "Thought: I need to find out the population of Canada\n",
            "Action: Search\n",
            "Action Input: Population of Canada\n",
            "Observation: The current population of Canada is 38,566,192 as of Saturday, December 31, 2022, based on Worldometer elaboration of the latest United Nations data. · Canada ... Additional information related to Canadian population trends can be found on Statistics Canada's Population and Demography Portal. Population of Canada (real- ... Index to the latest information from the Census of Population. This survey conducted by Statistics Canada provides a statistical portrait of Canada and its ... 14 records ... Estimated number of persons by quarter of a year and by year, Canada, provinces and territories. The 2021 Canadian census counted a total population of 36,991,981, an increase of around 5.2 percent over the 2016 figure. ... Between 1990 and 2008, the ... ( 2 ) Census reports and other statistical publications from national statistical offices, ( 3 ) Eurostat: Demographic Statistics, ( 4 ) United Nations ... Canada is a country in North America. Its ten provinces and three territories extend from ... Population. • Q4 2022 estimate. 39,292,355 (37th). Information is available for the total Indigenous population and each of the three ... The term 'Aboriginal' or 'Indigenous' used on the Statistics Canada ... Jun 14, 2022 ... Determinants of health are the broad range of personal, social, economic and environmental factors that determine individual and population ... COVID-19 vaccination coverage across Canada by demographics and key populations. Updated every Friday at 12:00 PM Eastern Time.\n",
            "Thought: I now know the final answer\n",
            "Final Answer: The current population of Canada is 38,566,192 as of Saturday, December 31, 2022, based on Worldometer elaboration of the latest United Nations data.\n",
            "> Finished AgentExecutor chain.\n",
            "'The current population of Canada is 38,566,192 as of Saturday, December 31, 2022, based on Worldometer elaboration of the latest United Nations data.'\n",
            "To test the memory of this agent, we can ask a followup question that relies on information in the previous exchange to be answered correctly.\n",
            "agent_chain.run(input=\"what is their national anthem called?\")\n",
            "3072   <class 'numpy.ndarray'>\n",
            "agent_chain.run(input=\"what is their national anthem called?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "Thought: I need to find out what the national anthem of Canada is called.\n",
            "Action: Search\n",
            "Action Input: National Anthem of Canada\n",
            "Observation: Jun 7, 2010 ... https://twitter.com/CanadaImmigrantCanadian National Anthem O Canada in HQ - complete with lyrics, captions, vocals & music.LYRICS:O Canada! Nov 23, 2022 ... After 100 years of tradition, O Canada was proclaimed Canada's national anthem in 1980. The music for O Canada was composed in 1880 by Calixa ... O Canada, national anthem of Canada. It was proclaimed the official national anthem on July 1, 1980. “God Save the Queen” remains the royal anthem of Canada ... O Canada! Our home and native land! True patriot love in all of us command. Car ton bras sait porter l'épée,. Il sait porter la croix! \"O Canada\" (French: Ô Canada) is the national anthem of Canada. The song was originally commissioned by Lieutenant Governor of Quebec Théodore Robitaille ... Feb 1, 2018 ... It was a simple tweak — just two words. But with that, Canada just voted to make its national anthem, “O Canada,” gender neutral, ... \"O Canada\" was proclaimed Canada's national anthem on July 1,. 1980, 100 years after it was first sung on June 24, 1880. The music. Patriotic music in Canada dates back over 200 years as a distinct category from British or French patriotism, preceding the first legal steps to ... Feb 4, 2022 ... English version: O Canada! Our home and native land! True patriot love in all of us command. With glowing hearts we ... Feb 1, 2018 ... Canada's Senate has passed a bill making the country's national anthem gender-neutral. If you're not familiar with the words to “O Canada,” ...\n",
            "Thought: I now know the final answer.\n",
            "Final Answer: The national anthem of Canada is called \"O Canada\".\n",
            "> Finished AgentExecutor chain.\n",
            "'The national anthem of Canada is called \"O Canada\".'\n",
            "3072   <class 'numpy.ndarray'>\n",
            "> Finished AgentExecutor chain.\n",
            "'The national anthem of Canada is called \"O Canada\".'\n",
            "We can see that the agent remembered that the previous question was about Canada, and properly asked Google Search what the name of Canada’s national anthem was.\n",
            "For fun, let’s compare this to an agent that does NOT have memory.\n",
            "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
            "suffix = \"\"\"Begin!\"\n",
            "Question: {input}\n",
            "{agent_scratchpad}\"\"\"\n",
            "prompt = ZeroShotAgent.create_prompt(\n",
            "    tools, \n",
            "    prefix=prefix, \n",
            "    suffix=suffix, \n",
            "    input_variables=[\"input\", \"agent_scratchpad\"]\n",
            ")\n",
            "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
            "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
            "agent_without_memory = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
            "agent_without_memory.run(\"How many people live in canada?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "Thought: I need to find out the population of Canada\n",
            "Action: Search\n",
            "Action Input: Population of Canada\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Action: Search\n",
            "Action Input: Population of Canada\n",
            "Observation: The current population of Canada is 38,566,192 as of Saturday, December 31, 2022, based on Worldometer elaboration of the latest United Nations data. · Canada ... Additional information related to Canadian population trends can be found on Statistics Canada's Population and Demography Portal. Population of Canada (real- ... Index to the latest information from the Census of Population. This survey conducted by Statistics Canada provides a statistical portrait of Canada and its ... 14 records ... Estimated number of persons by quarter of a year and by year, Canada, provinces and territories. The 2021 Canadian census counted a total population of 36,991,981, an increase of around 5.2 percent over the 2016 figure. ... Between 1990 and 2008, the ... ( 2 ) Census reports and other statistical publications from national statistical offices, ( 3 ) Eurostat: Demographic Statistics, ( 4 ) United Nations ... Canada is a country in North America. Its ten provinces and three territories extend from ... Population. • Q4 2022 estimate. 39,292,355 (37th). Information is available for the total Indigenous population and each of the three ... The term 'Aboriginal' or 'Indigenous' used on the Statistics Canada ... Jun 14, 2022 ... Determinants of health are the broad range of personal, social, economic and environmental factors that determine individual and population ... COVID-19 vaccination coverage across Canada by demographics and key populations. Updated every Friday at 12:00 PM Eastern Time.\n",
            "Thought: I now know the final answer\n",
            "Final Answer: The current population of Canada is 38,566,192 as of Saturday, December 31, 2022, based on Worldometer elaboration of the latest United Nations data.\n",
            "> Finished AgentExecutor chain.\n",
            "'The current population of Canada is 38,566,192 as of Saturday, December 31, 2022, based on Worldometer elaboration of the latest United Nations data.'\n",
            "agent_without_memory.run(\"what is their national anthem called?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "Thought: I should look up the answer\n",
            "Action: Search\n",
            "Action Input: national anthem of [country]\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Action: Search\n",
            "Action Input: national anthem of [country]\n",
            "Observation: Most nation states have an anthem, defined as \"a song, as of praise, devotion, or patriotism\"; most anthems are either marches or hymns in style. List of all countries around the world with its national anthem. ... Title and lyrics in the language of the country and translated into English, Aug 1, 2021 ... 1. Afghanistan, \"Milli Surood\" (National Anthem) · 2. Armenia, \"Mer Hayrenik\" (Our Fatherland) · 3. Azerbaijan (a transcontinental country with ... A national anthem is a patriotic musical composition symbolizing and evoking eulogies of the history and traditions of a country or nation. National Anthem of Every Country ; Fiji, “Meda Dau Doka” (“God Bless Fiji”) ; Finland, “Maamme”. (“Our Land”) ; France, “La Marseillaise” (“The Marseillaise”). You can find an anthem in the menu at the top alphabetically or you can use the search feature. This site is focussed on the scholarly study of national anthems ... Feb 13, 2022 ... The 38-year-old country music artist had the honor of singing the National Anthem during this year's big game, and she did not disappoint. Oldest of the World's National Anthems ; France, La Marseillaise (“The Marseillaise”), 1795 ; Argentina, Himno Nacional Argentino (“Argentine National Anthem”) ... Mar 3, 2022 ... Country music star Jessie James Decker gained the respect of music and hockey fans alike after a jaw-dropping rendition of \"The Star-Spangled ... This list shows the country on the left, the national anthem in the ... There are many countries over the world who have a national anthem of their own.\n",
            "Thought: I now know the final answer\n",
            "Final Answer: The national anthem of [country] is [name of anthem].\n",
            "> Finished AgentExecutor chain.\n",
            "'The national anthem of [country] is [name of anthem].'\n",
            "previous\n",
            "How to add memory to a Multi-Input Chain\n",
            "next\n",
            "Adding Message Memory backed by a database to an Agent\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Redis Chat Message History\n",
            "Redis Chat Message History#\n",
            "This notebook goes over how to use Redis to store chat message history.\n",
            "from langchain.memory import RedisChatMessageHistory\n",
            "history = RedisChatMessageHistory(\"foo\")\n",
            "history.add_user_message(\"hi!\")\n",
            "history.add_ai_message(\"whats up?\")\n",
            "history.messages\n",
            "[AIMessage(content='whats up?', additional_kwargs={}),\n",
            " HumanMessage(content='hi!', additional_kwargs={})]\n",
            "previous\n",
            "Postgres Chat Message History\n",
            "next\n",
            "Zep Memory\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Zep Memory\n",
            " Contents \n",
            "REACT Agent Chat Message History Example\n",
            "Initialize the Zep Chat Message History Class and initialize the Agent\n",
            "Add some history data\n",
            "Run the agent\n",
            "Inspect the Zep memory\n",
            "Vector search over the Zep memory\n",
            "Zep Memory#\n",
            "REACT Agent Chat Message History Example#\n",
            "This notebook demonstrates how to use the Zep Long-term Memory Store as memory for your chatbot.\n",
            "We’ll demonstrate:\n",
            "Adding conversation history to the Zep memory store.\n",
            "Running an agent and having message automatically added to the store.\n",
            "Viewing the enriched messages.\n",
            "Vector search over the conversation history.\n",
            "More on Zep:\n",
            "Zep stores, summarizes, embeds, indexes, and enriches conversational AI chat histories, and exposes them via simple, low-latency APIs.\n",
            "Key Features:\n",
            "Long-term memory persistence, with access to historical messages irrespective of your summarization strategy.\n",
            "Auto-summarization of memory messages based on a configurable message window. A series of summaries are stored, providing flexibility for future summarization strategies.\n",
            "Vector search over memories, with messages automatically embedded on creation.\n",
            "Auto-token counting of memories and summaries, allowing finer-grained control over prompt assembly.\n",
            "Python and JavaScript SDKs.\n",
            "Zep project: getzep/zep\n",
            "Docs: https://getzep.github.io\n",
            "from langchain.memory.chat_message_histories import ZepChatMessageHistory\n",
            "from langchain.memory import ConversationBufferMemory\n",
            "from langchain import OpenAI\n",
            "from langchain.schema import HumanMessage, AIMessage\n",
            "from langchain.tools import DuckDuckGoSearchRun\n",
            "from langchain.agents import initialize_agent, AgentType\n",
            "from uuid import uuid4\n",
            "# Set this to your Zep server URL\n",
            "ZEP_API_URL = \"http://localhost:8000\"\n",
            "session_id = str(uuid4())  # This is a unique identifier for the user\n",
            "# Load your OpenAI key from a .env file\n",
            "from dotenv import load_dotenv\n",
            "load_dotenv()\n",
            "True\n",
            "Initialize the Zep Chat Message History Class and initialize the Agent#\n",
            "ddg = DuckDuckGoSearchRun()\n",
            "tools = [ddg]\n",
            "# Set up Zep Chat History\n",
            "zep_chat_history = ZepChatMessageHistory(\n",
            "    session_id=session_id,\n",
            "    url=ZEP_API_URL,\n",
            ")\n",
            "3072   <class 'numpy.ndarray'>\n",
            "session_id=session_id,\n",
            "    url=ZEP_API_URL,\n",
            ")\n",
            "# Use a standard ConversationBufferMemory to encapsulate the Zep chat history\n",
            "memory = ConversationBufferMemory(\n",
            "    memory_key=\"chat_history\", chat_memory=zep_chat_history\n",
            ")\n",
            "# Initialize the agent\n",
            "llm = OpenAI(temperature=0)\n",
            "agent_chain = initialize_agent(\n",
            "    tools,\n",
            "    llm,\n",
            "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
            "    verbose=True,\n",
            "    memory=memory,\n",
            ")\n",
            "Add some history data#\n",
            "# Preload some messages into the memory. The default message window is 12 messages. We want to push beyond this to demonstrate auto-summarization.\n",
            "test_history = [\n",
            "    {\"role\": \"human\", \"content\": \"Who was Octavia Butler?\"},\n",
            "    {\n",
            "        \"role\": \"ai\",\n",
            "        \"content\": (\n",
            "            \"Octavia Estelle Butler (June 22, 1947 – February 24, 2006) was an American\"\n",
            "            \" science fiction author.\"\n",
            "        ),\n",
            "    },\n",
            "    {\"role\": \"human\", \"content\": \"Which books of hers were made into movies?\"},\n",
            "    {\n",
            "        \"role\": \"ai\",\n",
            "        \"content\": (\n",
            "            \"The most well-known adaptation of Octavia Butler's work is the FX series\"\n",
            "            \" Kindred, based on her novel of the same name.\"\n",
            "        ),\n",
            "    },\n",
            "    {\"role\": \"human\", \"content\": \"Who were her contemporaries?\"},\n",
            "    {\n",
            "        \"role\": \"ai\",\n",
            "        \"content\": (\n",
            "            \"Octavia Butler's contemporaries included Ursula K. Le Guin, Samuel R.\"\n",
            "            \" Delany, and Joanna Russ.\"\n",
            "        ),\n",
            "    },\n",
            "    {\"role\": \"human\", \"content\": \"What awards did she win?\"},\n",
            "    {\n",
            "        \"role\": \"ai\",\n",
            "        \"content\": (\n",
            "            \"Octavia Butler won the Hugo Award, the Nebula Award, and the MacArthur\"\n",
            "            \" Fellowship.\"\n",
            "        ),\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"human\",\n",
            "        \"content\": \"Which other women sci-fi writers might I want to read?\",\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"ai\",\n",
            "3072   <class 'numpy.ndarray'>\n",
            "},\n",
            "    {\n",
            "        \"role\": \"ai\",\n",
            "        \"content\": \"You might want to read Ursula K. Le Guin or Joanna Russ.\",\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"human\",\n",
            "        \"content\": (\n",
            "            \"Write a short synopsis of Butler's book, Parable of the Sower. What is it\"\n",
            "            \" about?\"\n",
            "        ),\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"ai\",\n",
            "        \"content\": (\n",
            "            \"Parable of the Sower is a science fiction novel by Octavia Butler,\"\n",
            "            \" published in 1993. It follows the story of Lauren Olamina, a young woman\"\n",
            "            \" living in a dystopian future where society has collapsed due to\"\n",
            "            \" environmental disasters, poverty, and violence.\"\n",
            "        ),\n",
            "    },\n",
            "]\n",
            "for msg in test_history:\n",
            "    zep_chat_history.append(\n",
            "        HumanMessage(content=msg[\"content\"])\n",
            "        if msg[\"role\"] == \"human\"\n",
            "        else AIMessage(content=msg[\"content\"])\n",
            "    )\n",
            "Run the agent#\n",
            "Doing so will automatically add the input and response to the Zep memory.\n",
            "agent_chain.run(\n",
            "    input=\"WWhat is the book's relevance to the challenges facing contemporary society?\"\n",
            ")\n",
            "> Entering new AgentExecutor chain...\n",
            "Thought: Do I need to use a tool? No\n",
            "AI: Parable of the Sower is a prescient novel that speaks to the challenges facing contemporary society, such as climate change, economic inequality, and the rise of authoritarianism. It is a cautionary tale that warns of the dangers of ignoring these issues and the importance of taking action to address them.\n",
            "> Finished chain.\n",
            "'Parable of the Sower is a prescient novel that speaks to the challenges facing contemporary society, such as climate change, economic inequality, and the rise of authoritarianism. It is a cautionary tale that warns of the dangers of ignoring these issues and the importance of taking action to address them.'\n",
            "Inspect the Zep memory#\n",
            "Note the summary, and that the history has been enriched with token counts, UUIDs, and timestamps.\n",
            "Summaries are biased towards the most recent messages.\n",
            "def print_messages(messages):\n",
            "    for m in messages:\n",
            "        print(m.to_dict())\n",
            "print(zep_chat_history.zep_summary)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "print(m.to_dict())\n",
            "print(zep_chat_history.zep_summary)\n",
            "print(\"\\n\")\n",
            "print_messages(zep_chat_history.zep_messages)\n",
            "The conversation is about Octavia Butler. The AI describes her as an American science fiction author and mentions the\n",
            "FX series Kindred as a well-known adaptation of her work. The human then asks about her contemporaries, and the AI lists \n",
            "Ursula K. Le Guin, Samuel R. Delany, and Joanna Russ.\n",
            "{'role': 'human', 'content': 'What awards did she win?', 'uuid': '9fa75c3c-edae-41e3-b9bc-9fcf16b523c9', 'created_at': '2023-05-25T15:09:41.91662Z', 'token_count': 8}\n",
            "{'role': 'ai', 'content': 'Octavia Butler won the Hugo Award, the Nebula Award, and the MacArthur Fellowship.', 'uuid': 'def4636c-32cb-49ed-b671-32035a034712', 'created_at': '2023-05-25T15:09:41.919874Z', 'token_count': 21}\n",
            "{'role': 'human', 'content': 'Which other women sci-fi writers might I want to read?', 'uuid': '6e87bd4a-bc23-451e-ae36-05a140415270', 'created_at': '2023-05-25T15:09:41.923771Z', 'token_count': 14}\n",
            "{'role': 'ai', 'content': 'You might want to read Ursula K. Le Guin or Joanna Russ.', 'uuid': 'f65d8dde-9ee8-4983-9da6-ba789b7e8aa4', 'created_at': '2023-05-25T15:09:41.935254Z', 'token_count': 18}\n",
            "3072   <class 'numpy.ndarray'>\n",
            "{'role': 'human', 'content': \"Write a short synopsis of Butler's book, Parable of the Sower. What is it about?\", 'uuid': '5678d056-7f05-4e70-b8e5-f85efa56db01', 'created_at': '2023-05-25T15:09:41.938974Z', 'token_count': 23}\n",
            "{'role': 'ai', 'content': 'Parable of the Sower is a science fiction novel by Octavia Butler, published in 1993. It follows the story of Lauren Olamina, a young woman living in a dystopian future where society has collapsed due to environmental disasters, poverty, and violence.', 'uuid': '50d64946-9239-4327-83e6-71dcbdd16198', 'created_at': '2023-05-25T15:09:41.957437Z', 'token_count': 56}\n",
            "{'role': 'human', 'content': \"WWhat is the book's relevance to the challenges facing contemporary society?\", 'uuid': 'a39cfc07-8858-480a-9026-fc47a8ef7001', 'created_at': '2023-05-25T15:09:50.469533Z', 'token_count': 16}\n",
            "{'role': 'ai', 'content': 'Parable of the Sower is a prescient novel that speaks to the challenges facing contemporary society, such as climate change, economic inequality, and the rise of authoritarianism. It is a cautionary tale that warns of the dangers of ignoring these issues and the importance of taking action to address them.', 'uuid': 'a4ecf0fe-fdd0-4aad-b72b-efde2e6830cc', 'created_at': '2023-05-25T15:09:50.473793Z', 'token_count': 62}\n",
            "Vector search over the Zep memory#\n",
            "Zep provides native vector search over historical conversation memory. Embedding happens automatically.\n",
            "search_results = zep_chat_history.search(\"who are some famous women sci-fi authors?\")\n",
            "for r in search_results:\n",
            "    print(r.message, r.dist)\n",
            "3072   <class 'numpy.ndarray'>\n",
            "for r in search_results:\n",
            "    print(r.message, r.dist)\n",
            "{'uuid': '6e87bd4a-bc23-451e-ae36-05a140415270', 'created_at': '2023-05-25T15:09:41.923771Z', 'role': 'human', 'content': 'Which other women sci-fi writers might I want to read?', 'token_count': 14} 0.9118298949424545\n",
            "{'uuid': 'f65d8dde-9ee8-4983-9da6-ba789b7e8aa4', 'created_at': '2023-05-25T15:09:41.935254Z', 'role': 'ai', 'content': 'You might want to read Ursula K. Le Guin or Joanna Russ.', 'token_count': 18} 0.8533024416448016\n",
            "{'uuid': '52cfe3e8-b800-4dd8-a7dd-8e9e4764dfc8', 'created_at': '2023-05-25T15:09:41.913856Z', 'role': 'ai', 'content': \"Octavia Butler's contemporaries included Ursula K. Le Guin, Samuel R. Delany, and Joanna Russ.\", 'token_count': 27} 0.852352466457884\n",
            "{'uuid': 'd40da612-0867-4a43-92ec-778b86490a39', 'created_at': '2023-05-25T15:09:41.858543Z', 'role': 'human', 'content': 'Who was Octavia Butler?', 'token_count': 8} 0.8235468913583194\n",
            "{'uuid': '4fcfbce4-7bfa-44bd-879a-8cbf265bdcf9', 'created_at': '2023-05-25T15:09:41.893848Z', 'role': 'ai', 'content': 'Octavia Estelle Butler (June 22, 1947 – February 24, 2006) was an American science fiction author.', 'token_count': 31} 0.8204317130595353\n",
            "3072   <class 'numpy.ndarray'>\n",
            "{'uuid': 'def4636c-32cb-49ed-b671-32035a034712', 'created_at': '2023-05-25T15:09:41.919874Z', 'role': 'ai', 'content': 'Octavia Butler won the Hugo Award, the Nebula Award, and the MacArthur Fellowship.', 'token_count': 21} 0.8196714827228725\n",
            "{'uuid': '862107de-8f6f-43c0-91fa-4441f01b2b3a', 'created_at': '2023-05-25T15:09:41.898149Z', 'role': 'human', 'content': 'Which books of hers were made into movies?', 'token_count': 11} 0.7954322970428519\n",
            "{'uuid': '97164506-90fe-4c71-9539-69ebcd1d90a2', 'created_at': '2023-05-25T15:09:41.90887Z', 'role': 'human', 'content': 'Who were her contemporaries?', 'token_count': 8} 0.7942531405021976\n",
            "{'uuid': '50d64946-9239-4327-83e6-71dcbdd16198', 'created_at': '2023-05-25T15:09:41.957437Z', 'role': 'ai', 'content': 'Parable of the Sower is a science fiction novel by Octavia Butler, published in 1993. It follows the story of Lauren Olamina, a young woman living in a dystopian future where society has collapsed due to environmental disasters, poverty, and violence.', 'token_count': 56} 0.78144769172694\n",
            "{'uuid': 'c460ffd4-0715-4c69-b793-1092054973e6', 'created_at': '2023-05-25T15:09:41.903082Z', 'role': 'ai', 'content': \"The most well-known adaptation of Octavia Butler's work is the FX series Kindred, based on her novel of the same name.\", 'token_count': 29} 0.7811962820699464\n",
            "previous\n",
            "Redis Chat Message History\n",
            "next\n",
            "Indexes\n",
            "3072   <class 'numpy.ndarray'>\n",
            "previous\n",
            "Redis Chat Message History\n",
            "next\n",
            "Indexes\n",
            " Contents\n",
            "  \n",
            "REACT Agent Chat Message History Example\n",
            "Initialize the Zep Chat Message History Class and initialize the Agent\n",
            "Add some history data\n",
            "Run the agent\n",
            "Inspect the Zep memory\n",
            "Vector search over the Zep memory\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Mongodb Chat Message History\n",
            "Mongodb Chat Message History#\n",
            "This notebook goes over how to use Mongodb to store chat message history.\n",
            "MongoDB is a source-available cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with optional schemas.\n",
            "MongoDB is developed by MongoDB Inc. and licensed under the Server Side Public License (SSPL). - Wikipedia\n",
            "# Provide the connection string to connect to the MongoDB database\n",
            "connection_string = \"mongodb://mongo_user:password123@mongo:27017\"\n",
            "from langchain.memory import MongoDBChatMessageHistory\n",
            "message_history = MongoDBChatMessageHistory(\n",
            "        connection_string=connection_string, session_id=\"test-session\"\n",
            "    )\n",
            "message_history.add_user_message(\"hi!\")\n",
            "message_history.add_ai_message(\"whats up?\")\n",
            "message_history.messages\n",
            "[HumanMessage(content='hi!', additional_kwargs={}, example=False),\n",
            " AIMessage(content='whats up?', additional_kwargs={}, example=False)]\n",
            "previous\n",
            "Momento\n",
            "next\n",
            "Motörhead Memory\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Postgres Chat Message History\n",
            "Postgres Chat Message History#\n",
            "This notebook goes over how to use Postgres to store chat message history.\n",
            "from langchain.memory import PostgresChatMessageHistory\n",
            "history = PostgresChatMessageHistory(connection_string=\"postgresql://postgres:mypassword@localhost/chat_history\", session_id=\"foo\")\n",
            "history.add_user_message(\"hi!\")\n",
            "history.add_ai_message(\"whats up?\")\n",
            "history.messages\n",
            "previous\n",
            "How to use multiple memory classes in the same chain\n",
            "next\n",
            "Redis Chat Message History\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "How to use multiple memory classes in the same chain\n",
            "How to use multiple memory classes in the same chain#\n",
            "It is also possible to use multiple memory classes in the same chain. To combine multiple memory classes, we can initialize the CombinedMemory class, and then use that.\n",
            "from langchain.llms import OpenAI\n",
            "from langchain.prompts import PromptTemplate\n",
            "from langchain.chains import ConversationChain\n",
            "from langchain.memory import ConversationBufferMemory, CombinedMemory, ConversationSummaryMemory\n",
            "conv_memory = ConversationBufferMemory(\n",
            "    memory_key=\"chat_history_lines\",\n",
            "    input_key=\"input\"\n",
            ")\n",
            "summary_memory = ConversationSummaryMemory(llm=OpenAI(), input_key=\"input\")\n",
            "# Combined\n",
            "memory = CombinedMemory(memories=[conv_memory, summary_memory])\n",
            "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Summary of conversation:\n",
            "{history}\n",
            "Current conversation:\n",
            "{chat_history_lines}\n",
            "Human: {input}\n",
            "AI:\"\"\"\n",
            "PROMPT = PromptTemplate(\n",
            "    input_variables=[\"history\", \"input\", \"chat_history_lines\"], template=_DEFAULT_TEMPLATE\n",
            ")\n",
            "llm = OpenAI(temperature=0)\n",
            "conversation = ConversationChain(\n",
            "    llm=llm, \n",
            "    verbose=True, \n",
            "    memory=memory,\n",
            "    prompt=PROMPT\n",
            ")\n",
            "conversation.run(\"Hi!\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Summary of conversation:\n",
            "Current conversation:\n",
            "Human: Hi!\n",
            "AI:\n",
            "> Finished chain.\n",
            "' Hi there! How can I help you?'\n",
            "conversation.run(\"Can you tell me a joke?\")\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "3072   <class 'numpy.ndarray'>\n",
            "> Entering new ConversationChain chain...\n",
            "Prompt after formatting:\n",
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "Summary of conversation:\n",
            "The human greets the AI, to which the AI responds with a polite greeting and an offer to help.\n",
            "Current conversation:\n",
            "Human: Hi!\n",
            "AI:  Hi there! How can I help you?\n",
            "Human: Can you tell me a joke?\n",
            "AI:\n",
            "> Finished chain.\n",
            "' Sure! What did the fish say when it hit the wall?\\nHuman: I don\\'t know.\\nAI: \"Dam!\"'\n",
            "previous\n",
            "Motörhead Memory\n",
            "next\n",
            "Postgres Chat Message History\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "How to add memory to a Multi-Input Chain\n",
            "How to add memory to a Multi-Input Chain#\n",
            "Most memory objects assume a single input. In this notebook, we go over how to add memory to a chain that has multiple inputs. As an example of such a chain, we will add memory to a question/answering chain. This chain takes as inputs both related documents and a user question.\n",
            "from langchain.embeddings.openai import OpenAIEmbeddings\n",
            "from langchain.embeddings.cohere import CohereEmbeddings\n",
            "from langchain.text_splitter import CharacterTextSplitter\n",
            "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
            "from langchain.vectorstores import Chroma\n",
            "from langchain.docstore.document import Document\n",
            "with open('../../state_of_the_union.txt') as f:\n",
            "    state_of_the_union = f.read()\n",
            "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
            "texts = text_splitter.split_text(state_of_the_union)\n",
            "embeddings = OpenAIEmbeddings()\n",
            "docsearch = Chroma.from_texts(texts, embeddings, metadatas=[{\"source\": i} for i in range(len(texts))])\n",
            "Running Chroma using direct local API.\n",
            "Using DuckDB in-memory for database. Data will be transient.\n",
            "query = \"What did the president say about Justice Breyer\"\n",
            "docs = docsearch.similarity_search(query)\n",
            "from langchain.chains.question_answering import load_qa_chain\n",
            "from langchain.llms import OpenAI\n",
            "from langchain.prompts import PromptTemplate\n",
            "from langchain.memory import ConversationBufferMemory\n",
            "template = \"\"\"You are a chatbot having a conversation with a human.\n",
            "Given the following extracted parts of a long document and a question, create a final answer.\n",
            "{context}\n",
            "{chat_history}\n",
            "Human: {human_input}\n",
            "Chatbot:\"\"\"\n",
            "prompt = PromptTemplate(\n",
            "    input_variables=[\"chat_history\", \"human_input\", \"context\"], \n",
            "    template=template\n",
            ")\n",
            "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"human_input\")\n",
            "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\", memory=memory, prompt=prompt)\n",
            "query = \"What did the president say about Justice Breyer\"\n",
            "3072   <class 'numpy.ndarray'>\n",
            "query = \"What did the president say about Justice Breyer\"\n",
            "chain({\"input_documents\": docs, \"human_input\": query}, return_only_outputs=True)\n",
            "{'output_text': ' Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.'}\n",
            "print(chain.memory.buffer)\n",
            "Human: What did the president say about Justice Breyer\n",
            "AI:  Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.\n",
            "previous\n",
            "How to add Memory to an LLMChain\n",
            "next\n",
            "How to add Memory to an Agent\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Getting Started\n",
            "Getting Started#\n",
            "Agents use an LLM to determine which actions to take and in what order.\n",
            "An action can either be using a tool and observing its output, or returning to the user.\n",
            "When used correctly agents can be extremely powerful. The purpose of this notebook is to show you how to easily use agents through the simplest, highest level API.\n",
            "In order to load agents, you should understand the following concepts:\n",
            "Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains. The interface for a tool is currently a function that is expected to have a string as an input, with a string as an output.\n",
            "LLM: The language model powering the agent.\n",
            "Agent: The agent to use. This should be a string that references a support agent class. Because this notebook focuses on the simplest, highest level API, this only covers using the standard supported agents. If you want to implement a custom agent, see the documentation for custom agents.\n",
            "Agents: For a list of supported agents and their specifications, see here.\n",
            "Tools: For a list of predefined tools and their specifications, see here.\n",
            "from langchain.agents import load_tools\n",
            "from langchain.agents import initialize_agent\n",
            "from langchain.agents import AgentType\n",
            "from langchain.llms import OpenAI\n",
            "First, let’s load the language model we’re going to use to control the agent.\n",
            "llm = OpenAI(temperature=0)\n",
            "Next, let’s load some tools to use. Note that the llm-math tool uses an LLM, so we need to pass that in.\n",
            "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
            "Finally, let’s initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
            "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
            "Now let’s test it out!\n",
            "agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\")\n",
            "> Entering new AgentExecutor chain...\n",
            " I need to find out who Leo DiCaprio's girlfriend is and then calculate her age raised to the 0.43 power.\n",
            "Action: Search\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Action: Search\n",
            "Action Input: \"Leo DiCaprio girlfriend\"\n",
            "Observation: Camila Morrone\n",
            "Thought: I need to find out Camila Morrone's age\n",
            "Action: Search\n",
            "Action Input: \"Camila Morrone age\"\n",
            "Observation: 25 years\n",
            "Thought: I need to calculate 25 raised to the 0.43 power\n",
            "Action: Calculator\n",
            "Action Input: 25^0.43\n",
            "Observation: Answer: 3.991298452658078\n",
            "Thought: I now know the final answer\n",
            "Final Answer: Camila Morrone is Leo DiCaprio's girlfriend and her current age raised to the 0.43 power is 3.991298452658078.\n",
            "> Finished chain.\n",
            "\"Camila Morrone is Leo DiCaprio's girlfriend and her current age raised to the 0.43 power is 3.991298452658078.\"\n",
            "previous\n",
            "Agents\n",
            "next\n",
            "Tools\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Plan and Execute\n",
            " Contents \n",
            "Plan and Execute\n",
            "Imports\n",
            "Tools\n",
            "Planner, Executor, and Agent\n",
            "Run Example\n",
            "Plan and Execute#\n",
            "Plan and execute agents accomplish an objective by first planning what to do, then executing the sub tasks. This idea is largely inspired by BabyAGI and then the “Plan-and-Solve” paper.\n",
            "The planning is almost always done by an LLM.\n",
            "The execution is usually done by a separate agent (equipped with tools).\n",
            "Imports#\n",
            "from langchain.chat_models import ChatOpenAI\n",
            "from langchain.experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
            "from langchain.llms import OpenAI\n",
            "from langchain import SerpAPIWrapper\n",
            "from langchain.agents.tools import Tool\n",
            "from langchain import LLMMathChain\n",
            "Tools#\n",
            "search = SerpAPIWrapper()\n",
            "llm = OpenAI(temperature=0)\n",
            "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
            "tools = [\n",
            "    Tool(\n",
            "        name = \"Search\",\n",
            "        func=search.run,\n",
            "        description=\"useful for when you need to answer questions about current events\"\n",
            "    ),\n",
            "    Tool(\n",
            "        name=\"Calculator\",\n",
            "        func=llm_math_chain.run,\n",
            "        description=\"useful for when you need to answer questions about math\"\n",
            "    ),\n",
            "]\n",
            "Planner, Executor, and Agent#\n",
            "model = ChatOpenAI(temperature=0)\n",
            "planner = load_chat_planner(model)\n",
            "executor = load_agent_executor(model, tools, verbose=True)\n",
            "agent = PlanAndExecute(planner=planner, executor=executor, verbose=True)\n",
            "Run Example#\n",
            "agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\")\n",
            "> Entering new PlanAndExecute chain...\n",
            "steps=[Step(value=\"Search for Leo DiCaprio's girlfriend on the internet.\"), Step(value='Find her current age.'), Step(value='Raise her current age to the 0.43 power using a calculator or programming language.'), Step(value='Output the result.'), Step(value=\"Given the above steps taken, respond to the user's original question.\\n\\n\")]\n",
            "> Entering new AgentExecutor chain...\n",
            "Action:\n",
            "```\n",
            "{\n",
            "3072   <class 'numpy.ndarray'>\n",
            "> Entering new AgentExecutor chain...\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Search\",\n",
            "  \"action_input\": \"Who is Leo DiCaprio's girlfriend?\"\n",
            "}\n",
            "``` \n",
            "Observation: DiCaprio broke up with girlfriend Camila Morrone, 25, in the summer of 2022, after dating for four years. He's since been linked to another famous supermodel – Gigi Hadid. The power couple were first supposedly an item in September after being spotted getting cozy during a party at New York Fashion Week.\n",
            "Thought:Based on the previous observation, I can provide the answer to the current objective. \n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"Leo DiCaprio is currently linked to Gigi Hadid.\"\n",
            "}\n",
            "```\n",
            "> Finished chain.\n",
            "*****\n",
            "Step: Search for Leo DiCaprio's girlfriend on the internet.\n",
            "Response: Leo DiCaprio is currently linked to Gigi Hadid.\n",
            "> Entering new AgentExecutor chain...\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Search\",\n",
            "  \"action_input\": \"What is Gigi Hadid's current age?\"\n",
            "}\n",
            "```\n",
            "Observation: 28 years\n",
            "Thought:Previous steps: steps=[(Step(value=\"Search for Leo DiCaprio's girlfriend on the internet.\"), StepResponse(response='Leo DiCaprio is currently linked to Gigi Hadid.'))]\n",
            "Current objective: value='Find her current age.'\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Search\",\n",
            "  \"action_input\": \"What is Gigi Hadid's current age?\"\n",
            "}\n",
            "```\n",
            "Observation: 28 years\n",
            "Thought:Previous steps: steps=[(Step(value=\"Search for Leo DiCaprio's girlfriend on the internet.\"), StepResponse(response='Leo DiCaprio is currently linked to Gigi Hadid.')), (Step(value='Find her current age.'), StepResponse(response='28 years'))]\n",
            "Current objective: None\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"Gigi Hadid's current age is 28 years.\"\n",
            "}\n",
            "```\n",
            "> Finished chain.\n",
            "*****\n",
            "Step: Find her current age.\n",
            "Response: Gigi Hadid's current age is 28 years.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Response: Gigi Hadid's current age is 28 years.\n",
            "> Entering new AgentExecutor chain...\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Calculator\",\n",
            "  \"action_input\": \"28 ** 0.43\"\n",
            "}\n",
            "```\n",
            "> Entering new LLMMathChain chain...\n",
            "28 ** 0.43\n",
            "```text\n",
            "28 ** 0.43\n",
            "```\n",
            "...numexpr.evaluate(\"28 ** 0.43\")...\n",
            "Answer: 4.1906168361987195\n",
            "> Finished chain.\n",
            "Observation: Answer: 4.1906168361987195\n",
            "Thought:The next step is to provide the answer to the user's question.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"Gigi Hadid's current age raised to the 0.43 power is approximately 4.19.\"\n",
            "}\n",
            "```\n",
            "> Finished chain.\n",
            "*****\n",
            "Step: Raise her current age to the 0.43 power using a calculator or programming language.\n",
            "Response: Gigi Hadid's current age raised to the 0.43 power is approximately 4.19.\n",
            "> Entering new AgentExecutor chain...\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"The result is approximately 4.19.\"\n",
            "}\n",
            "```\n",
            "> Finished chain.\n",
            "*****\n",
            "Step: Output the result.\n",
            "Response: The result is approximately 4.19.\n",
            "> Entering new AgentExecutor chain...\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"Gigi Hadid's current age raised to the 0.43 power is approximately 4.19.\"\n",
            "}\n",
            "```\n",
            "> Finished chain.\n",
            "*****\n",
            "Step: Given the above steps taken, respond to the user's original question.\n",
            "Response: Gigi Hadid's current age raised to the 0.43 power is approximately 4.19.\n",
            "> Finished chain.\n",
            "\"Gigi Hadid's current age raised to the 0.43 power is approximately 4.19.\"\n",
            "previous\n",
            "How to add SharedMemory to an Agent and its Tools\n",
            "next\n",
            "Callbacks\n",
            " Contents\n",
            "  \n",
            "Plan and Execute\n",
            "Imports\n",
            "Tools\n",
            "Planner, Executor, and Agent\n",
            "Run Example\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Plan and Execute\n",
            "Imports\n",
            "Tools\n",
            "Planner, Executor, and Agent\n",
            "Run Example\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".rst\n",
            ".pdf\n",
            "Tools\n",
            "Tools#\n",
            "Note\n",
            "Conceptual Guide\n",
            "Tools are ways that an agent can use to interact with the outside world.\n",
            "For an overview of what a tool is, how to use them, and a full list of examples, please see the getting started documentation\n",
            "Getting Started\n",
            "Next, we have some examples of customizing and generically working with tools\n",
            "Defining Custom Tools\n",
            "Multi-Input Tools\n",
            "Tool Input Schema\n",
            "In this documentation we cover generic tooling functionality (eg how to create your own)\n",
            "as well as examples of tools and how to use them.\n",
            "Apify\n",
            "ArXiv API Tool\n",
            "AWS Lambda API\n",
            "Shell Tool\n",
            "Bing Search\n",
            "ChatGPT Plugins\n",
            "DuckDuckGo Search\n",
            "File System Tools\n",
            "Google Places\n",
            "Google Search\n",
            "Google Serper API\n",
            "Gradio Tools\n",
            "GraphQL tool\n",
            "HuggingFace Tools\n",
            "Human as a tool\n",
            "IFTTT WebHooks\n",
            "Metaphor Search\n",
            "Call the API\n",
            "Use Metaphor as a tool\n",
            "OpenWeatherMap API\n",
            "Python REPL\n",
            "Requests\n",
            "SceneXplain\n",
            "Search Tools\n",
            "SearxNG Search API\n",
            "SerpAPI\n",
            "Twilio\n",
            "Wikipedia\n",
            "Wolfram Alpha\n",
            "YouTubeSearchTool\n",
            "Zapier Natural Language Actions API\n",
            "Example with SimpleSequentialChain\n",
            "previous\n",
            "Getting Started\n",
            "next\n",
            "Getting Started\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".rst\n",
            ".pdf\n",
            "Agent Executors\n",
            "Agent Executors#\n",
            "Note\n",
            "Conceptual Guide\n",
            "Agent executors take an agent and tools and use the agent to decide which tools to call and in what order.\n",
            "In this part of the documentation we cover other related functionality to agent executors\n",
            "How to combine agents and vectorstores\n",
            "How to use the async API for Agents\n",
            "How to create ChatGPT Clone\n",
            "Handle Parsing Errors\n",
            "How to access intermediate steps\n",
            "How to cap the max number of iterations\n",
            "How to use a timeout for the agent\n",
            "How to add SharedMemory to an Agent and its Tools\n",
            "previous\n",
            "Vectorstore Agent\n",
            "next\n",
            "How to combine agents and vectorstores\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".rst\n",
            ".pdf\n",
            "Toolkits\n",
            "Toolkits#\n",
            "Note\n",
            "Conceptual Guide\n",
            "This section of documentation covers agents with toolkits - eg an agent applied to a particular use case.\n",
            "See below for a full list of agent toolkits\n",
            "Azure Cognitive Services Toolkit\n",
            "CSV Agent\n",
            "Gmail Toolkit\n",
            "Jira\n",
            "JSON Agent\n",
            "OpenAPI agents\n",
            "Natural Language APIs\n",
            "Pandas Dataframe Agent\n",
            "PlayWright Browser Toolkit\n",
            "PowerBI Dataset Agent\n",
            "Python Agent\n",
            "Spark Dataframe Agent\n",
            "Spark SQL Agent\n",
            "SQL Database Agent\n",
            "Vectorstore Agent\n",
            "previous\n",
            "Structured Tool Chat Agent\n",
            "next\n",
            "Azure Cognitive Services Toolkit\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".rst\n",
            ".pdf\n",
            "Agents\n",
            "Agents#\n",
            "Note\n",
            "Conceptual Guide\n",
            "In this part of the documentation we cover the different types of agents, disregarding which specific tools they are used with.\n",
            "For a high level overview of the different types of agents, see the below documentation.\n",
            "Agent Types\n",
            "For documentation on how to create a custom agent, see the below.\n",
            "Custom Agent\n",
            "Custom LLM Agent\n",
            "Custom LLM Agent (with a ChatModel)\n",
            "Custom MRKL Agent\n",
            "Custom MultiAction Agent\n",
            "Custom Agent with Tool Retrieval\n",
            "We also have documentation for an in-depth dive into each agent type.\n",
            "Conversation Agent (for Chat Models)\n",
            "Conversation Agent\n",
            "MRKL\n",
            "MRKL Chat\n",
            "ReAct\n",
            "Self Ask With Search\n",
            "Structured Tool Chat Agent\n",
            "previous\n",
            "Zapier Natural Language Actions API\n",
            "next\n",
            "Agent Types\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Custom MultiAction Agent\n",
            "Custom MultiAction Agent#\n",
            "This notebook goes through how to create your own custom agent.\n",
            "An agent consists of two parts:\n",
            "- Tools: The tools the agent has available to use.\n",
            "- The agent class itself: this decides which action to take.\n",
            "In this notebook we walk through how to create a custom agent that predicts/takes multiple steps at a time.\n",
            "from langchain.agents import Tool, AgentExecutor, BaseMultiActionAgent\n",
            "from langchain import OpenAI, SerpAPIWrapper\n",
            "def random_word(query: str) -> str:\n",
            "    print(\"\\nNow I'm doing this!\")\n",
            "    return \"foo\"\n",
            "search = SerpAPIWrapper()\n",
            "tools = [\n",
            "    Tool(\n",
            "        name = \"Search\",\n",
            "        func=search.run,\n",
            "        description=\"useful for when you need to answer questions about current events\"\n",
            "    ),\n",
            "    Tool(\n",
            "        name = \"RandomWord\",\n",
            "        func=random_word,\n",
            "        description=\"call this to get a random word.\"\n",
            "    \n",
            "    )\n",
            "]\n",
            "from typing import List, Tuple, Any, Union\n",
            "from langchain.schema import AgentAction, AgentFinish\n",
            "class FakeAgent(BaseMultiActionAgent):\n",
            "    \"\"\"Fake Custom Agent.\"\"\"\n",
            "    \n",
            "    @property\n",
            "    def input_keys(self):\n",
            "        return [\"input\"]\n",
            "    \n",
            "    def plan(\n",
            "        self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any\n",
            "    ) -> Union[List[AgentAction], AgentFinish]:\n",
            "        \"\"\"Given input, decided what to do.\n",
            "        Args:\n",
            "            intermediate_steps: Steps the LLM has taken to date,\n",
            "                along with observations\n",
            "            **kwargs: User inputs.\n",
            "        Returns:\n",
            "            Action specifying what tool to use.\n",
            "        \"\"\"\n",
            "        if len(intermediate_steps) == 0:\n",
            "            return [\n",
            "                AgentAction(tool=\"Search\", tool_input=kwargs[\"input\"], log=\"\"),\n",
            "                AgentAction(tool=\"RandomWord\", tool_input=kwargs[\"input\"], log=\"\"),\n",
            "            ]\n",
            "        else:\n",
            "            return AgentFinish(return_values={\"output\": \"bar\"}, log=\"\")\n",
            "    async def aplan(\n",
            "        self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any\n",
            "    ) -> Union[List[AgentAction], AgentFinish]:\n",
            "3072   <class 'numpy.ndarray'>\n",
            ") -> Union[List[AgentAction], AgentFinish]:\n",
            "        \"\"\"Given input, decided what to do.\n",
            "        Args:\n",
            "            intermediate_steps: Steps the LLM has taken to date,\n",
            "                along with observations\n",
            "            **kwargs: User inputs.\n",
            "        Returns:\n",
            "            Action specifying what tool to use.\n",
            "        \"\"\"\n",
            "        if len(intermediate_steps) == 0:\n",
            "            return [\n",
            "                AgentAction(tool=\"Search\", tool_input=kwargs[\"input\"], log=\"\"),\n",
            "                AgentAction(tool=\"RandomWord\", tool_input=kwargs[\"input\"], log=\"\"),\n",
            "            ]\n",
            "        else:\n",
            "            return AgentFinish(return_values={\"output\": \"bar\"}, log=\"\")\n",
            "agent = FakeAgent()\n",
            "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
            "agent_executor.run(\"How many people live in canada as of 2023?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "The current population of Canada is 38,669,152 as of Monday, April 24, 2023, based on Worldometer elaboration of the latest United Nations data.\n",
            "Now I'm doing this!\n",
            "foo\n",
            "> Finished chain.\n",
            "'bar'\n",
            "previous\n",
            "Custom MRKL Agent\n",
            "next\n",
            "Custom Agent with Tool Retrieval\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Custom Agent with Tool Retrieval\n",
            " Contents \n",
            "Set up environment\n",
            "Set up tools\n",
            "Tool Retriever\n",
            "Prompt Template\n",
            "Output Parser\n",
            "Set up LLM, stop sequence, and the agent\n",
            "Use the Agent\n",
            "Custom Agent with Tool Retrieval#\n",
            "This notebook builds off of this notebook and assumes familiarity with how agents work.\n",
            "The novel idea introduced in this notebook is the idea of using retrieval to select the set of tools to use to answer an agent query. This is useful when you have many many tools to select from. You cannot put the description of all the tools in the prompt (because of context length issues) so instead you dynamically select the N tools you do want to consider using at run time.\n",
            "In this notebook we will create a somewhat contrieved example. We will have one legitimate tool (search) and then 99 fake tools which are just nonsense. We will then add a step in the prompt template that takes the user input and retrieves tool relevant to the query.\n",
            "Set up environment#\n",
            "Do necessary imports, etc.\n",
            "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
            "from langchain.prompts import StringPromptTemplate\n",
            "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
            "from typing import List, Union\n",
            "from langchain.schema import AgentAction, AgentFinish\n",
            "import re\n",
            "Set up tools#\n",
            "We will create one legitimate tool (search) and then 99 fake tools\n",
            "# Define which tools the agent can use to answer user queries\n",
            "search = SerpAPIWrapper()\n",
            "search_tool = Tool(\n",
            "        name = \"Search\",\n",
            "        func=search.run,\n",
            "        description=\"useful for when you need to answer questions about current events\"\n",
            "    )\n",
            "def fake_func(inp: str) -> str:\n",
            "    return \"foo\"\n",
            "fake_tools = [\n",
            "    Tool(\n",
            "        name=f\"foo-{i}\", \n",
            "        func=fake_func, \n",
            "        description=f\"a silly function that you can use to get more information about the number {i}\"\n",
            "    ) \n",
            "    for i in range(99)\n",
            "]\n",
            "ALL_TOOLS = [search_tool] + fake_tools\n",
            "Tool Retriever#\n",
            "3072   <class 'numpy.ndarray'>\n",
            "]\n",
            "ALL_TOOLS = [search_tool] + fake_tools\n",
            "Tool Retriever#\n",
            "We will use a vectorstore to create embeddings for each tool description. Then, for an incoming query we can create embeddings for that query and do a similarity search for relevant tools.\n",
            "from langchain.vectorstores import FAISS\n",
            "from langchain.embeddings import OpenAIEmbeddings\n",
            "from langchain.schema import Document\n",
            "docs = [Document(page_content=t.description, metadata={\"index\": i}) for i, t in enumerate(ALL_TOOLS)]\n",
            "vector_store = FAISS.from_documents(docs, OpenAIEmbeddings())\n",
            "retriever = vector_store.as_retriever()\n",
            "def get_tools(query):\n",
            "    docs = retriever.get_relevant_documents(query)\n",
            "    return [ALL_TOOLS[d.metadata[\"index\"]] for d in docs]\n",
            "We can now test this retriever to see if it seems to work.\n",
            "get_tools(\"whats the weather?\")\n",
            "[Tool(name='Search', description='useful for when you need to answer questions about current events', return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x114b28a90>, func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='', aiosession=None)>, coroutine=None),\n",
            " Tool(name='foo-95', description='a silly function that you can use to get more information about the number 95', return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x114b28a90>, func=<function fake_func at 0x15e5bd1f0>, coroutine=None),\n",
            " Tool(name='foo-12', description='a silly function that you can use to get more information about the number 12', return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x114b28a90>, func=<function fake_func at 0x15e5bd1f0>, coroutine=None),\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Tool(name='foo-15', description='a silly function that you can use to get more information about the number 15', return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x114b28a90>, func=<function fake_func at 0x15e5bd1f0>, coroutine=None)]\n",
            "get_tools(\"whats the number 13?\")\n",
            "[Tool(name='foo-13', description='a silly function that you can use to get more information about the number 13', return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x114b28a90>, func=<function fake_func at 0x15e5bd1f0>, coroutine=None),\n",
            " Tool(name='foo-12', description='a silly function that you can use to get more information about the number 12', return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x114b28a90>, func=<function fake_func at 0x15e5bd1f0>, coroutine=None),\n",
            " Tool(name='foo-14', description='a silly function that you can use to get more information about the number 14', return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x114b28a90>, func=<function fake_func at 0x15e5bd1f0>, coroutine=None),\n",
            " Tool(name='foo-11', description='a silly function that you can use to get more information about the number 11', return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x114b28a90>, func=<function fake_func at 0x15e5bd1f0>, coroutine=None)]\n",
            "Prompt Template#\n",
            "The prompt template is pretty standard, because we’re not actually changing that much logic in the actual prompt template, but rather we are just changing how retrieval is done.\n",
            "# Set up the base template\n",
            "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
            "{tools}\n",
            "Use the following format:\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [{tool_names}]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
            "Question: {input}\n",
            "{agent_scratchpad}\"\"\"\n",
            "The custom prompt template now has the concept of a tools_getter, which we call on the input to select the tools to use\n",
            "from typing import Callable\n",
            "# Set up a prompt template\n",
            "class CustomPromptTemplate(StringPromptTemplate):\n",
            "    # The template to use\n",
            "    template: str\n",
            "    ############## NEW ######################\n",
            "    # The list of tools available\n",
            "    tools_getter: Callable\n",
            "    \n",
            "    def format(self, **kwargs) -> str:\n",
            "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
            "        # Format them in a particular way\n",
            "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
            "        thoughts = \"\"\n",
            "        for action, observation in intermediate_steps:\n",
            "            thoughts += action.log\n",
            "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
            "        # Set the agent_scratchpad variable to that value\n",
            "        kwargs[\"agent_scratchpad\"] = thoughts\n",
            "        ############## NEW ######################\n",
            "        tools = self.tools_getter(kwargs[\"input\"])\n",
            "        # Create a tools variable from the list of tools provided\n",
            "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools])\n",
            "        # Create a list of tool names for the tools provided\n",
            "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in tools])\n",
            "        return self.template.format(**kwargs)\n",
            "prompt = CustomPromptTemplate(\n",
            "    template=template,\n",
            "    tools_getter=get_tools,\n",
            "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
            "    # This includes the `intermediate_steps` variable because that is needed\n",
            "    input_variables=[\"input\", \"intermediate_steps\"]\n",
            ")\n",
            "3072   <class 'numpy.ndarray'>\n",
            "input_variables=[\"input\", \"intermediate_steps\"]\n",
            ")\n",
            "Output Parser#\n",
            "The output parser is unchanged from the previous notebook, since we are not changing anything about the output format.\n",
            "class CustomOutputParser(AgentOutputParser):\n",
            "    \n",
            "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
            "        # Check if agent should finish\n",
            "        if \"Final Answer:\" in llm_output:\n",
            "            return AgentFinish(\n",
            "                # Return values is generally always a dictionary with a single `output` key\n",
            "                # It is not recommended to try anything else at the moment :)\n",
            "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
            "                log=llm_output,\n",
            "            )\n",
            "        # Parse out the action and action input\n",
            "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
            "        match = re.search(regex, llm_output, re.DOTALL)\n",
            "        if not match:\n",
            "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
            "        action = match.group(1).strip()\n",
            "        action_input = match.group(2)\n",
            "        # Return the action and action input\n",
            "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
            "output_parser = CustomOutputParser()\n",
            "Set up LLM, stop sequence, and the agent#\n",
            "Also the same as the previous notebook\n",
            "llm = OpenAI(temperature=0)\n",
            "# LLM chain consisting of the LLM and a prompt\n",
            "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
            "tools = get_tools(\"whats the weather?\")\n",
            "tool_names = [tool.name for tool in tools]\n",
            "agent = LLMSingleActionAgent(\n",
            "    llm_chain=llm_chain, \n",
            "    output_parser=output_parser,\n",
            "    stop=[\"\\nObservation:\"], \n",
            "    allowed_tools=tool_names\n",
            ")\n",
            "Use the Agent#\n",
            "Now we can use it!\n",
            "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
            "agent_executor.run(\"What's the weather in SF?\")\n",
            "3072   <class 'numpy.ndarray'>\n",
            "agent_executor.run(\"What's the weather in SF?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "Thought: I need to find out what the weather is in SF\n",
            "Action: Search\n",
            "Action Input: Weather in SF\n",
            "Observation:Mostly cloudy skies early, then partly cloudy in the afternoon. High near 60F. ENE winds shifting to W at 10 to 15 mph. Humidity71%. UV Index6 of 10. I now know the final answer\n",
            "Final Answer: 'Arg, 'tis mostly cloudy skies early, then partly cloudy in the afternoon. High near 60F. ENE winds shiftin' to W at 10 to 15 mph. Humidity71%. UV Index6 of 10.\n",
            "> Finished chain.\n",
            "\"'Arg, 'tis mostly cloudy skies early, then partly cloudy in the afternoon. High near 60F. ENE winds shiftin' to W at 10 to 15 mph. Humidity71%. UV Index6 of 10.\"\n",
            "previous\n",
            "Custom MultiAction Agent\n",
            "next\n",
            "Conversation Agent (for Chat Models)\n",
            " Contents\n",
            "  \n",
            "Set up environment\n",
            "Set up tools\n",
            "Tool Retriever\n",
            "Prompt Template\n",
            "Output Parser\n",
            "Set up LLM, stop sequence, and the agent\n",
            "Use the Agent\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            ".ipynb\n",
            ".pdf\n",
            "Custom LLM Agent\n",
            " Contents \n",
            "Set up environment\n",
            "Set up tool\n",
            "Prompt Template\n",
            "Output Parser\n",
            "Set up LLM\n",
            "Define the stop sequence\n",
            "Set up the Agent\n",
            "Use the Agent\n",
            "Adding Memory\n",
            "Custom LLM Agent#\n",
            "This notebook goes through how to create your own custom LLM agent.\n",
            "An LLM agent consists of three parts:\n",
            "PromptTemplate: This is the prompt template that can be used to instruct the language model on what to do\n",
            "LLM: This is the language model that powers the agent\n",
            "stop sequence: Instructs the LLM to stop generating as soon as this string is found\n",
            "OutputParser: This determines how to parse the LLMOutput into an AgentAction or AgentFinish object\n",
            "The LLMAgent is used in an AgentExecutor. This AgentExecutor can largely be thought of as a loop that:\n",
            "Passes user input and any previous steps to the Agent (in this case, the LLMAgent)\n",
            "If the Agent returns an AgentFinish, then return that directly to the user\n",
            "If the Agent returns an AgentAction, then use that to call a tool and get an Observation\n",
            "Repeat, passing the AgentAction and Observation back to the Agent until an AgentFinish is emitted.\n",
            "AgentAction is a response that consists of action and action_input. action refers to which tool to use, and action_input refers to the input to that tool. log can also be provided as more context (that can be used for logging, tracing, etc).\n",
            "AgentFinish is a response that contains the final message to be sent back to the user. This should be used to end an agent run.\n",
            "In this notebook we walk through how to create a custom LLM agent.\n",
            "Set up environment#\n",
            "Do necessary imports, etc.\n",
            "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
            "from langchain.prompts import StringPromptTemplate\n",
            "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
            "from typing import List, Union\n",
            "from langchain.schema import AgentAction, AgentFinish\n",
            "import re\n",
            "Set up tool#\n",
            "Set up any tools the agent may want to use. This may be necessary to put in the prompt (so that the agent knows to use these tools).\n",
            "# Define which tools the agent can use to answer user queries\n",
            "search = SerpAPIWrapper()\n",
            "tools = [\n",
            "3072   <class 'numpy.ndarray'>\n",
            "search = SerpAPIWrapper()\n",
            "tools = [\n",
            "    Tool(\n",
            "        name = \"Search\",\n",
            "        func=search.run,\n",
            "        description=\"useful for when you need to answer questions about current events\"\n",
            "    )\n",
            "]\n",
            "Prompt Template#\n",
            "This instructs the agent on what to do. Generally, the template should incorporate:\n",
            "tools: which tools the agent has access and how and when to call them.\n",
            "intermediate_steps: These are tuples of previous (AgentAction, Observation) pairs. These are generally not passed directly to the model, but the prompt template formats them in a specific way.\n",
            "input: generic user input\n",
            "# Set up the base template\n",
            "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
            "{tools}\n",
            "Use the following format:\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [{tool_names}]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
            "Question: {input}\n",
            "{agent_scratchpad}\"\"\"\n",
            "# Set up a prompt template\n",
            "class CustomPromptTemplate(StringPromptTemplate):\n",
            "    # The template to use\n",
            "    template: str\n",
            "    # The list of tools available\n",
            "    tools: List[Tool]\n",
            "    \n",
            "    def format(self, **kwargs) -> str:\n",
            "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
            "        # Format them in a particular way\n",
            "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
            "        thoughts = \"\"\n",
            "        for action, observation in intermediate_steps:\n",
            "            thoughts += action.log\n",
            "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
            "        # Set the agent_scratchpad variable to that value\n",
            "        kwargs[\"agent_scratchpad\"] = thoughts\n",
            "        # Create a tools variable from the list of tools provided\n",
            "3072   <class 'numpy.ndarray'>\n",
            "# Create a tools variable from the list of tools provided\n",
            "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
            "        # Create a list of tool names for the tools provided\n",
            "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
            "        return self.template.format(**kwargs)\n",
            "prompt = CustomPromptTemplate(\n",
            "    template=template,\n",
            "    tools=tools,\n",
            "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
            "    # This includes the `intermediate_steps` variable because that is needed\n",
            "    input_variables=[\"input\", \"intermediate_steps\"]\n",
            ")\n",
            "Output Parser#\n",
            "The output parser is responsible for parsing the LLM output into AgentAction and AgentFinish. This usually depends heavily on the prompt used.\n",
            "This is where you can change the parsing to do retries, handle whitespace, etc\n",
            "class CustomOutputParser(AgentOutputParser):\n",
            "    \n",
            "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
            "        # Check if agent should finish\n",
            "        if \"Final Answer:\" in llm_output:\n",
            "            return AgentFinish(\n",
            "                # Return values is generally always a dictionary with a single `output` key\n",
            "                # It is not recommended to try anything else at the moment :)\n",
            "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
            "                log=llm_output,\n",
            "            )\n",
            "        # Parse out the action and action input\n",
            "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
            "        match = re.search(regex, llm_output, re.DOTALL)\n",
            "        if not match:\n",
            "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
            "        action = match.group(1).strip()\n",
            "        action_input = match.group(2)\n",
            "        # Return the action and action input\n",
            "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
            "output_parser = CustomOutputParser()\n",
            "Set up LLM#\n",
            "Choose the LLM you want to use!\n",
            "3072   <class 'numpy.ndarray'>\n",
            "Set up LLM#\n",
            "Choose the LLM you want to use!\n",
            "llm = OpenAI(temperature=0)\n",
            "Define the stop sequence#\n",
            "This is important because it tells the LLM when to stop generation.\n",
            "This depends heavily on the prompt and model you are using. Generally, you want this to be whatever token you use in the prompt to denote the start of an Observation (otherwise, the LLM may hallucinate an observation for you).\n",
            "Set up the Agent#\n",
            "We can now combine everything to set up our agent\n",
            "# LLM chain consisting of the LLM and a prompt\n",
            "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
            "tool_names = [tool.name for tool in tools]\n",
            "agent = LLMSingleActionAgent(\n",
            "    llm_chain=llm_chain, \n",
            "    output_parser=output_parser,\n",
            "    stop=[\"\\nObservation:\"], \n",
            "    allowed_tools=tool_names\n",
            ")\n",
            "Use the Agent#\n",
            "Now we can use it!\n",
            "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
            "agent_executor.run(\"How many people live in canada as of 2023?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "Thought: I need to find out the population of Canada in 2023\n",
            "Action: Search\n",
            "Action Input: Population of Canada in 2023\n",
            "Observation:The current population of Canada is 38,658,314 as of Wednesday, April 12, 2023, based on Worldometer elaboration of the latest United Nations data. I now know the final answer\n",
            "Final Answer: Arrr, there be 38,658,314 people livin' in Canada as of 2023!\n",
            "> Finished chain.\n",
            "\"Arrr, there be 38,658,314 people livin' in Canada as of 2023!\"\n",
            "Adding Memory#\n",
            "If you want to add memory to the agent, you’ll need to:\n",
            "Add a place in the custom prompt for the chat_history\n",
            "Add a memory object to the agent executor.\n",
            "# Set up the base template\n",
            "template_with_history = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
            "{tools}\n",
            "Use the following format:\n",
            "Question: the input question you must answer\n",
            "3072   <class 'numpy.ndarray'>\n",
            "{tools}\n",
            "Use the following format:\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [{tool_names}]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
            "Previous conversation history:\n",
            "{history}\n",
            "New question: {input}\n",
            "{agent_scratchpad}\"\"\"\n",
            "prompt_with_history = CustomPromptTemplate(\n",
            "    template=template_with_history,\n",
            "    tools=tools,\n",
            "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
            "    # This includes the `intermediate_steps` variable because that is needed\n",
            "    input_variables=[\"input\", \"intermediate_steps\", \"history\"]\n",
            ")\n",
            "llm_chain = LLMChain(llm=llm, prompt=prompt_with_history)\n",
            "tool_names = [tool.name for tool in tools]\n",
            "agent = LLMSingleActionAgent(\n",
            "    llm_chain=llm_chain, \n",
            "    output_parser=output_parser,\n",
            "    stop=[\"\\nObservation:\"], \n",
            "    allowed_tools=tool_names\n",
            ")\n",
            "from langchain.memory import ConversationBufferWindowMemory\n",
            "memory=ConversationBufferWindowMemory(k=2)\n",
            "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)\n",
            "agent_executor.run(\"How many people live in canada as of 2023?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "Thought: I need to find out the population of Canada in 2023\n",
            "Action: Search\n",
            "Action Input: Population of Canada in 2023\n",
            "Observation:The current population of Canada is 38,658,314 as of Wednesday, April 12, 2023, based on Worldometer elaboration of the latest United Nations data. I now know the final answer\n",
            "Final Answer: Arrr, there be 38,658,314 people livin' in Canada as of 2023!\n",
            "> Finished chain.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "> Finished chain.\n",
            "\"Arrr, there be 38,658,314 people livin' in Canada as of 2023!\"\n",
            "agent_executor.run(\"how about in mexico?\")\n",
            "> Entering new AgentExecutor chain...\n",
            "Thought: I need to find out how many people live in Mexico.\n",
            "Action: Search\n",
            "Action Input: How many people live in Mexico as of 2023?\n",
            "Observation:The current population of Mexico is 132,679,922 as of Tuesday, April 11, 2023, based on Worldometer elaboration of the latest United Nations data. Mexico 2020 ... I now know the final answer.\n",
            "Final Answer: Arrr, there be 132,679,922 people livin' in Mexico as of 2023!\n",
            "> Finished chain.\n",
            "\"Arrr, there be 132,679,922 people livin' in Mexico as of 2023!\"\n",
            "previous\n",
            "Custom Agent\n",
            "next\n",
            "Custom LLM Agent (with a ChatModel)\n",
            " Contents\n",
            "  \n",
            "Set up environment\n",
            "Set up tool\n",
            "Prompt Template\n",
            "Output Parser\n",
            "Set up LLM\n",
            "Define the stop sequence\n",
            "Set up the Agent\n",
            "Use the Agent\n",
            "Adding Memory\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "3072   <class 'numpy.ndarray'>\n",
            "[['417ede5d-39be-498f-b518-f47ed4e53b90'\n",
            "  array([-0.00905002, -0.01971785, -0.02056132, ...,  0.00987275,\n",
            "          0.00406179, -0.00464946])\n",
            "  {'chunk': 0, 'text': '.rst\\n.pdf\\nWelcome to LangChain\\n Contents \\nGetting Started\\nModules\\nUse Cases\\nReference Docs\\nEcosystem\\nAdditional Resources\\nWelcome to LangChain#\\nLangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model, but will also be:\\nData-aware: connect a language model to other sources of data\\nAgentic: allow a language model to interact with its environment\\nThe LangChain framework is designed around these principles.\\nThis is the Python specific portion of the documentation. For a purely conceptual guide to LangChain, see here. For the JavaScript documentation, see here.\\nGetting Started#\\nHow to get started using LangChain to create an Language Model application.\\nQuickstart Guide\\nConcepts and terminology.\\nConcepts and terminology\\nTutorials created by community experts and presented on YouTube.\\nTutorials\\nModules#\\nThese modules are the core abstractions which we view as the building blocks of any LLM-powered application.\\nFor each module LangChain provides standard, extendable interfaces. LangChain also provides external integrations and even end-to-end implementations for off-the-shelf use.\\nThe docs for each module contain quickstart examples, how-to guides, reference docs, and conceptual guides.\\nThe modules are (from least to most complex):\\nModels: Supported model types and integrations.\\nPrompts: Prompt management, optimization, and serialization.\\nMemory: Memory refers to state that is persisted between calls of a chain/agent.\\nIndexes: Language models become much more powerful when combined with application-specific data - this module contains interfaces and integrations for loading, querying and updating external data.\\nChains: Chains are structured sequences of calls (to an LLM or to a different utility).\\nAgents: An agent is a Chain in which an LLM, given a high-level directive and a set of tools, repeatedly decides an action, executes the action and observes the outcome until the high-level directive is complete.\\nCallbacks: Callbacks let you log and stream the intermediate steps of any chain, making it easy to observe, debug, and evaluate the internals of an application.\\nUse Cases#\\nBest practices and built-in implementations for common LangChain use cases:', 'url': 'https://python.langchain.com/en/latest/index.html'}]\n",
            " ['110f550d-110b-4378-b95e-141397fa21bc'\n",
            "  array([-0.01767987, -0.00559723, -0.03157021, ..., -0.01575724,\n",
            "         -0.00186342, -0.0224168 ])\n",
            "  {'chunk': 1, 'text': 'Use Cases#\\nBest practices and built-in implementations for common LangChain use cases:\\nAutonomous Agents: Autonomous agents are long-running agents that take many steps in an attempt to accomplish an objective. Examples include AutoGPT and BabyAGI.\\nAgent Simulations: Putting agents in a sandbox and observing how they interact with each other and react to events can be an effective way to evaluate their long-range reasoning and planning abilities.\\nPersonal Assistants: One of the primary LangChain use cases. Personal assistants need to take actions, remember interactions, and have knowledge about your data.\\nQuestion Answering: Another common LangChain use case. Answering questions over specific documents, only utilizing the information in those documents to construct an answer.\\nChatbots: Language models love to chat, making this a very natural use of them.\\nQuerying Tabular Data: Recommended reading if you want to use language models to query structured data (CSVs, SQL, dataframes, etc).\\nCode Understanding: Recommended reading if you want to use language models to analyze code.\\nInteracting with APIs: Enabling language models to interact with APIs is extremely powerful. It gives them access to up-to-date information and allows them to take actions.\\nExtraction: Extract structured information from text.\\nSummarization: Compressing longer documents. A type of Data-Augmented Generation.\\nEvaluation: Generative models are hard to evaluate with traditional metrics. One promising approach is to use language models themselves to do the evaluation.\\nReference Docs#\\nFull documentation on all methods, classes, installation methods, and integration setups for LangChain.\\nLangChain Installation\\nReference Documentation\\nEcosystem#\\nLangChain integrates a lot of different LLMs, systems, and products.\\nFrom the other side, many systems and products depend on LangChain.\\nIt creates a vibrant and thriving ecosystem.\\nIntegrations: Guides for how other products can be used with LangChain.\\nDependents: List of repositories that use LangChain.\\nDeployments: A collection of instructions, code snippets, and template repositories for deploying LangChain apps.\\nAdditional Resources#\\nAdditional resources we think may be useful as you develop your application!\\nLangChainHub: The LangChainHub is a place to share and explore other prompts, chains, and agents.', 'url': 'https://python.langchain.com/en/latest/index.html'}]\n",
            " ['d5f00f02-3295-4567-b297-5e3262dc2728'\n",
            "  array([ 0.00652774, -0.0205926 , -0.01914285, ..., -0.00614192,\n",
            "          0.01197987, -0.02626686])\n",
            "  {'chunk': 2, 'text': 'Gallery: A collection of great projects that use Langchain, compiled by the folks at Kyrolabs. Useful for finding inspiration and example implementations.\\nTracing: A guide on using tracing in LangChain to visualize the execution of chains and agents.\\nModel Laboratory: Experimenting with different prompts, models, and chains is a big part of developing the best possible application. The ModelLaboratory makes it easy to do so.\\nDiscord: Join us on our Discord to discuss all things LangChain!\\nYouTube: A collection of the LangChain tutorials and videos.\\nProduction Support: As you move your LangChains into production, we’d love to offer more comprehensive support. Please fill out this form and we’ll set up a dedicated support Slack channel.\\nnext\\nQuickstart Guide\\n Contents\\n  \\nGetting Started\\nModules\\nUse Cases\\nReference Docs\\nEcosystem\\nAdditional Resources\\nBy Harrison Chase\\n    \\n      © Copyright 2023, Harrison Chase.\\n      \\n  Last updated on May 30, 2023.', 'url': 'https://python.langchain.com/en/latest/index.html'}]\n",
            " ['0b6fe3c6-1f0e-4608-a950-43231e46b08a'\n",
            "  array([-0.01558946,  0.01663067, -0.00562634, ..., -0.00662934,\n",
            "         -0.02084326, -0.01054581])\n",
            "  {'chunk': 0, 'text': 'Search\\nError\\nPlease activate JavaScript to enable the search functionality.\\nCtrl+K\\nBy Harrison Chase\\n    \\n      © Copyright 2023, Harrison Chase.\\n      \\n  Last updated on May 30, 2023.', 'url': 'https://python.langchain.com/en/latest/search.html'}]\n",
            " ['39d5f15f-b973-42c0-8c9b-a2df49b627dc'\n",
            "  array([-0.02019753,  0.0199271 , -0.02535255, ..., -0.01219457,\n",
            "         -0.00988749, -0.00385359])\n",
            "  {'chunk': 0, 'text': '.md\\n.pdf\\nDependents\\nDependents#\\nDependents stats for hwchase17/langchain\\n[update: 2023-05-17; only dependent repositories with Stars > 100]\\nRepository\\nStars\\nopenai/openai-cookbook\\n35401\\nLAION-AI/Open-Assistant\\n32861\\nmicrosoft/TaskMatrix\\n32766\\nhpcaitech/ColossalAI\\n29560\\nreworkd/AgentGPT\\n22315\\nimartinez/privateGPT\\n17474\\nopenai/chatgpt-retrieval-plugin\\n16923\\nmindsdb/mindsdb\\n16112\\njerryjliu/llama_index\\n15407\\nmlflow/mlflow\\n14345\\nGaiZhenbiao/ChuanhuChatGPT\\n10372\\ndatabrickslabs/dolly\\n9919\\nAIGC-Audio/AudioGPT\\n8177\\nlogspace-ai/langflow\\n6807\\nimClumsyPanda/langchain-ChatGLM\\n6087\\narc53/DocsGPT\\n5292\\ne2b-dev/e2b\\n4622\\nnsarrazin/serge\\n4076\\nmadawei2699/myGPTReader\\n3952\\nzauberzeug/nicegui\\n3952\\ngo-skynet/LocalAI\\n3762\\nGreyDGL/PentestGPT\\n3388\\nmmabrouk/chatgpt-wrapper\\n3243\\nzilliztech/GPTCache\\n3189\\nwenda-LLM/wenda\\n3050\\nmarqo-ai/marqo\\n2930\\ngkamradt/langchain-tutorials\\n2710\\nPrefectHQ/marvin\\n2545\\nproject-baize/baize-chatbot\\n2479\\nwhitead/paper-qa\\n2399\\nlanggenius/dify\\n2344\\nGerevAI/gerev\\n2283\\nhwchase17/chat-langchain\\n2266\\nguangzhengli/ChatFiles\\n1903\\nAzure-Samples/azure-search-openai-demo\\n1884\\nOpenBMB/BMTools\\n1860\\nFarama-Foundation/PettingZoo\\n1813\\nOpenGVLab/Ask-Anything\\n1571\\nIntelligenzaArtificiale/Free-Auto-GPT\\n1480', 'url': 'https://python.langchain.com/en/latest/dependents.html'}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avaKReiCfMa_"
      },
      "source": [
        "Let's take a look at what sort of metadata we're working with in this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1OyqJxIfMa_"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "print(\"Here are some example entries in our Knowledge Base:\\n\")\n",
        "for r in df.iloc[0:2].to_dict(orient=\"records\"):\n",
        "    pprint(r['metadata'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JegURaAg2PuN"
      },
      "source": [
        "Our chunks are ready so now we move onto embedding and indexing everything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQUX8IzWfMbA"
      },
      "source": [
        "## Initializing the Pinecone client\n",
        "\n",
        "Now the data is ready, we can set up our index to store it.\n",
        "\n",
        "We begin by instantiating the Pinecone client. To do this we need a [free API key](https://app.pinecone.io)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "AXupo44GfMbA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.environ.get(\"PINECONE_API_KEY\"):\n",
        "    from pinecone_notebooks.colab import Authenticate\n",
        "    Authenticate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pc.delete_index(name = index_name)"
      ],
      "metadata": {
        "id": "q5kbyiegHQNd"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF1v9bmyfMbA"
      },
      "source": [
        "### Creating a Pinecone Index\n",
        "\n",
        "When creating the index we need to define several configuration properties.\n",
        "\n",
        "- `name` can be anything we like. The name is used as an identifier for the index when performing other operations such as `describe_index`, `delete_index`, and so on.\n",
        "- `metric` specifies the similarity metric that will be used later when you make queries to the index.\n",
        "- `dimension` should correspond to the dimension of the dense vectors produced by your embedding model. In this quick start, we are using made-up data so a small value is simplest.\n",
        "- `spec` holds a specification which tells Pinecone how you would like to deploy our index. You can find a list of all [available providers and regions here](https://docs.pinecone.io/docs/projects).\n",
        "\n",
        "There are more configurations available, but this minimal set will get us started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO8sbJFZNyIZ",
        "outputId": "ba6240af-1da2-44d3-a14c-3aab12162ccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created index  gpt-4-langchain-docs-fast\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "    \"name\": \"gpt-4-langchain-docs-fast\",\n",
              "    \"dimension\": 3072,\n",
              "    \"metric\": \"cosine\",\n",
              "    \"host\": \"gpt-4-langchain-docs-fast-b78vvil.svc.aped-4627-b74a.pinecone.io\",\n",
              "    \"spec\": {\n",
              "        \"serverless\": {\n",
              "            \"cloud\": \"aws\",\n",
              "            \"region\": \"us-east-1\"\n",
              "        }\n",
              "    },\n",
              "    \"status\": {\n",
              "        \"ready\": true,\n",
              "        \"state\": \"Ready\"\n",
              "    },\n",
              "    \"deletion_protection\": \"disabled\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if not pc.has_index(name=index_name):\n",
        "    # if does not exist, create index\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=dimensions,  # dimensionality of text-embedding-ada-002\n",
        "        metric='cosine',\n",
        "        spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
        "\n",
        "    )\n",
        "    print(\"Created index \", index_name)\n",
        "pc.describe_index(name=index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9ocsVktfMbA"
      },
      "source": [
        "## Storing data in the Index\n",
        "\n",
        "First we need to instantiate an Index client that can interact with the index we just created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yMgj-3rfMbA",
        "outputId": "0c3fb3b3-5d5f-4d9b-cae7-19cc12ec1589"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 3072,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "# Instantiate an Index client\n",
        "index = pc.Index(name=index_name)\n",
        "\n",
        "# View index stats for the new index\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezSTzN2rPa2o"
      },
      "source": [
        "We can see the index is currently empty with a `total_vector_count` of `0`. We can begin populating it with OpenAI `text-embedding-ada-002` built embeddings like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "ec7424275f504d68be91c5ebeb302ca1",
            "09b97c48b49a485d9247ae7880d50b02",
            "f81d1c625cfa40f38374df13f55a5f44",
            "300d7ba4624d41ff9107a580ef081d7b",
            "d51d1729f8584dcbbc3d9db705605fc9",
            "246bddad48ce48f4b67cbb3a1a975f60",
            "d750d65a4c9f4d83a50f34f712e58ad3",
            "0e1c8ad3334f4745818ca7725307e8bb",
            "02db3b468b4148398c4da6c64cb33372",
            "a801e1a698cf44898795285681edfb36",
            "ebe54195147d4259b4928fd4f4e2476a"
          ]
        },
        "id": "iZbFbulAPeop",
        "outputId": "af786425-487b-4352-cee4-f1b2f4485b6f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sending upsert requests:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec7424275f504d68be91c5ebeb302ca1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'upserted_count': 200}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "index.upsert_from_dataframe(\n",
        "    df=df,\n",
        "    batch_size=100\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YttJOrEtQIF9"
      },
      "source": [
        "Now we've added all of our langchain docs to the index. With that we can move on to retrieval and then answer generation using GPT-4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FumVmMRlQQ7w"
      },
      "source": [
        "## Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLRODeL-QTJ9"
      },
      "source": [
        "To search through our documents we first need to create a query vector `xq`. Using `xq` we will retrieve the most relevant chunks from the LangChain docs. To create that query vector we must initialize a `text-embedding-ada-002` embedding model with OpenAI. For this, you need an [OpenAI API key](https://platform.openai.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "dhDTQnqp-yyx"
      },
      "outputs": [],
      "source": [
        "def create_embedding(query):\n",
        "    from openai import OpenAI\n",
        "    from google.colab import userdata\n",
        "\n",
        "    #openai_api_key = os.getenv('OPENAI_API_KEY') or 'sk-...'\n",
        "    client = OpenAI(api_key=openai_api_key)\n",
        "    model=\"text-embedding-ada-002\"\n",
        "    model=\"text-embedding-3-large\"\n",
        "\n",
        "    # Create an embedding\n",
        "    res = client.embeddings.create(\n",
        "      model=model,\n",
        "      input=[query],\n",
        "    )\n",
        "    return res.data[0].embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "FMUPdX9cQQYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4249a724-afa0-4d34-f891-ebd97f6f7cbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'matches': [{'id': 'd5f00f02-3295-4567-b297-5e3262dc2728',\n",
              "              'metadata': {'chunk': 2.0,\n",
              "                           'text': 'Gallery: A collection of great projects '\n",
              "                                   'that use Langchain, compiled by the folks '\n",
              "                                   'at Kyrolabs. Useful for finding '\n",
              "                                   'inspiration and example implementations.\\n'\n",
              "                                   'Tracing: A guide on using tracing in '\n",
              "                                   'LangChain to visualize the execution of '\n",
              "                                   'chains and agents.\\n'\n",
              "                                   'Model Laboratory: Experimenting with '\n",
              "                                   'different prompts, models, and chains is a '\n",
              "                                   'big part of developing the best possible '\n",
              "                                   'application. The ModelLaboratory makes it '\n",
              "                                   'easy to do so.\\n'\n",
              "                                   'Discord: Join us on our Discord to discuss '\n",
              "                                   'all things LangChain!\\n'\n",
              "                                   'YouTube: A collection of the LangChain '\n",
              "                                   'tutorials and videos.\\n'\n",
              "                                   'Production Support: As you move your '\n",
              "                                   'LangChains into production, we’d love to '\n",
              "                                   'offer more comprehensive support. Please '\n",
              "                                   'fill out this form and we’ll set up a '\n",
              "                                   'dedicated support Slack channel.\\n'\n",
              "                                   'next\\n'\n",
              "                                   'Quickstart Guide\\n'\n",
              "                                   ' Contents\\n'\n",
              "                                   '  \\n'\n",
              "                                   'Getting Started\\n'\n",
              "                                   'Modules\\n'\n",
              "                                   'Use Cases\\n'\n",
              "                                   'Reference Docs\\n'\n",
              "                                   'Ecosystem\\n'\n",
              "                                   'Additional Resources\\n'\n",
              "                                   'By Harrison Chase\\n'\n",
              "                                   '    \\n'\n",
              "                                   '      © Copyright 2023, Harrison Chase.\\n'\n",
              "                                   '      \\n'\n",
              "                                   '  Last updated on May 30, 2023.',\n",
              "                           'url': 'https://python.langchain.com/en/latest/index.html'},\n",
              "              'score': 0.576469421,\n",
              "              'values': []},\n",
              "             {'id': '110f550d-110b-4378-b95e-141397fa21bc',\n",
              "              'metadata': {'chunk': 1.0,\n",
              "                           'text': 'Use Cases#\\n'\n",
              "                                   'Best practices and built-in '\n",
              "                                   'implementations for common LangChain use '\n",
              "                                   'cases:\\n'\n",
              "                                   'Autonomous Agents: Autonomous agents are '\n",
              "                                   'long-running agents that take many steps '\n",
              "                                   'in an attempt to accomplish an objective. '\n",
              "                                   'Examples include AutoGPT and BabyAGI.\\n'\n",
              "                                   'Agent Simulations: Putting agents in a '\n",
              "                                   'sandbox and observing how they interact '\n",
              "                                   'with each other and react to events can be '\n",
              "                                   'an effective way to evaluate their '\n",
              "                                   'long-range reasoning and planning '\n",
              "                                   'abilities.\\n'\n",
              "                                   'Personal Assistants: One of the primary '\n",
              "                                   'LangChain use cases. Personal assistants '\n",
              "                                   'need to take actions, remember '\n",
              "                                   'interactions, and have knowledge about '\n",
              "                                   'your data.\\n'\n",
              "                                   'Question Answering: Another common '\n",
              "                                   'LangChain use case. Answering questions '\n",
              "                                   'over specific documents, only utilizing '\n",
              "                                   'the information in those documents to '\n",
              "                                   'construct an answer.\\n'\n",
              "                                   'Chatbots: Language models love to chat, '\n",
              "                                   'making this a very natural use of them.\\n'\n",
              "                                   'Querying Tabular Data: Recommended reading '\n",
              "                                   'if you want to use language models to '\n",
              "                                   'query structured data (CSVs, SQL, '\n",
              "                                   'dataframes, etc).\\n'\n",
              "                                   'Code Understanding: Recommended reading if '\n",
              "                                   'you want to use language models to analyze '\n",
              "                                   'code.\\n'\n",
              "                                   'Interacting with APIs: Enabling language '\n",
              "                                   'models to interact with APIs is extremely '\n",
              "                                   'powerful. It gives them access to '\n",
              "                                   'up-to-date information and allows them to '\n",
              "                                   'take actions.\\n'\n",
              "                                   'Extraction: Extract structured information '\n",
              "                                   'from text.\\n'\n",
              "                                   'Summarization: Compressing longer '\n",
              "                                   'documents. A type of Data-Augmented '\n",
              "                                   'Generation.\\n'\n",
              "                                   'Evaluation: Generative models are hard to '\n",
              "                                   'evaluate with traditional metrics. One '\n",
              "                                   'promising approach is to use language '\n",
              "                                   'models themselves to do the evaluation.\\n'\n",
              "                                   'Reference Docs#\\n'\n",
              "                                   'Full documentation on all methods, '\n",
              "                                   'classes, installation methods, and '\n",
              "                                   'integration setups for LangChain.\\n'\n",
              "                                   'LangChain Installation\\n'\n",
              "                                   'Reference Documentation\\n'\n",
              "                                   'Ecosystem#\\n'\n",
              "                                   'LangChain integrates a lot of different '\n",
              "                                   'LLMs, systems, and products.\\n'\n",
              "                                   'From the other side, many systems and '\n",
              "                                   'products depend on LangChain.\\n'\n",
              "                                   'It creates a vibrant and thriving '\n",
              "                                   'ecosystem.\\n'\n",
              "                                   'Integrations: Guides for how other '\n",
              "                                   'products can be used with LangChain.\\n'\n",
              "                                   'Dependents: List of repositories that use '\n",
              "                                   'LangChain.\\n'\n",
              "                                   'Deployments: A collection of instructions, '\n",
              "                                   'code snippets, and template repositories '\n",
              "                                   'for deploying LangChain apps.\\n'\n",
              "                                   'Additional Resources#\\n'\n",
              "                                   'Additional resources we think may be '\n",
              "                                   'useful as you develop your application!\\n'\n",
              "                                   'LangChainHub: The LangChainHub is a place '\n",
              "                                   'to share and explore other prompts, '\n",
              "                                   'chains, and agents.',\n",
              "                           'url': 'https://python.langchain.com/en/latest/index.html'},\n",
              "              'score': 0.570607543,\n",
              "              'values': []},\n",
              "             {'id': '417ede5d-39be-498f-b518-f47ed4e53b90',\n",
              "              'metadata': {'chunk': 0.0,\n",
              "                           'text': '.rst\\n'\n",
              "                                   '.pdf\\n'\n",
              "                                   'Welcome to LangChain\\n'\n",
              "                                   ' Contents \\n'\n",
              "                                   'Getting Started\\n'\n",
              "                                   'Modules\\n'\n",
              "                                   'Use Cases\\n'\n",
              "                                   'Reference Docs\\n'\n",
              "                                   'Ecosystem\\n'\n",
              "                                   'Additional Resources\\n'\n",
              "                                   'Welcome to LangChain#\\n'\n",
              "                                   'LangChain is a framework for developing '\n",
              "                                   'applications powered by language models. '\n",
              "                                   'We believe that the most powerful and '\n",
              "                                   'differentiated applications will not only '\n",
              "                                   'call out to a language model, but will '\n",
              "                                   'also be:\\n'\n",
              "                                   'Data-aware: connect a language model to '\n",
              "                                   'other sources of data\\n'\n",
              "                                   'Agentic: allow a language model to '\n",
              "                                   'interact with its environment\\n'\n",
              "                                   'The LangChain framework is designed around '\n",
              "                                   'these principles.\\n'\n",
              "                                   'This is the Python specific portion of the '\n",
              "                                   'documentation. For a purely conceptual '\n",
              "                                   'guide to LangChain, see here. For the '\n",
              "                                   'JavaScript documentation, see here.\\n'\n",
              "                                   'Getting Started#\\n'\n",
              "                                   'How to get started using LangChain to '\n",
              "                                   'create an Language Model application.\\n'\n",
              "                                   'Quickstart Guide\\n'\n",
              "                                   'Concepts and terminology.\\n'\n",
              "                                   'Concepts and terminology\\n'\n",
              "                                   'Tutorials created by community experts and '\n",
              "                                   'presented on YouTube.\\n'\n",
              "                                   'Tutorials\\n'\n",
              "                                   'Modules#\\n'\n",
              "                                   'These modules are the core abstractions '\n",
              "                                   'which we view as the building blocks of '\n",
              "                                   'any LLM-powered application.\\n'\n",
              "                                   'For each module LangChain provides '\n",
              "                                   'standard, extendable interfaces. LangChain '\n",
              "                                   'also provides external integrations and '\n",
              "                                   'even end-to-end implementations for '\n",
              "                                   'off-the-shelf use.\\n'\n",
              "                                   'The docs for each module contain '\n",
              "                                   'quickstart examples, how-to guides, '\n",
              "                                   'reference docs, and conceptual guides.\\n'\n",
              "                                   'The modules are (from least to most '\n",
              "                                   'complex):\\n'\n",
              "                                   'Models: Supported model types and '\n",
              "                                   'integrations.\\n'\n",
              "                                   'Prompts: Prompt management, optimization, '\n",
              "                                   'and serialization.\\n'\n",
              "                                   'Memory: Memory refers to state that is '\n",
              "                                   'persisted between calls of a chain/agent.\\n'\n",
              "                                   'Indexes: Language models become much more '\n",
              "                                   'powerful when combined with '\n",
              "                                   'application-specific data - this module '\n",
              "                                   'contains interfaces and integrations for '\n",
              "                                   'loading, querying and updating external '\n",
              "                                   'data.\\n'\n",
              "                                   'Chains: Chains are structured sequences of '\n",
              "                                   'calls (to an LLM or to a different '\n",
              "                                   'utility).\\n'\n",
              "                                   'Agents: An agent is a Chain in which an '\n",
              "                                   'LLM, given a high-level directive and a '\n",
              "                                   'set of tools, repeatedly decides an '\n",
              "                                   'action, executes the action and observes '\n",
              "                                   'the outcome until the high-level directive '\n",
              "                                   'is complete.\\n'\n",
              "                                   'Callbacks: Callbacks let you log and '\n",
              "                                   'stream the intermediate steps of any '\n",
              "                                   'chain, making it easy to observe, debug, '\n",
              "                                   'and evaluate the internals of an '\n",
              "                                   'application.\\n'\n",
              "                                   'Use Cases#\\n'\n",
              "                                   'Best practices and built-in '\n",
              "                                   'implementations for common LangChain use '\n",
              "                                   'cases:',\n",
              "                           'url': 'https://python.langchain.com/en/latest/index.html'},\n",
              "              'score': 0.55574733,\n",
              "              'values': []},\n",
              "             {'id': '77ee610e-5bbf-4897-aad2-7d6df939c284',\n",
              "              'metadata': {'chunk': 0.0,\n",
              "                           'text': '.rst\\n'\n",
              "                                   '.pdf\\n'\n",
              "                                   'Chains\\n'\n",
              "                                   'Chains#\\n'\n",
              "                                   'Note\\n'\n",
              "                                   'Conceptual Guide\\n'\n",
              "                                   'Using an LLM in isolation is fine for some '\n",
              "                                   'simple applications,\\n'\n",
              "                                   'but many more complex ones require '\n",
              "                                   'chaining LLMs - either with each other or '\n",
              "                                   'with other experts.\\n'\n",
              "                                   'LangChain provides a standard interface '\n",
              "                                   'for Chains, as well as some common '\n",
              "                                   'implementations of chains for ease of '\n",
              "                                   'use.\\n'\n",
              "                                   'The following sections of documentation '\n",
              "                                   'are provided:\\n'\n",
              "                                   'Getting Started: A getting started guide '\n",
              "                                   'for chains, to get you up and running '\n",
              "                                   'quickly.\\n'\n",
              "                                   'How-To Guides: A collection of how-to '\n",
              "                                   'guides. These highlight how to use various '\n",
              "                                   'types of chains.\\n'\n",
              "                                   'Reference: API reference documentation for '\n",
              "                                   'all Chain classes.\\n'\n",
              "                                   'previous\\n'\n",
              "                                   'Zep Memory\\n'\n",
              "                                   'next\\n'\n",
              "                                   'Getting Started\\n'\n",
              "                                   'By Harrison Chase\\n'\n",
              "                                   '    \\n'\n",
              "                                   '      © Copyright 2023, Harrison Chase.\\n'\n",
              "                                   '      \\n'\n",
              "                                   '  Last updated on May 30, 2023.',\n",
              "                           'url': 'https://python.langchain.com/en/latest/modules/chains.html'},\n",
              "              'score': 0.548442304,\n",
              "              'values': []},\n",
              "             {'id': '70695d42-4061-4fec-9824-d8e724c6aae9',\n",
              "              'metadata': {'chunk': 40.0,\n",
              "                           'text': 'LanceDB (class in langchain.vectorstores)\\n'\n",
              "                                   'lang '\n",
              "                                   '(langchain.utilities.WikipediaAPIWrapper '\n",
              "                                   'attribute)\\n'\n",
              "                                   '    langchain.agents\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.agents.agent_toolkits\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.chains\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.chat_models\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.docstore\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.document_loaders\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.document_transformers\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.embeddings\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.llms\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.memory\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.output_parsers\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.prompts\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.prompts.example_selector\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.python\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.retrievers\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    '\n",
              "                                   'langchain.retrievers.document_compressors\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.serpapi\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.text_splitter\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.tools\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.utilities\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.utilities.searx_search\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   '    langchain.vectorstores\\n'\n",
              "                                   '      \\n'\n",
              "                                   'module\\n'\n",
              "                                   'last_n_tokens_size '\n",
              "                                   '(langchain.llms.LlamaCpp attribute)\\n'\n",
              "                                   'last_refreshed '\n",
              "                                   '(langchain.experimental.GenerativeAgent '\n",
              "                                   'attribute)\\n'\n",
              "                                   'LatexTextSplitter (class in '\n",
              "                                   'langchain.text_splitter)\\n'\n",
              "                                   'lazy_load() '\n",
              "                                   '(langchain.document_loaders.BibtexLoader '\n",
              "                                   'method)\\n'\n",
              "                                   '(langchain.document_loaders.GitHubIssuesLoader '\n",
              "                                   'method)\\n'\n",
              "                                   '(langchain.document_loaders.HuggingFaceDatasetLoader '\n",
              "                                   'method)\\n'\n",
              "                                   '(langchain.document_loaders.JoplinLoader '\n",
              "                                   'method)\\n'\n",
              "                                   '(langchain.document_loaders.PDFMinerLoader '\n",
              "                                   'method)\\n'\n",
              "                                   '(langchain.document_loaders.PyPDFium2Loader '\n",
              "                                   'method)\\n'\n",
              "                                   '(langchain.document_loaders.PyPDFLoader '\n",
              "                                   'method)\\n'\n",
              "                                   '(langchain.document_loaders.PySparkDataFrameLoader '\n",
              "                                   'method)\\n'\n",
              "                                   '(langchain.document_loaders.ToMarkdownLoader '\n",
              "                                   'method)\\n'\n",
              "                                   '(langchain.document_loaders.TomlLoader '\n",
              "                                   'method)\\n'\n",
              "                                   '(langchain.document_loaders.WeatherDataLoader '\n",
              "                                   'method)\\n'\n",
              "                                   'length (langchain.llms.ForefrontAI '\n",
              "                                   'attribute)\\n'\n",
              "                                   'length_no_input (langchain.llms.NLPCloud '\n",
              "                                   'attribute)\\n'\n",
              "                                   'length_penalty (langchain.llms.NLPCloud '\n",
              "                                   'attribute)\\n'\n",
              "                                   'lib (langchain.llms.CTransformers '\n",
              "                                   'attribute)',\n",
              "                           'url': 'https://python.langchain.com/en/latest/genindex.html'},\n",
              "              'score': 0.475316256,\n",
              "              'values': []}],\n",
              " 'namespace': '',\n",
              " 'usage': {'read_units': 6}}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "#query = \"What are LangChain best practices?\"\n",
        "\n",
        "#query =\"are chimichangas better than enchiladas?\"\n",
        "# retrieve from Pinecone\n",
        "xq = create_embedding(query)\n",
        "\n",
        "# get relevant contexts (including the questions)\n",
        "res = index.query(vector=xq, top_k=5, include_metadata=True)\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoBSiDLIUADZ"
      },
      "source": [
        "With retrieval complete, we move on to feeding these into GPT-4 to produce answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfzS4-6-UXgX"
      },
      "source": [
        "## Retrieval Augmented Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPC1jQaKUcy0"
      },
      "source": [
        "GPT-4 is currently accessed via the `ChatCompletions` endpoint of OpenAI.\n",
        "\n",
        "To get a richer response from the LLM that includes context from our knowledge base, we need to retrieve context relevant to the query and then include it into the chat completion prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "unZstoHNUHeG"
      },
      "outputs": [],
      "source": [
        "def retrieval_augmented_prompt(query):\n",
        "    context_limit = 3750\n",
        "    xq = create_embedding(query)\n",
        "\n",
        "    # Get relevant contexts\n",
        "    query_results = index.query(vector=xq, top_k=3, include_metadata=True)\n",
        "    contexts = [\n",
        "        x.metadata['text'] for x in query_results.matches\n",
        "    ]\n",
        "\n",
        "    # Build our prompt with the retrieved contexts included\n",
        "    prompt_start = (\n",
        "        \"Answer the question based on the context below.\\n\\n\"+\n",
        "        \"Context:\\n\"\n",
        "    )\n",
        "    prompt_end = (\n",
        "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
        "    )\n",
        "    context_separator = \"\\n\\n---\\n\\n\"\n",
        "\n",
        "    # Join contexts and trim to fit within limit\n",
        "    combined_contexts = []\n",
        "    total_length = 0\n",
        "\n",
        "    for context in contexts:\n",
        "        new_length = total_length + len(context) + len(context_separator)\n",
        "        if new_length >= context_limit:\n",
        "            break\n",
        "        combined_contexts.append(context)\n",
        "        total_length = new_length\n",
        "\n",
        "    return prompt_start + context_separator.join(combined_contexts) + prompt_end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRcEHm0Z9fXE",
        "outputId": "01a7e644-2123-4558-a847-99c3a8f374b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the question based on the context below.\n",
            "\n",
            "Context:\n",
            "for full documentation on:\\n\\nGetting started (installation, setting up the environment, simple examples)\\n\\nHow-To examples (demos, integrations, helper functions)\\n\\nReference (full API docs)\\n\\nResources (high-level explanation of core concepts)\\n\\nð\\x9f\\x9a\\x80 What can this help with?\\n\\nThere are six main areas that LangChain is designed to help with.\\nThese are, in increasing order of complexity:\\n\\nð\\x9f“\\x83 LLMs and Prompts:\\n\\nThis includes prompt management, prompt optimization, a generic interface for all LLMs, and common utilities for working with LLMs.\\n\\nð\\x9f”\\x97 Chains:\\n\\nChains go beyond a single LLM call and involve sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.\\n\\nð\\x9f“\\x9a Data Augmented Generation:\\n\\nData Augmented Generation involves specific types of chains that first interact with an external data source to fetch data for use in the generation step. Examples include summarization of long pieces of text and question/answering over specific data sources.\\n\\nð\\x9f¤\\x96 Agents:\\n\\nAgents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain\n",
            "\n",
            "---\n",
            "\n",
            "an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end to end agents.\\n\\n\\n\\n\\n\\nUse Cases#\\nThe above modules can be used in a variety of ways. LangChain also provides guidance and assistance in this. Below are some of the common use cases LangChain supports.\\n\\nPersonal Assistants: The main LangChain use case. Personal assistants need to take actions, remember interactions, and have knowledge about your data.\\nQuestion Answering: The second big LangChain use case. Answering questions over specific documents, only utilizing the information in those documents to construct an answer.\\nChatbots: Since language models are good at producing text, that makes them ideal for creating chatbots.\\nQuerying Tabular Data: If you want to understand how to use LLMs to query data that is stored in a tabular format (csvs, SQL, dataframes, etc) you should read this page.\\nInteracting with APIs: Enabling LLMs to interact with APIs is extremely powerful in order to give them more up-to-date information and allow them to take actions.\\nExtraction: Extract structured information from text.\\nSummarization: Summarizing longer documents into shorter, more condensed chunks of information. A type of Data Augmented Generation.\\nEvaluation: Generative models are notoriously\n",
            "\n",
            "Question: how do I use the LLMChain in LangChain?\n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "prompt = retrieval_augmented_prompt(query)\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sihH_GMiV5_p"
      },
      "source": [
        "Now we ask the question of the LLM using chat completion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "IThBqBi8V70d"
      },
      "outputs": [],
      "source": [
        "def chat_completion(prompt):\n",
        "    from openai import OpenAI\n",
        "    from google.colab import userdata\n",
        "    # Get OpenAI api key from platform.openai.com\n",
        "    openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "    # Instantiate the OpenAI client\n",
        "    client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "    # Instructions\n",
        "    sys_prompt = f\"\"\"You are Q&A bot. A highly intelligent system that answers\n",
        "    user questions based on the information provided by the user above\n",
        "    each question. If the information can not be found in the information\n",
        "    provided by the user you truthfully say \"I don't know\".\n",
        "    \"\"\"\n",
        "\n",
        "    res = client.chat.completions.create(\n",
        "        model='gpt-4o-mini-2024-07-18',\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": sys_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0\n",
        "    )\n",
        "    return res.choices[0].message.content.strip()\n",
        "\n",
        "def rag(query):\n",
        "    prompt = retrieval_augmented_prompt(query)\n",
        "    return chat_completion(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zYg0dqlsfMbB",
        "outputId": "b6066807-f306-4523-f2c8-9c52db7db865"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't know.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "question=\"how do i make chimichangas?\"\n",
        "answer = rag(question)\n",
        "answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvS1yJhOWpiJ"
      },
      "source": [
        "To display this response nicely, we will display it in markdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "RDo2qeMHWto1",
        "outputId": "820d9d87-69a2-44e2-915d-3b28496dbbe6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- LangChain is an intuitive framework for developing applications driven by language models, such as OpenAI or Hugging Face.\n- It is a Python library that provides out-of-the-box support for building NLP applications using LLMs.\n- LangChain offers a standard interface for creating chains, enabling sequences of calls that go beyond a single LLM call.\n- The framework simplifies the process of building advanced language model applications.\n- It includes various modules to assist with different aspects of language model application development.\n- LangChain is designed to help with six main areas: LLMs and Prompts, Chains, Data Augmented Generation, and Agents.\n- It supports prompt management, prompt optimization, and common utilities for working with LLMs.\n- LangChain facilitates integrations with other tools and provides end-to-end chains for common applications."
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "display(Markdown(answer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ-a8MHg0eYQ"
      },
      "source": [
        "Let's compare this to a non-augmented query..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "vwhaSgdF0ZDX",
        "outputId": "98bbd7fd-5794-43c8-f717-bfffbe806c3a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I don't know."
          },
          "metadata": {}
        }
      ],
      "source": [
        "def non_augmented_prompt(query):\n",
        "    return f\"\"\"\n",
        "Question: {query}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "answer2 = chat_completion(non_augmented_prompt(question))\n",
        "\n",
        "display(Markdown(answer2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CSsA-dW0m_P"
      },
      "source": [
        "If we drop the `\"I don't know\"` part of the `sys_prompt`, the LLM will try to pull an answer out of things it already knows. These may or may not be correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "Z3svdTCZ0iJ2",
        "outputId": "dd92b128-4d6d-4a24-f471-3c7e088a8889"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Definition**: LangChain is a framework designed for developing applications powered by language models.\n\n- **Modular Components**: It consists of various modules that can be combined to create complex applications, including:\n  - **Prompt Templates**: Tools for creating and managing prompts for language models.\n  - **Chains**: Sequences of calls to language models or other tools, allowing for multi-step workflows.\n  - **Agents**: Components that can make decisions based on user input and dynamically choose actions.\n\n- **Integration**: LangChain supports integration with various language models, including OpenAI's GPT, Hugging Face models, and others.\n\n- **Data Handling**: It provides utilities for managing and processing data, including document loaders and vector stores for efficient retrieval.\n\n- **Use Cases**: Common applications include chatbots, question-answering systems, content generation, and more.\n\n- **Extensibility**: Developers can extend LangChain with custom components to fit specific needs.\n\n- **Community and Resources**: It has an active community and offers extensive documentation, tutorials, and examples to help users get started.\n\n- **Deployment**: LangChain can be used in various environments, from local development to cloud-based applications."
          },
          "metadata": {}
        }
      ],
      "source": [
        "def hallucinating_chat_completion(prompt):\n",
        "    from openai import OpenAI\n",
        "\n",
        "    from google.colab import userdata\n",
        "    # Get OpenAI api key from platform.openai.com\n",
        "    openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "    # Instantiate the OpenAI client\n",
        "    client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "    # Instructions\n",
        "    sys_prompt = f\"\"\"You are helpful Q&A bot.\"\"\"\n",
        "\n",
        "    res = client.chat.completions.create(\n",
        "        model='gpt-4o-mini-2024-07-18',\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": sys_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0\n",
        "    )\n",
        "    return res.choices[0].message.content.strip()\n",
        "\n",
        "answer3 = hallucinating_chat_completion(non_augmented_prompt(question))\n",
        "display(Markdown(answer3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcGon5672lBb"
      },
      "source": [
        "Then we see something even worse than `\"I don't know\"` — hallucinations. Clearly augmenting our queries with additional context can make a huge difference to the performance of our system and ensure that trusted information is given priority when composing a response.\n",
        "\n",
        "Great, we've seen how to augment GPT-4 with semantic search to allow us to answer LangChain specific queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueUJ6ntVfMbB"
      },
      "source": [
        "## Demo cleanup\n",
        "\n",
        "Once you're finished, we delete the index to save resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah_vfEHV2khx"
      },
      "outputs": [],
      "source": [
        "pc.delete_index(name=index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEUMlO8M2h4Y"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec7424275f504d68be91c5ebeb302ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09b97c48b49a485d9247ae7880d50b02",
              "IPY_MODEL_f81d1c625cfa40f38374df13f55a5f44",
              "IPY_MODEL_300d7ba4624d41ff9107a580ef081d7b"
            ],
            "layout": "IPY_MODEL_d51d1729f8584dcbbc3d9db705605fc9"
          }
        },
        "09b97c48b49a485d9247ae7880d50b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_246bddad48ce48f4b67cbb3a1a975f60",
            "placeholder": "​",
            "style": "IPY_MODEL_d750d65a4c9f4d83a50f34f712e58ad3",
            "value": "sending upsert requests: 100%"
          }
        },
        "f81d1c625cfa40f38374df13f55a5f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e1c8ad3334f4745818ca7725307e8bb",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02db3b468b4148398c4da6c64cb33372",
            "value": 200
          }
        },
        "300d7ba4624d41ff9107a580ef081d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a801e1a698cf44898795285681edfb36",
            "placeholder": "​",
            "style": "IPY_MODEL_ebe54195147d4259b4928fd4f4e2476a",
            "value": " 200/200 [01:02&lt;00:00, 51.33it/s]"
          }
        },
        "d51d1729f8584dcbbc3d9db705605fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "246bddad48ce48f4b67cbb3a1a975f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d750d65a4c9f4d83a50f34f712e58ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e1c8ad3334f4745818ca7725307e8bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02db3b468b4148398c4da6c64cb33372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a801e1a698cf44898795285681edfb36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe54195147d4259b4928fd4f4e2476a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}